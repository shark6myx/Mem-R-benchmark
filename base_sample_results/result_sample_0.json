{
  "sample_idx": 0,
  "total_questions": 199,
  "individual_results": [
    {
      "sample_id": 0,
      "question": "When did Caroline go to the LGBTQ support group?",
      "prediction": "yesterday, 7 May, 2023",
      "reference": "7 May 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8571428571428571,
        "rouge1_f": 0.8571428571428571,
        "rouge2_f": 0.8,
        "rougeL_f": 0.8571428571428571,
        "bleu1": 0.5,
        "bleu2": 0.316227766016838,
        "bleu3": 0.1384586850774637,
        "bleu4": 0.09554427922043669,
        "bert_precision": 0.9111090898513794,
        "bert_recall": 0.9640330076217651,
        "bert_f1": 0.9368242025375366,
        "meteor": 0.32258064516129037,
        "sbert_similarity": 0.9192559719085693
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie paint a sunrise?",
      "prediction": "last year",
      "reference": 2022,
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8694188594818115,
        "bert_recall": 0.9111441373825073,
        "bert_f1": 0.8897925615310669,
        "meteor": 0.0,
        "sbert_similarity": 0.3672372102737427
      }
    },
    {
      "sample_id": 0,
      "question": "What fields would Caroline be likely to pursue in her educaton?",
      "prediction": "counseling or working in mental health",
      "reference": "Psychology, counseling certification",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2222222222222222,
        "rouge1_f": 0.2222222222222222,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2222222222222222,
        "bleu1": 0.16666666666666669,
        "bleu2": 0.05773502691896258,
        "bleu3": 0.04506819749679463,
        "bleu4": 0.040824829046386304,
        "bert_precision": 0.830034613609314,
        "bert_recall": 0.8526803851127625,
        "bert_f1": 0.8412051796913147,
        "meteor": 0.15151515151515152,
        "sbert_similarity": 0.6807615756988525
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline research?",
      "prediction": "adoption agencies",
      "reference": "Adoption agencies",
      "category": 1,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 0.46773514128719823,
        "bleu4": 0.316227766016838,
        "bert_precision": 0.9317574501037598,
        "bert_recall": 0.8727336525917053,
        "bert_f1": 0.9012802839279175,
        "meteor": 0.9375,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What is Caroline's identity?",
      "prediction": "Caroline's identity is a transgender woman.",
      "reference": "Transgender woman",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.4444444444444445,
        "rouge2_f": 0.2857142857142857,
        "rougeL_f": 0.4444444444444445,
        "bleu1": 0.25,
        "bleu2": 0.18898223650461357,
        "bleu3": 0.08622792534209149,
        "bleu4": 0.05873949094699214,
        "bert_precision": 0.8472981452941895,
        "bert_recall": 0.8727124333381653,
        "bert_f1": 0.8598175644874573,
        "meteor": 0.20833333333333334,
        "sbert_similarity": 0.6433996558189392
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie run a charity race?",
      "prediction": "last Saturday, 20 May, 2023",
      "reference": "The sunday before 25 May 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.3636363636363636,
        "rouge1_f": 0.3636363636363636,
        "rouge2_f": 0.22222222222222224,
        "rougeL_f": 0.3636363636363636,
        "bleu1": 0.2857142857142857,
        "bleu2": 0.06900655593423542,
        "bleu3": 0.047098549390932394,
        "bleu4": 0.039281465090051315,
        "bert_precision": 0.9140217304229736,
        "bert_recall": 0.9026490449905396,
        "bert_f1": 0.9082997441291809,
        "meteor": 0.0847457627118644,
        "sbert_similarity": 0.8449991941452026
      }
    },
    {
      "sample_id": 0,
      "question": "When is Melanie planning on going camping?",
      "prediction": "next month",
      "reference": "June 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8738223314285278,
        "bert_recall": 0.8416210412979126,
        "bert_f1": 0.8574194312095642,
        "meteor": 0.0,
        "sbert_similarity": 0.5679936408996582
      }
    },
    {
      "sample_id": 0,
      "question": "What is Caroline's relationship status?",
      "prediction": "Caroline is thrilled to make a family for kids who need one.",
      "reference": "Single",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8229660987854004,
        "bert_recall": 0.859571099281311,
        "bert_f1": 0.8408704400062561,
        "meteor": 0.0,
        "sbert_similarity": 0.15529610216617584
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline give a speech at a school?",
      "prediction": "last week on 9 June, 2023",
      "reference": "The week before 9 June 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.4000000000000001,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5714285714285714,
        "bleu2": 0.3086066999241838,
        "bleu3": 0.12657485247324374,
        "bleu4": 0.08307018474412793,
        "bert_precision": 0.9537617564201355,
        "bert_recall": 0.9529368877410889,
        "bert_f1": 0.9533491134643555,
        "meteor": 0.25,
        "sbert_similarity": 0.8689267635345459
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline meet up with her friends, family, and mentors?",
      "prediction": "last week on 9 June, 2023",
      "reference": "The week before 9 June 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.4000000000000001,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5714285714285714,
        "bleu2": 0.3086066999241838,
        "bleu3": 0.12657485247324374,
        "bleu4": 0.08307018474412793,
        "bert_precision": 0.9537617564201355,
        "bert_recall": 0.9529368877410889,
        "bert_f1": 0.9533491134643555,
        "meteor": 0.25,
        "sbert_similarity": 0.8689267635345459
      }
    },
    {
      "sample_id": 0,
      "question": "How long has Caroline had her current group of friends for?",
      "prediction": "4 years since I moved from my home country.",
      "reference": "4 years",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.3636363636363636,
        "rouge1_f": 0.3636363636363636,
        "rouge2_f": 0.2222222222222222,
        "rougeL_f": 0.3636363636363636,
        "bleu1": 0.2,
        "bleu2": 0.14907119849998599,
        "bleu3": 0.06705330284284157,
        "bleu4": 0.0446323613785333,
        "bert_precision": 0.8505902290344238,
        "bert_recall": 0.9121282696723938,
        "bert_f1": 0.8802850842475891,
        "meteor": 0.6944444444444445,
        "sbert_similarity": 0.6198556423187256
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Caroline move from 4 years ago?",
      "prediction": "Caroline started transitioning three years ago.",
      "reference": "Sweden",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8324146270751953,
        "bert_recall": 0.8625906705856323,
        "bert_f1": 0.8472340106964111,
        "meteor": 0.0,
        "sbert_similarity": 0.04232289642095566
      }
    },
    {
      "sample_id": 0,
      "question": "How long ago was Caroline's 18th birthday?",
      "prediction": "about 4 years ago",
      "reference": "10 years ago",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5714285714285715,
        "rouge1_f": 0.5714285714285715,
        "rouge2_f": 0.4,
        "rougeL_f": 0.5714285714285715,
        "bleu1": 0.5,
        "bleu2": 0.408248290463863,
        "bleu3": 0.20600140803015504,
        "bleu4": 0.16990442448471224,
        "bert_precision": 0.9107354283332825,
        "bert_recall": 0.9314624071121216,
        "bert_f1": 0.920982301235199,
        "meteor": 0.6048387096774195,
        "sbert_similarity": 0.8088800311088562
      }
    },
    {
      "sample_id": 0,
      "question": "What career path has Caroline decided to persue?",
      "prediction": "counseling and mental health",
      "reference": "counseling or mental health for Transgender people",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5454545454545454,
        "rouge1_f": 0.5454545454545454,
        "rouge2_f": 0.2222222222222222,
        "rougeL_f": 0.5454545454545454,
        "bleu1": 0.354274914555761,
        "bleu2": 0.23618327637050732,
        "bleu3": 0.1112396062304518,
        "bleu4": 0.08881915596542085,
        "bert_precision": 0.9401496648788452,
        "bert_recall": 0.8874038457870483,
        "bert_f1": 0.913015604019165,
        "meteor": 0.3814262023217247,
        "sbert_similarity": 0.6846485733985901
      }
    },
    {
      "sample_id": 0,
      "question": "Would Caroline still want to pursue counseling as a career if she hadn't received support growing up?",
      "prediction": "I want to pass that same support to anyone who needs it.",
      "reference": "Likely no",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8139373064041138,
        "bert_recall": 0.8192213773727417,
        "bert_f1": 0.8165707588195801,
        "meteor": 0.16666666666666669,
        "sbert_similarity": 0.12115900963544846
      }
    },
    {
      "sample_id": 0,
      "question": "What activities does Melanie partake in?",
      "prediction": "pottery, running, camping, biking",
      "reference": "pottery, camping, painting, swimming",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.5,
        "rouge2_f": 0.0,
        "rougeL_f": 0.5,
        "bleu1": 0.7142857142857143,
        "bleu2": 0.5976143046671969,
        "bleu3": 0.4185793008243382,
        "bleu4": 0.20556680845025987,
        "bert_precision": 0.9616600275039673,
        "bert_recall": 0.9618307948112488,
        "bert_f1": 0.9617454409599304,
        "meteor": 0.25,
        "sbert_similarity": 0.8578824996948242
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie sign up for a pottery class?",
      "prediction": "yesterday, 3 July 2023",
      "reference": "2 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5714285714285715,
        "rouge1_f": 0.5714285714285715,
        "rouge2_f": 0.4,
        "rougeL_f": 0.5714285714285715,
        "bleu1": 0.4,
        "bleu2": 0.316227766016838,
        "bleu3": 0.1522474354853864,
        "bleu4": 0.11362193664674995,
        "bert_precision": 0.9208704233169556,
        "bert_recall": 0.9646010398864746,
        "bert_f1": 0.9422286152839661,
        "meteor": 0.6048387096774195,
        "sbert_similarity": 0.8569438457489014
      }
    },
    {
      "sample_id": 0,
      "question": "When is Caroline going to the transgender conference?",
      "prediction": "this month",
      "reference": "July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8705527782440186,
        "bert_recall": 0.8371520042419434,
        "bert_f1": 0.853525698184967,
        "meteor": 0.0,
        "sbert_similarity": 0.48674145340919495
      }
    },
    {
      "sample_id": 0,
      "question": "Where has Melanie camped?",
      "prediction": "in the mountains and at the beach",
      "reference": "beach, mountains, forest",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4444444444444444,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2,
        "bleu1": 0.2857142857142857,
        "bleu2": 0.06900655593423542,
        "bleu3": 0.047098549390932394,
        "bleu4": 0.039281465090051315,
        "bert_precision": 0.8515216708183289,
        "bert_recall": 0.8339496850967407,
        "bert_f1": 0.8426440954208374,
        "meteor": 0.0,
        "sbert_similarity": 0.6775467395782471
      }
    },
    {
      "sample_id": 0,
      "question": "What do Melanie's kids like?",
      "prediction": "The kids loved it and it was a nice way to relax after the road trip.",
      "reference": "dinosaurs, nature",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8273831605911255,
        "bert_recall": 0.8013603091239929,
        "bert_f1": 0.8141639232635498,
        "meteor": 0.0,
        "sbert_similarity": 0.1271049976348877
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go to the museum?",
      "prediction": "6 July, 2023",
      "reference": "5 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5,
        "bleu2": 0.12909944487358058,
        "bleu3": 0.09635409769034631,
        "bleu4": 0.09554427922043669,
        "bert_precision": 0.9585504531860352,
        "bert_recall": 0.9829279184341431,
        "bert_f1": 0.9705861210823059,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.9262788891792297
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline have a picnic?",
      "prediction": "last week on 6 July, 2023",
      "reference": "The week before 6 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.4000000000000001,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5714285714285714,
        "bleu2": 0.3086066999241838,
        "bleu3": 0.12657485247324374,
        "bleu4": 0.08307018474412793,
        "bert_precision": 0.9422187209129333,
        "bert_recall": 0.9516827464103699,
        "bert_f1": 0.9469270706176758,
        "meteor": 0.25,
        "sbert_similarity": 0.8749296069145203
      }
    },
    {
      "sample_id": 0,
      "question": "Would Caroline likely have Dr. Seuss books on her bookshelf?",
      "prediction": "I've got lots of kids' books- classics, stories from different cultures, educational books, all of that.",
      "reference": "Yes, since she collects classic children's books",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.09090909090909091,
        "rouge1_f": 0.15999999999999998,
        "rouge2_f": 0.0,
        "rougeL_f": 0.15999999999999998,
        "bleu1": 0.0909090909090909,
        "bleu2": 0.020806259464411975,
        "bleu3": 0.013510398157576722,
        "bleu4": 0.010331208012220438,
        "bert_precision": 0.8653687238693237,
        "bert_recall": 0.8898049592971802,
        "bert_f1": 0.877416729927063,
        "meteor": 0.0,
        "sbert_similarity": 0.5071794390678406
      }
    },
    {
      "sample_id": 0,
      "question": "What books has Melanie read?",
      "prediction": "\"Charlotte's Web\"",
      "reference": "\"Nothing is Impossible\", \"Charlotte's Web\"",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5714285714285715,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5714285714285715,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.301194211912202,
        "bleu2": 0.301194211912202,
        "bleu3": 0.301194211912202,
        "bleu4": 0.301194211912202,
        "bert_precision": 0.9526907205581665,
        "bert_recall": 0.9140009880065918,
        "bert_f1": 0.9329448938369751,
        "meteor": 0.39893617021276595,
        "sbert_similarity": 0.7511487603187561
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie do to destress?",
      "prediction": "I've been running farther to de-stress, which has been great for my headspace.",
      "reference": "Running, pottery",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.14285714285714285,
        "rouge1_f": 0.11764705882352941,
        "rouge2_f": 0.0,
        "rougeL_f": 0.11764705882352941,
        "bleu1": 0.12500000000000003,
        "bleu2": 0.028867513459481287,
        "bleu3": 0.018864614597621485,
        "bleu4": 0.014628063653657535,
        "bert_precision": 0.8261620998382568,
        "bert_recall": 0.8199148178100586,
        "bert_f1": 0.8230265974998474,
        "meteor": 0.0,
        "sbert_similarity": 0.23419292271137238
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline go to the LGBTQ conference?",
      "prediction": "10 July, 2023",
      "reference": "10 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 0.75,
        "bleu2": 0.49999999999999994,
        "bleu3": 0.23549424823785386,
        "bleu4": 0.1880301546543197,
        "bert_precision": 0.9584363102912903,
        "bert_recall": 0.9826313853263855,
        "bert_f1": 0.9703831076622009,
        "meteor": 0.3333333333333333,
        "sbert_similarity": 0.9868618845939636
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie read the book \"nothing is impossible\"?",
      "prediction": "not mentioned",
      "reference": 2022,
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8321195840835571,
        "bert_recall": 0.900690495967865,
        "bert_f1": 0.865048348903656,
        "meteor": 0.0,
        "sbert_similarity": 0.21296730637550354
      }
    },
    {
      "sample_id": 0,
      "question": "Would Caroline pursue writing as a career option?",
      "prediction": "Gonna continue my edu and check out career options, which is pretty exciting!",
      "reference": "LIkely no; though she likes reading, she wants to be a counselor",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0.0625,
        "bleu2": 0.02041241452319315,
        "bleu3": 0.015007489164383502,
        "bleu4": 0.012300686288463768,
        "bert_precision": 0.8412824869155884,
        "bert_recall": 0.8411259651184082,
        "bert_f1": 0.8412042260169983,
        "meteor": 0.04132231404958677,
        "sbert_similarity": 0.2692645788192749
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline go to the adoption meeting?",
      "prediction": "Last Friday, 15 July, 2023.",
      "reference": "The friday before 15 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.7272727272727272,
        "rouge1_f": 0.7272727272727272,
        "rouge2_f": 0.4444444444444445,
        "rougeL_f": 0.7272727272727272,
        "bleu1": 0.5,
        "bleu2": 0.26726124191242434,
        "bleu3": 0.1083896554122787,
        "bleu4": 0.06985342056580097,
        "bert_precision": 0.9410033226013184,
        "bert_recall": 0.9196636080741882,
        "bert_f1": 0.930211067199707,
        "meteor": 0.0847457627118644,
        "sbert_similarity": 0.8644826412200928
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go to the pottery workshop?",
      "prediction": "15 July, 2023",
      "reference": "The Friday before 15 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5714285714285715,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.45489799478447507,
        "bleu2": 0.30326532985631666,
        "bleu3": 0.14283448174223617,
        "bleu4": 0.11404605374835301,
        "bert_precision": 0.932933509349823,
        "bert_recall": 0.8869171142578125,
        "bert_f1": 0.9093435406684875,
        "meteor": 0.17543859649122806,
        "sbert_similarity": 0.7955406308174133
      }
    },
    {
      "sample_id": 0,
      "question": "Would Melanie be considered a member of the LGBTQ community?",
      "prediction": "The context does not explicitly state Melanie's sexual orientation or gender identity, so it's unclear if she is a member of the LGBTQ community.",
      "reference": "Likely no, she does not refer to herself as part of it",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.22857142857142854,
        "rouge1_f": 0.2631578947368421,
        "rouge2_f": 0.05555555555555555,
        "rougeL_f": 0.15789473684210525,
        "bleu1": 0.21428571428571425,
        "bleu2": 0.0890870806374748,
        "bleu3": 0.03235463577999653,
        "bleu4": 0.018693000799960027,
        "bert_precision": 0.8519039154052734,
        "bert_recall": 0.8668415546417236,
        "bert_f1": 0.8593078255653381,
        "meteor": 0.23910984848484848,
        "sbert_similarity": 0.5424456596374512
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go camping in June?",
      "prediction": "last week on 27 June, 2023",
      "reference": "The week before 27 June 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.4000000000000001,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5714285714285714,
        "bleu2": 0.3086066999241838,
        "bleu3": 0.12657485247324374,
        "bleu4": 0.08307018474412793,
        "bert_precision": 0.9519211649894714,
        "bert_recall": 0.951376736164093,
        "bert_f1": 0.9516488909721375,
        "meteor": 0.25,
        "sbert_similarity": 0.8657471537590027
      }
    },
    {
      "sample_id": 0,
      "question": "What LGBTQ+ events has Caroline participated in?",
      "prediction": "Caroline participated in an LGBTQ+ pride parade, an LGBTQ conference, a transgender poetry reading, and is organizing an LGBTQ art show.",
      "reference": "Pride parade, school speech, support group",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.16666666666666666,
        "rouge1_f": 0.14814814814814814,
        "rouge2_f": 0.08000000000000002,
        "rougeL_f": 0.14814814814814814,
        "bleu1": 0.15999999999999998,
        "bleu2": 0.11547005383792518,
        "bleu3": 0.08547903235542961,
        "bleu4": 0.04028998029112094,
        "bert_precision": 0.8505078554153442,
        "bert_recall": 0.8761056065559387,
        "bert_f1": 0.863116979598999,
        "meteor": 0.25,
        "sbert_similarity": 0.5478386878967285
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline go to a pride parade during the summer?",
      "prediction": "last Friday on 14 August, 2023",
      "reference": "The week before 3 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.16666666666666666,
        "rouge1_f": 0.16666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.16666666666666666,
        "bleu1": 0.14285714285714285,
        "bleu2": 0.048795003647426664,
        "bleu3": 0.037468614372419724,
        "bleu4": 0.033031643180138064,
        "bert_precision": 0.9188138246536255,
        "bert_recall": 0.9075930118560791,
        "bert_f1": 0.9131689667701721,
        "meteor": 0.08333333333333333,
        "sbert_similarity": 0.7725843191146851
      }
    },
    {
      "sample_id": 0,
      "question": "What events has Caroline participated in to help children?",
      "prediction": "Last Friday I went to a council meeting for adoption. It was inspiring and emotional - so many people wanted to create loving homes for children in need.",
      "reference": "Mentoring program, school speech",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8334182500839233,
        "bert_recall": 0.8315896391868591,
        "bert_f1": 0.8325030207633972,
        "meteor": 0.0,
        "sbert_similarity": 0.2819942235946655
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go camping in July?",
      "prediction": "two weekends ago, 15 July 2023",
      "reference": "two weekends before 17 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.4000000000000001,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5714285714285714,
        "bleu2": 0.4364357804719847,
        "bleu3": 0.15910628243699468,
        "bleu4": 0.09878765474230743,
        "bert_precision": 0.8811059594154358,
        "bert_recall": 0.8969345092773438,
        "bert_f1": 0.8889498114585876,
        "meteor": 0.625,
        "sbert_similarity": 0.9012724757194519
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline join a mentorship program?",
      "prediction": "Last weekend, 17 July 2023.",
      "reference": "The weekend before 17 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.7272727272727272,
        "rouge1_f": 0.7272727272727272,
        "rouge2_f": 0.4444444444444445,
        "rougeL_f": 0.7272727272727272,
        "bleu1": 0.5714285714285714,
        "bleu2": 0.4364357804719847,
        "bleu3": 0.34016320005192946,
        "bleu4": 0.17567205239427922,
        "bert_precision": 0.9605886936187744,
        "bert_recall": 0.9471758008003235,
        "bert_f1": 0.953835129737854,
        "meteor": 0.3177966101694915,
        "sbert_similarity": 0.893252968788147
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie paint recently?",
      "prediction": "a painting of a sunflower on a canvas",
      "reference": "sunset",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8015382289886475,
        "bert_recall": 0.8515958786010742,
        "bert_f1": 0.8258091807365417,
        "meteor": 0.0,
        "sbert_similarity": 0.2863439619541168
      }
    },
    {
      "sample_id": 0,
      "question": "What activities has Melanie done with her family?",
      "prediction": "camping, exploring the forest, hiking, biking, going to the beach, visiting a museum, playing at a park",
      "reference": "Pottery, painting, camping, museum, swimming, hiking",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.28571428571428575,
        "rouge1_f": 0.2608695652173913,
        "rouge2_f": 0.0,
        "rougeL_f": 0.1739130434782609,
        "bleu1": 0.3478260869565218,
        "bleu2": 0.2177862025921883,
        "bleu3": 0.06262787440255622,
        "bleu4": 0.03259889346257788,
        "bert_precision": 0.8614368438720703,
        "bert_recall": 0.8625841736793518,
        "bert_f1": 0.86201012134552,
        "meteor": 0.14084507042253522,
        "sbert_similarity": 0.7052826881408691
      }
    },
    {
      "sample_id": 0,
      "question": "In what ways is Caroline participating in the LGBTQ community?",
      "prediction": "Caroline is spreading awareness, encouraging students to get involved, joining a mentorship program for LGBTQ youth, attending conferences, and organizing an LGBTQ art show.",
      "reference": "Joining activist group, going to pride parades, participating in an art show, mentoring program",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.3243243243243243,
        "rouge1_f": 0.3157894736842105,
        "rouge2_f": 0.05555555555555555,
        "rougeL_f": 0.2105263157894737,
        "bleu1": 0.3103448275862069,
        "bleu2": 0.10527936095153945,
        "bleu3": 0.03567767099509874,
        "bleu4": 0.019933673568014454,
        "bert_precision": 0.8898808360099792,
        "bert_recall": 0.891027569770813,
        "bert_f1": 0.8904538750648499,
        "meteor": 0.19999999999999998,
        "sbert_similarity": 0.5020586252212524
      }
    },
    {
      "sample_id": 0,
      "question": "How many times has Melanie gone to the beach in 2023?",
      "prediction": "We don't go often, usually only once or twice a year.",
      "reference": 2,
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7987546920776367,
        "bert_recall": 0.8506215810775757,
        "bert_f1": 0.8238726258277893,
        "meteor": 0.0,
        "sbert_similarity": 0.0562899187207222
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline join a new activist group?",
      "prediction": "last Tues, on 20 July, 2023",
      "reference": "The Tuesday before 20 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.5,
        "rouge2_f": 0.4000000000000001,
        "rougeL_f": 0.5,
        "bleu1": 0.375,
        "bleu2": 0.23145502494313785,
        "bleu3": 0.098573017775554,
        "bleu4": 0.06500593260343691,
        "bert_precision": 0.9183221459388733,
        "bert_recall": 0.9276615381240845,
        "bert_f1": 0.9229681491851807,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.7162471413612366
      }
    },
    {
      "sample_id": 0,
      "question": "Would Melanie be more interested in going to a national park or a theme park?",
      "prediction": "Melanie enjoys camping and exploring nature.",
      "reference": "National park; she likes the outdoors",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8981950283050537,
        "bert_recall": 0.8946856260299683,
        "bert_f1": 0.896436870098114,
        "meteor": 0.0,
        "sbert_similarity": 0.5718467831611633
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of art does Caroline make?",
      "prediction": "Caroline's art is about expressing her trans experience.",
      "reference": "abstract art",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2,
        "rouge1_f": 0.1818181818181818,
        "rouge2_f": 0.0,
        "rougeL_f": 0.1818181818181818,
        "bleu1": 0.10000000000000002,
        "bleu2": 0.03333333333333335,
        "bleu3": 0.024950558772614845,
        "bleu4": 0.021105340631872645,
        "bert_precision": 0.8517217636108398,
        "bert_recall": 0.8896167278289795,
        "bert_f1": 0.8702569007873535,
        "meteor": 0.19230769230769235,
        "sbert_similarity": 0.39067336916923523
      }
    },
    {
      "sample_id": 0,
      "question": "When is Melanie's daughter's birthday?",
      "prediction": "last night on 14 August",
      "reference": "13 August",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.28571428571428575,
        "rouge1_f": 0.28571428571428575,
        "rouge2_f": 0.0,
        "rougeL_f": 0.28571428571428575,
        "bleu1": 0.2,
        "bleu2": 0.07071067811865477,
        "bleu3": 0.05665132701906204,
        "bleu4": 0.05372849659117709,
        "bert_precision": 0.8706361055374146,
        "bert_recall": 0.9469426870346069,
        "bert_f1": 0.9071876406669617,
        "meteor": 0.21739130434782608,
        "sbert_similarity": 0.6153324842453003
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline attend a pride parade in August?",
      "prediction": "Last Friday in August.",
      "reference": "The Friday before 14 August 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0.3274923012311928,
        "bleu2": 0.08187307530779821,
        "bleu3": 0.05830302516643934,
        "bleu4": 0.05231223689135342,
        "bert_precision": 0.9194896221160889,
        "bert_recall": 0.8561984300613403,
        "bert_f1": 0.8867161273956299,
        "meteor": 0.08620689655172413,
        "sbert_similarity": 0.6092867851257324
      }
    },
    {
      "sample_id": 0,
      "question": "Would Melanie be considered an ally to the transgender community?",
      "prediction": "Yes, Melanie shows support and encouragement for Caroline's journey and advocacy for the trans community.",
      "reference": "Yes, she is supportive",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.11764705882352941,
        "rouge1_f": 0.2,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2,
        "bleu1": 0.11111111111111109,
        "bleu2": 0.08084520834544433,
        "bleu3": 0.035619862080836485,
        "bleu4": 0.02284411468856457,
        "bert_precision": 0.8673995733261108,
        "bert_recall": 0.907461941242218,
        "bert_f1": 0.8869785666465759,
        "meteor": 0.19607843137254904,
        "sbert_similarity": 0.509857177734375
      }
    },
    {
      "sample_id": 0,
      "question": "Who supports Caroline when she has a negative experience?",
      "prediction": "I've been so helpful to have people around me who accept and support me.",
      "reference": "Her mentors, family, and friends",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.1111111111111111,
        "rouge1_f": 0.1,
        "rouge2_f": 0.0,
        "rougeL_f": 0.1,
        "bleu1": 0.0625,
        "bleu2": 0.02041241452319315,
        "bleu3": 0.015007489164383502,
        "bleu4": 0.012300686288463768,
        "bert_precision": 0.8463136553764343,
        "bert_recall": 0.8670814633369446,
        "bert_f1": 0.8565716743469238,
        "meteor": 0.08474576271186442,
        "sbert_similarity": 0.21199099719524384
      }
    },
    {
      "sample_id": 0,
      "question": "What types of pottery have Melanie and her kids made?",
      "prediction": "We all made our own pots.",
      "reference": "bowls, cup",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8648644685745239,
        "bert_recall": 0.8462419509887695,
        "bert_f1": 0.8554518818855286,
        "meteor": 0.0,
        "sbert_similarity": 0.2862437963485718
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline and Melanie go to a pride fesetival together?",
      "prediction": "last year at the Pride fest",
      "reference": 2022,
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7912021279335022,
        "bert_recall": 0.8358185887336731,
        "bert_f1": 0.812898576259613,
        "meteor": 0.0,
        "sbert_similarity": 0.20312748849391937
      }
    },
    {
      "sample_id": 0,
      "question": "What would Caroline's political leaning likely be?",
      "prediction": "supportive of LGBTQ rights and community involvement",
      "reference": "Liberal",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.800667405128479,
        "bert_recall": 0.8484238982200623,
        "bert_f1": 0.8238542079925537,
        "meteor": 0.0,
        "sbert_similarity": 0.2795277535915375
      }
    },
    {
      "sample_id": 0,
      "question": "What has Melanie painted?",
      "prediction": "a lake sunrise, a sunset, and nature-inspired paintings",
      "reference": "Horse, sunset, sunrise",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.3333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.16666666666666666,
        "bleu1": 0.4,
        "bleu2": 0.21081851067789192,
        "bleu3": 0.08428689847931439,
        "bleu4": 0.05307712171072445,
        "bert_precision": 0.8699131608009338,
        "bert_recall": 0.8851408958435059,
        "bert_f1": 0.8774609565734863,
        "meteor": 0.14285714285714288,
        "sbert_similarity": 0.6567995548248291
      }
    },
    {
      "sample_id": 0,
      "question": "What are Melanie's pets' names?",
      "prediction": "Luna and Oliver",
      "reference": "Oliver, Luna, Bailey",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.3333333333333333,
        "bleu1": 0.3422780793550613,
        "bleu2": 0.09373671250115519,
        "bleu3": 0.07816643970700751,
        "bleu4": 0.069372929071742,
        "bert_precision": 0.9074835181236267,
        "bert_recall": 0.8730452060699463,
        "bert_f1": 0.8899312615394592,
        "meteor": 0.0,
        "sbert_similarity": 0.8309195041656494
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline apply to adoption agencies?",
      "prediction": "23 August, 2023",
      "reference": "The week of 23 August 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5714285714285715,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.45489799478447507,
        "bleu2": 0.30326532985631666,
        "bleu3": 0.14283448174223617,
        "bleu4": 0.11404605374835301,
        "bert_precision": 0.931142270565033,
        "bert_recall": 0.8844871520996094,
        "bert_f1": 0.9072152376174927,
        "meteor": 0.17543859649122806,
        "sbert_similarity": 0.8501457571983337
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline draw a self-portrait?",
      "prediction": "last week on 23 August, 2023",
      "reference": "The week before 23 August 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.4000000000000001,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5714285714285714,
        "bleu2": 0.3086066999241838,
        "bleu3": 0.12657485247324374,
        "bleu4": 0.08307018474412793,
        "bert_precision": 0.9407691955566406,
        "bert_recall": 0.9499505162239075,
        "bert_f1": 0.9453375935554504,
        "meteor": 0.25,
        "sbert_similarity": 0.8732798099517822
      }
    },
    {
      "sample_id": 0,
      "question": "What subject have Caroline and Melanie both painted?",
      "prediction": "nature-inspired ones",
      "reference": "Sunsets",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8240329027175903,
        "bert_recall": 0.7965723872184753,
        "bert_f1": 0.8100700378417969,
        "meteor": 0.0,
        "sbert_similarity": 0.2742471992969513
      }
    },
    {
      "sample_id": 0,
      "question": "What symbols are important to Caroline?",
      "prediction": "the necklace symbolizes love, faith and strength; the rainbow flag mural reflects the courage and strength of the trans community; the eagle symbolizes freedom and pride.",
      "reference": "Rainbow flag, transgender symbol",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.17391304347826086,
        "rouge1_f": 0.19999999999999998,
        "rouge2_f": 0.07142857142857142,
        "rougeL_f": 0.19999999999999998,
        "bleu1": 0.10000000000000002,
        "bleu2": 0.05872202195147035,
        "bleu3": 0.02397985266141786,
        "bleu4": 0.014614031921776127,
        "bert_precision": 0.8271316289901733,
        "bert_recall": 0.887857973575592,
        "bert_f1": 0.8564196228981018,
        "meteor": 0.16129032258064518,
        "sbert_similarity": 0.6526272892951965
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline encounter people on a hike and have a negative experience?",
      "prediction": "1:50 pm on 17 August, 2023",
      "reference": "The week before 25 August 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.3333333333333333,
        "rouge1_f": 0.30769230769230765,
        "rouge2_f": 0.1818181818181818,
        "rougeL_f": 0.30769230769230765,
        "bleu1": 0.2857142857142857,
        "bleu2": 0.06900655593423542,
        "bleu3": 0.047098549390932394,
        "bleu4": 0.039281465090051315,
        "bert_precision": 0.8766248226165771,
        "bert_recall": 0.8834635615348816,
        "bert_f1": 0.8800308704376221,
        "meteor": 0.08333333333333333,
        "sbert_similarity": 0.6876281499862671
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie make a plate in pottery class?",
      "prediction": "25 August, 2023",
      "reference": "24 August 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5,
        "bleu2": 0.12909944487358058,
        "bleu3": 0.09635409769034631,
        "bleu4": 0.09554427922043669,
        "bert_precision": 0.9609243869781494,
        "bert_recall": 0.9851833581924438,
        "bert_f1": 0.9729026556015015,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.9536036252975464
      }
    },
    {
      "sample_id": 0,
      "question": "Would Caroline be considered religious?",
      "prediction": "It stands for love, faith and strength.",
      "reference": "Somewhat, but not extremely religious",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0.11111111111111109,
        "bleu2": 0.03726779962499649,
        "bleu3": 0.028067124621919234,
        "bleu4": 0.023980296761827107,
        "bert_precision": 0.8320812582969666,
        "bert_recall": 0.8277197480201721,
        "bert_f1": 0.8298947215080261,
        "meteor": 0.0,
        "sbert_similarity": 0.23542360961437225
      }
    },
    {
      "sample_id": 0,
      "question": "What instruments does Melanie play?",
      "prediction": "clarinet",
      "reference": "clarinet and violin",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.5,
        "rouge2_f": 0.0,
        "rougeL_f": 0.5,
        "bleu1": 0.1353352832366127,
        "bleu2": 0.04279677428117006,
        "bleu3": 0.02960813390314045,
        "bleu4": 0.024066394763145416,
        "bert_precision": 0.9644253253936768,
        "bert_recall": 0.8998497724533081,
        "bert_f1": 0.931019127368927,
        "meteor": 0.17857142857142855,
        "sbert_similarity": 0.8449621200561523
      }
    },
    {
      "sample_id": 0,
      "question": "What musical artists/bands has Melanie seen?",
      "prediction": "Melanie has seen a band playing on a stage.",
      "reference": "Summer Sounds, Matt Patterson",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8560835719108582,
        "bert_recall": 0.8354477286338806,
        "bert_f1": 0.8456397652626038,
        "meteor": 0.0,
        "sbert_similarity": 0.1074700728058815
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go to the park?",
      "prediction": "yesterday, 28 August, 2023",
      "reference": "27 August 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5714285714285715,
        "rouge1_f": 0.5714285714285715,
        "rouge2_f": 0.4,
        "rougeL_f": 0.5714285714285715,
        "bleu1": 0.3333333333333333,
        "bleu2": 0.08164965809277261,
        "bleu3": 0.05665132701906204,
        "bleu4": 0.048549177170732344,
        "bert_precision": 0.9140295386314392,
        "bert_recall": 0.9651964902877808,
        "bert_f1": 0.9389165043830872,
        "meteor": 0.16129032258064518,
        "sbert_similarity": 0.9055353403091431
      }
    },
    {
      "sample_id": 0,
      "question": "When is Caroline's youth center putting on a talent show?",
      "prediction": "next month",
      "reference": "September 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8689346313476562,
        "bert_recall": 0.8372642993927002,
        "bert_f1": 0.852805495262146,
        "meteor": 0.0,
        "sbert_similarity": 0.536835789680481
      }
    },
    {
      "sample_id": 0,
      "question": "Would Melanie likely enjoy the song \"The Four Seasons\" by Vivaldi?",
      "prediction": "I'm a fan of both classical like Bach and Mozart.",
      "reference": "Yes; it's classical music",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.14285714285714288,
        "rouge1_f": 0.12500000000000003,
        "rouge2_f": 0.0,
        "rougeL_f": 0.12500000000000003,
        "bleu1": 0.08333333333333333,
        "bleu2": 0.027524094128159027,
        "bleu3": 0.020427282860665447,
        "bleu4": 0.017033186037639283,
        "bert_precision": 0.8660361766815186,
        "bert_recall": 0.8776320219039917,
        "bert_f1": 0.8717955350875854,
        "meteor": 0.10869565217391304,
        "sbert_similarity": 0.5727803111076355
      }
    },
    {
      "sample_id": 0,
      "question": "What are some changes Caroline has faced during her transition journey?",
      "prediction": "Transitioning wasn't easy and acceptance wasn't either.",
      "reference": "Changes to her body, losing unsupportive friends",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8428346514701843,
        "bert_recall": 0.8432291746139526,
        "bert_f1": 0.8430318832397461,
        "meteor": 0.0,
        "sbert_similarity": 0.11761322617530823
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie do with her family on hikes?",
      "prediction": "We explored nature, roasted marshmallows around the campfire and even went on a hike.",
      "reference": "Roast marshmallows, tell stories",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.11111111111111112,
        "rouge1_f": 0.22222222222222224,
        "rouge2_f": 0.125,
        "rougeL_f": 0.22222222222222224,
        "bleu1": 0.12500000000000003,
        "bleu2": 0.028867513459481287,
        "bleu3": 0.018864614597621485,
        "bleu4": 0.014628063653657535,
        "bert_precision": 0.8740320205688477,
        "bert_recall": 0.8853223323822021,
        "bert_f1": 0.8796409368515015,
        "meteor": 0.1,
        "sbert_similarity": 0.6628168225288391
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline go biking with friends?",
      "prediction": "last weekend, 13 September 2023",
      "reference": "The weekend before 13 September 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.7272727272727272,
        "rouge1_f": 0.7272727272727272,
        "rouge2_f": 0.4444444444444445,
        "rougeL_f": 0.7272727272727272,
        "bleu1": 0.6666666666666666,
        "bleu2": 0.5163977794943222,
        "bleu3": 0.4091569047284194,
        "bleu4": 0.21711852081087685,
        "bert_precision": 0.9573115110397339,
        "bert_recall": 0.9493043422698975,
        "bert_f1": 0.953291118144989,
        "meteor": 0.4990583804143125,
        "sbert_similarity": 0.9144020080566406
      }
    },
    {
      "sample_id": 0,
      "question": "How long has Melanie been practicing art?",
      "prediction": "Seven years now.",
      "reference": "Since 2016",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8721544146537781,
        "bert_recall": 0.8533461093902588,
        "bert_f1": 0.8626477122306824,
        "meteor": 0.0,
        "sbert_similarity": 0.49278581142425537
      }
    },
    {
      "sample_id": 0,
      "question": "What personality traits might Melanie say Caroline has?",
      "prediction": "kind, inspiring, supportive, creative, caring",
      "reference": "Thoughtful, authentic, driven",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0.2222222222222222,
        "bleu2": 0.05270462766947299,
        "bleu3": 0.03528075103412339,
        "bleu4": 0.028517539529041507,
        "bert_precision": 0.882665753364563,
        "bert_recall": 0.8836590051651001,
        "bert_f1": 0.8831620812416077,
        "meteor": 0.0,
        "sbert_similarity": 0.5987378358840942
      }
    },
    {
      "sample_id": 0,
      "question": "What transgender-specific events has Caroline attended?",
      "prediction": "LGBTQ conference, LGBTQ pride parade, LGBTQ support group, transgender poetry reading, LGBTQ art show.",
      "reference": "Poetry reading, conference",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.42857142857142855,
        "rouge1_f": 0.35294117647058826,
        "rouge2_f": 0.13333333333333336,
        "rougeL_f": 0.23529411764705882,
        "bleu1": 0.21052631578947367,
        "bleu2": 0.15294382258037448,
        "bleu3": 0.11369541118456825,
        "bleu4": 0.05415315253510895,
        "bert_precision": 0.8536297082901001,
        "bert_recall": 0.9201260805130005,
        "bert_f1": 0.8856314420700073,
        "meteor": 0.4573170731707317,
        "sbert_similarity": 0.4680475890636444
      }
    },
    {
      "sample_id": 0,
      "question": "What book did Melanie read from Caroline's suggestion?",
      "prediction": "that book you recommended a while ago",
      "reference": "\"Becoming Nicole\"",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.82767653465271,
        "bert_recall": 0.8288825750350952,
        "bert_f1": 0.8282791376113892,
        "meteor": 0.0,
        "sbert_similarity": 0.11817920207977295
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie's friend adopt a child?",
      "prediction": "last year",
      "reference": 2022,
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8694188594818115,
        "bert_recall": 0.9111441373825073,
        "bert_f1": 0.8897925615310669,
        "meteor": 0.0,
        "sbert_similarity": 0.3672372102737427
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie get hurt?",
      "prediction": "Sorry to hear that, Melanie. I hope you're okay.",
      "reference": "September 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8115320205688477,
        "bert_recall": 0.7853717803955078,
        "bert_f1": 0.798237681388855,
        "meteor": 0.0,
        "sbert_similarity": 0.005050720646977425
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie's family go on a roadtrip?",
      "prediction": "this past weekend, 20 October 2023",
      "reference": "The weekend before 20 October 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.4000000000000001,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5714285714285714,
        "bleu2": 0.4364357804719847,
        "bleu3": 0.34016320005192946,
        "bleu4": 0.17567205239427922,
        "bert_precision": 0.9256094694137573,
        "bert_recall": 0.9383182525634766,
        "bert_f1": 0.9319205284118652,
        "meteor": 0.49074074074074076,
        "sbert_similarity": 0.9236389398574829
      }
    },
    {
      "sample_id": 0,
      "question": "How many children does Melanie have?",
      "prediction": "the kids",
      "reference": 3,
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8666282892227173,
        "bert_recall": 0.9128153920173645,
        "bert_f1": 0.8891224265098572,
        "meteor": 0.0,
        "sbert_similarity": 0.28513815999031067
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go on a hike after the roadtrip?",
      "prediction": "a few weeks ago",
      "reference": "19 October 2023",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7924395203590393,
        "bert_recall": 0.805031955242157,
        "bert_f1": 0.798686146736145,
        "meteor": 0.0,
        "sbert_similarity": 0.3106365203857422
      }
    },
    {
      "sample_id": 0,
      "question": "Would Melanie go on another roadtrip soon?",
      "prediction": "We were all freaked when my son got into an accident.",
      "reference": "Likely no; since this one went badly",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8609130382537842,
        "bert_recall": 0.8423429131507874,
        "bert_f1": 0.8515267968177795,
        "meteor": 0.0,
        "sbert_similarity": 0.040077779442071915
      }
    },
    {
      "sample_id": 0,
      "question": "What items has Melanie bought?",
      "prediction": "new shoes",
      "reference": "Figurines, shoes",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.5,
        "rouge2_f": 0.0,
        "rougeL_f": 0.5,
        "bleu1": 0.3032653298563167,
        "bleu2": 0.13562437855552414,
        "bleu3": 0.10556327625176448,
        "bleu4": 0.09069748827745895,
        "bert_precision": 0.9461965560913086,
        "bert_recall": 0.8264420032501221,
        "bert_f1": 0.8822741508483887,
        "meteor": 0.25,
        "sbert_similarity": 0.6501548886299133
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline pass the adoption interview?",
      "prediction": "Last Friday, 20 October 2023.",
      "reference": "The Friday before 22 October 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5454545454545454,
        "rouge1_f": 0.5454545454545454,
        "rouge2_f": 0.22222222222222224,
        "rougeL_f": 0.5454545454545454,
        "bleu1": 0.42857142857142855,
        "bleu2": 0.26726124191242434,
        "bleu3": 0.11511121735118796,
        "bleu4": 0.07730551756939454,
        "bert_precision": 0.9555650353431702,
        "bert_recall": 0.9378255009651184,
        "bert_f1": 0.9466121792793274,
        "meteor": 0.0847457627118644,
        "sbert_similarity": 0.8594999313354492
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie buy the figurines?",
      "prediction": "21 October, 2023",
      "reference": "21 October 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 0.75,
        "bleu2": 0.49999999999999994,
        "bleu3": 0.23549424823785386,
        "bleu4": 0.1880301546543197,
        "bert_precision": 0.9591522216796875,
        "bert_recall": 0.9847801923751831,
        "bert_f1": 0.9717972278594971,
        "meteor": 0.3333333333333333,
        "sbert_similarity": 0.9866596460342407
      }
    },
    {
      "sample_id": 0,
      "question": "Would Caroline want to move back to her home country soon?",
      "prediction": "I think I'm ready to give all my love to a child.",
      "reference": "No; she's in the process of adopting children.",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0.07142857142857141,
        "bleu2": 0.023440361546924773,
        "bleu3": 0.017300021018422027,
        "bleu4": 0.01428363257865929,
        "bert_precision": 0.8909317255020142,
        "bert_recall": 0.8965370655059814,
        "bert_f1": 0.8937256336212158,
        "meteor": 0.0,
        "sbert_similarity": 0.3548682928085327
      }
    },
    {
      "sample_id": 0,
      "question": "What did the charity race raise awareness for?",
      "prediction": "mental health",
      "reference": "mental health",
      "category": 4,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 0.46773514128719823,
        "bleu4": 0.316227766016838,
        "bert_precision": 0.9999998807907104,
        "bert_recall": 0.9999998807907104,
        "bert_f1": 0.9999998807907104,
        "meteor": 0.9375,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie realize after the charity race?",
      "prediction": "Really made me think about taking care of our minds.",
      "reference": "self-care is important",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.14285714285714288,
        "rouge2_f": 0.0,
        "rougeL_f": 0.14285714285714288,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8738051652908325,
        "bert_recall": 0.8957986831665039,
        "bert_f1": 0.8846652507781982,
        "meteor": 0.0,
        "sbert_similarity": 0.36099255084991455
      }
    },
    {
      "sample_id": 0,
      "question": "How does Melanie prioritize self-care?",
      "prediction": "I'm carving out some me-time each day - running, reading, or playing my violin - which refreshes me and helps me stay present for my fam!",
      "reference": "by carving out some me-time each day for activities like running, reading, or playing the violin",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6153846153846153,
        "rouge1_f": 0.6046511627906976,
        "rouge2_f": 0.43902439024390244,
        "rougeL_f": 0.558139534883721,
        "bleu1": 0.4666666666666667,
        "bleu2": 0.40114777854287703,
        "bleu3": 0.361941551554555,
        "bleu4": 0.3179303998422513,
        "bert_precision": 0.9024893045425415,
        "bert_recall": 0.9424304962158203,
        "bert_f1": 0.9220275282859802,
        "meteor": 0.6928104575163399,
        "sbert_similarity": 0.6163122057914734
      }
    },
    {
      "sample_id": 0,
      "question": "What are Caroline's plans for the summer?",
      "prediction": "I'm thrilled to make a family for kids who need one. It'll be tough as a single parent, but I'm up for the challenge!",
      "reference": "researching adoption agencies",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8119651079177856,
        "bert_recall": 0.8450896143913269,
        "bert_f1": 0.8281962871551514,
        "meteor": 0.0,
        "sbert_similarity": 0.23716199398040771
      }
    },
    {
      "sample_id": 0,
      "question": "What type of individuals does the adoption agency Caroline is considering support?",
      "prediction": "LGBTQ+ folks with adoption.",
      "reference": "LGBTQ+ individuals",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.3333333333333333,
        "rouge1_f": 0.3333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.3333333333333333,
        "bleu1": 0.2,
        "bleu2": 0.07071067811865477,
        "bleu3": 0.05665132701906204,
        "bleu4": 0.05372849659117709,
        "bert_precision": 0.9171934127807617,
        "bert_recall": 0.9533190131187439,
        "bert_f1": 0.9349073171615601,
        "meteor": 0.22727272727272727,
        "sbert_similarity": 0.7080492973327637
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Caroline choose the adoption agency?",
      "prediction": "I chose them 'cause they help LGBTQ+ folks with adoption. Their inclusivity and support really spoke to me.",
      "reference": "because of their inclusivity and support for LGBTQ+ individuals",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.3703703703703704,
        "rouge1_f": 0.3703703703703704,
        "rouge2_f": 0.24,
        "rougeL_f": 0.2962962962962963,
        "bleu1": 0.25,
        "bleu2": 0.19867985355975656,
        "bleu3": 0.16667923575277016,
        "bleu4": 0.12673718536830808,
        "bert_precision": 0.8836987018585205,
        "bert_recall": 0.9078872203826904,
        "bert_f1": 0.8956297039985657,
        "meteor": 0.48888888888888904,
        "sbert_similarity": 0.531123697757721
      }
    },
    {
      "sample_id": 0,
      "question": "What is Caroline excited about in the adoption process?",
      "prediction": "I'm stoked to start this new chapter.",
      "reference": "creating a family for kids who need one",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8597844839096069,
        "bert_recall": 0.8186506628990173,
        "bert_f1": 0.8387135863304138,
        "meteor": 0.0,
        "sbert_similarity": 0.15431660413742065
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie think about Caroline's decision to adopt?",
      "prediction": "Your future family is gonna be so lucky to have you!",
      "reference": "she thinks Caroline is doing something amazing and will be an awesome mom",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.16666666666666669,
        "rouge1_f": 0.16666666666666669,
        "rouge2_f": 0.0,
        "rougeL_f": 0.16666666666666669,
        "bleu1": 0.15384615384615385,
        "bleu2": 0.03580574370197164,
        "bleu3": 0.023547737997202885,
        "bleu4": 0.018476860420522198,
        "bert_precision": 0.8569023609161377,
        "bert_recall": 0.8647681474685669,
        "bert_f1": 0.8608173131942749,
        "meteor": 0.07812500000000001,
        "sbert_similarity": 0.25269246101379395
      }
    },
    {
      "sample_id": 0,
      "question": "How long have Mel and her husband been married?",
      "prediction": "5 years already!",
      "reference": "Mel and her husband have been married for 5 years.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.30769230769230765,
        "rouge1_f": 0.30769230769230765,
        "rouge2_f": 0.1818181818181818,
        "rougeL_f": 0.30769230769230765,
        "bleu1": 0.08688697172522257,
        "bleu2": 0.07094291534080824,
        "bleu3": 0.035797677029744235,
        "bleu4": 0.029524961852386813,
        "bert_precision": 0.8519003391265869,
        "bert_recall": 0.8372288942337036,
        "bert_f1": 0.8445008993148804,
        "meteor": 0.053763440860215055,
        "sbert_similarity": 0.28969717025756836
      }
    },
    {
      "sample_id": 0,
      "question": "What does Caroline's necklace symbolize?",
      "prediction": "love, faith and strength",
      "reference": "love, faith, and strength",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 0.8187307530779819,
        "bleu2": 0.7090416310250969,
        "bleu3": 0.5181569246973543,
        "bleu4": 0.2737591267534727,
        "bert_precision": 0.9906566739082336,
        "bert_recall": 0.9857159852981567,
        "bert_f1": 0.9881801009178162,
        "meteor": 0.6388888888888888,
        "sbert_similarity": 0.9917947053909302
      }
    },
    {
      "sample_id": 0,
      "question": "What country is Caroline's grandma from?",
      "prediction": "The context does not provide information about Caroline's grandma's country.",
      "reference": "Sweden",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8028202056884766,
        "bert_recall": 0.8221868276596069,
        "bert_f1": 0.8123881220817566,
        "meteor": 0.0,
        "sbert_similarity": 0.10720138251781464
      }
    },
    {
      "sample_id": 0,
      "question": "What was grandma's gift to Caroline?",
      "prediction": "a necklace",
      "reference": "necklace",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5,
        "bleu2": 0.223606797749979,
        "bleu3": 0.1740444189610778,
        "bleu4": 0.1495348781221221,
        "bert_precision": 0.8547325134277344,
        "bert_recall": 0.9164278507232666,
        "bert_f1": 0.8845056891441345,
        "meteor": 0.45454545454545453,
        "sbert_similarity": 0.9594278335571289
      }
    },
    {
      "sample_id": 0,
      "question": "What is Melanie's hand-painted bowl a reminder of?",
      "prediction": "art and self-expression",
      "reference": "art and self-expression",
      "category": 4,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie and her family do while camping?",
      "prediction": "explored nature, roasted marshmallows around the campfire and even went on a hike.",
      "reference": "explored nature, roasted marshmallows, and went on a hike",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8181818181818181,
        "rouge1_f": 0.8181818181818181,
        "rouge2_f": 0.6,
        "rougeL_f": 0.8181818181818181,
        "bleu1": 0.6666666666666666,
        "bleu2": 0.5773502691896257,
        "bleu3": 0.5077018911399525,
        "bleu4": 0.42311785416105785,
        "bert_precision": 0.9487874507904053,
        "bert_recall": 0.9758626222610474,
        "bert_f1": 0.962134599685669,
        "meteor": 0.7153712548849327,
        "sbert_similarity": 0.9060356020927429
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of counseling and mental health services is Caroline interested in pursuing?",
      "prediction": "I'm still figuring out the details, but I'm thinking of working with trans people, helping them accept themselves and supporting their mental health.",
      "reference": "working with trans people, helping them accept themselves and supporting their mental health",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.7428571428571429,
        "rouge1_f": 0.6842105263157895,
        "rouge2_f": 0.6666666666666666,
        "rougeL_f": 0.6842105263157895,
        "bleu1": 0.5,
        "bleu2": 0.49065338146265813,
        "bleu3": 0.4842838338767059,
        "bleu4": 0.47022156411316,
        "bert_precision": 0.9081205725669861,
        "bert_recall": 0.9564201831817627,
        "bert_f1": 0.9316447377204895,
        "meteor": 0.8568948412698413,
        "sbert_similarity": 0.9305446743965149
      }
    },
    {
      "sample_id": 0,
      "question": "What workshop did Caroline attend recently?",
      "prediction": "an LGBTQ art show",
      "reference": "LGBTQ+ counseling workshop",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.28571428571428575,
        "rouge2_f": 0.0,
        "rougeL_f": 0.28571428571428575,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.87659752368927,
        "bert_recall": 0.8446881771087646,
        "bert_f1": 0.8603470921516418,
        "meteor": 0.0,
        "sbert_similarity": 0.6103930473327637
      }
    },
    {
      "sample_id": 0,
      "question": "What was discussed in the LGBTQ+ counseling workshop?",
      "prediction": "They talked about different therapeutic methods and how to best work with trans people.",
      "reference": "therapeutic methods and how to best work with trans people",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8333333333333333,
        "rouge1_f": 0.8333333333333333,
        "rouge2_f": 0.8181818181818181,
        "rougeL_f": 0.8333333333333333,
        "bleu1": 0.6666666666666666,
        "bleu2": 0.6546536707079771,
        "bleu3": 0.6441485748898267,
        "bleu4": 0.6262844962765469,
        "bert_precision": 0.9290654063224792,
        "bert_recall": 0.9489880800247192,
        "bert_f1": 0.9389211535453796,
        "meteor": 0.8647910731244065,
        "sbert_similarity": 0.8247992396354675
      }
    },
    {
      "sample_id": 0,
      "question": "What motivated Caroline to pursue counseling?",
      "prediction": "I want to help people who have gone through the same things as me.",
      "reference": "her own journey and the support she received, and how counseling improved her life",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.07692307692307691,
        "rouge1_f": 0.07142857142857142,
        "rouge2_f": 0.0,
        "rougeL_f": 0.07142857142857142,
        "bleu1": 0.06666666666666667,
        "bleu2": 0.02182178902359924,
        "bleu3": 0.016071866876084712,
        "bleu4": 0.013217947626377298,
        "bert_precision": 0.8842028379440308,
        "bert_recall": 0.8664472103118896,
        "bert_f1": 0.8752349615097046,
        "meteor": 0.07142857142857142,
        "sbert_similarity": 0.40900319814682007
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of place does Caroline want to create for people?",
      "prediction": "a loving home",
      "reference": "a safe and inviting place for people to grow",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.16666666666666666,
        "rouge1_f": 0.16666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.16666666666666666,
        "bleu1": 0.045111761078870896,
        "bleu2": 0.017471709937655493,
        "bleu3": 0.01639159154635143,
        "bleu4": 0.015377056977980369,
        "bert_precision": 0.8790748715400696,
        "bert_recall": 0.8513867855072021,
        "bert_f1": 0.8650093674659729,
        "meteor": 0.11904761904761904,
        "sbert_similarity": 0.3547641932964325
      }
    },
    {
      "sample_id": 0,
      "question": "Did Melanie make the black and white bowl in the photo?",
      "prediction": "Yeah, I made this bowl in my class. It took some work, but I'm pretty proud of it.",
      "reference": "Yes",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8163771033287048,
        "bert_recall": 0.8290358185768127,
        "bert_f1": 0.8226577639579773,
        "meteor": 0.0,
        "sbert_similarity": 0.06276193261146545
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of books does Caroline have in her library?",
      "prediction": "I've got lots of kids' books- classics, stories from different cultures, educational books, all of that.",
      "reference": "kids' books - classics, stories from different cultures, educational books",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666667,
        "rouge1_f": 0.6923076923076924,
        "rouge2_f": 0.6666666666666666,
        "rougeL_f": 0.6923076923076924,
        "bleu1": 0.5,
        "bleu2": 0.46291004988627577,
        "bleu3": 0.4253732906611973,
        "bleu4": 0.3922967662532704,
        "bert_precision": 0.9142001867294312,
        "bert_recall": 0.9451372623443604,
        "bert_f1": 0.9294113516807556,
        "meteor": 0.6526761648055449,
        "sbert_similarity": 0.8442566990852356
      }
    },
    {
      "sample_id": 0,
      "question": "What was Melanie's favorite book from her childhood?",
      "prediction": "Melanie loved reading \"Charlotte's Web\" as a kid.",
      "reference": "\"Charlotte's Web\"",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.5,
        "rouge2_f": 0.4,
        "rougeL_f": 0.5,
        "bleu1": 0.4166666666666667,
        "bleu2": 0.3892494720807615,
        "bleu3": 0.3605790708802296,
        "bleu4": 0.31702331385234306,
        "bert_precision": 0.9017806053161621,
        "bert_recall": 0.9477951526641846,
        "bert_f1": 0.9242154955863953,
        "meteor": 0.7211538461538463,
        "sbert_similarity": 0.634933352470398
      }
    },
    {
      "sample_id": 0,
      "question": "What book did Caroline recommend to Melanie?",
      "prediction": "\"Becoming Nicole\" by Amy Ellis Nutt.",
      "reference": "\"Becoming Nicole\"",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.5,
        "rouge2_f": 0.33333333333333337,
        "rougeL_f": 0.5,
        "bleu1": 0.4444444444444444,
        "bleu2": 0.408248290463863,
        "bleu3": 0.3661572458236839,
        "bleu4": 0.2984745896009823,
        "bert_precision": 0.8811114430427551,
        "bert_recall": 0.969406008720398,
        "bert_f1": 0.9231522679328918,
        "meteor": 0.78125,
        "sbert_similarity": 0.7488877177238464
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline take away from the book \"Becoming Nicole\"?",
      "prediction": "It made me feel connected and gave me a lot of hope for my own path.",
      "reference": "Lessons on self-acceptance and finding support",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.09523809523809522,
        "rouge1_f": 0.08695652173913043,
        "rouge2_f": 0.0,
        "rougeL_f": 0.08695652173913043,
        "bleu1": 0.0588235294117647,
        "bleu2": 0.019174124721184262,
        "bleu3": 0.014076093604378503,
        "bleu4": 0.011502783619900045,
        "bert_precision": 0.8656476736068726,
        "bert_recall": 0.8624590039253235,
        "bert_f1": 0.8640503287315369,
        "meteor": 0.14285714285714288,
        "sbert_similarity": 0.30920058488845825
      }
    },
    {
      "sample_id": 0,
      "question": "What are the new shoes that Melanie got used for?",
      "prediction": "to de-stress",
      "reference": "Running",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8630030155181885,
        "bert_recall": 0.8907979726791382,
        "bert_f1": 0.8766802549362183,
        "meteor": 0.0,
        "sbert_similarity": 0.24689754843711853
      }
    },
    {
      "sample_id": 0,
      "question": "What is Melanie's reason for getting into running?",
      "prediction": "I've been running farther to de-stress, which has been great for my headspace.",
      "reference": "To de-stress and clear her mind",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2222222222222222,
        "rouge1_f": 0.27272727272727276,
        "rouge2_f": 0.2,
        "rougeL_f": 0.27272727272727276,
        "bleu1": 0.12500000000000003,
        "bleu2": 0.09128709291752769,
        "bleu3": 0.04033183084278514,
        "bleu4": 0.026012784404037925,
        "bert_precision": 0.8737565875053406,
        "bert_recall": 0.9166404008865356,
        "bert_f1": 0.8946849703788757,
        "meteor": 0.07462686567164178,
        "sbert_similarity": 0.373477578163147
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie say running has been great for?",
      "prediction": "running has been great for my mental health.",
      "reference": "Her mental health",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.36363636363636365,
        "rouge1_f": 0.36363636363636365,
        "rouge2_f": 0.22222222222222224,
        "rougeL_f": 0.36363636363636365,
        "bleu1": 0.2222222222222222,
        "bleu2": 0.16666666666666669,
        "bleu3": 0.07542890820012248,
        "bleu4": 0.050712153369465586,
        "bert_precision": 0.8737192153930664,
        "bert_recall": 0.9068927764892578,
        "bert_f1": 0.8899970054626465,
        "meteor": 0.14285714285714288,
        "sbert_similarity": 0.3235776722431183
      }
    },
    {
      "sample_id": 0,
      "question": "What did Mel and her kids make during the pottery workshop?",
      "prediction": "We all made our own pots.",
      "reference": "pots",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2857142857142857,
        "rouge1_f": 0.2857142857142857,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2857142857142857,
        "bleu1": 0.14285714285714285,
        "bleu2": 0.048795003647426664,
        "bleu3": 0.037468614372419724,
        "bleu4": 0.033031643180138064,
        "bert_precision": 0.8354479670524597,
        "bert_recall": 0.8648542165756226,
        "bert_f1": 0.8498967885971069,
        "meteor": 0.0,
        "sbert_similarity": 0.6329399347305298
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of pot did Mel and her kids make with clay?",
      "prediction": "they all made our own pots",
      "reference": "a cup with a dog face on it",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8605320453643799,
        "bert_recall": 0.8536015152931213,
        "bert_f1": 0.857052743434906,
        "meteor": 0.0,
        "sbert_similarity": 0.06355363875627518
      }
    },
    {
      "sample_id": 0,
      "question": "What creative project do Mel and her kids do together besides pottery?",
      "prediction": "painting together lately, especially nature-inspired ones.",
      "reference": "painting",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2857142857142857,
        "rouge1_f": 0.25,
        "rouge2_f": 0.0,
        "rougeL_f": 0.25,
        "bleu1": 0.12500000000000003,
        "bleu2": 0.04225771273642583,
        "bleu3": 0.032085442892067474,
        "bleu4": 0.02777619034011792,
        "bert_precision": 0.8140379190444946,
        "bert_recall": 0.8520554304122925,
        "bert_f1": 0.832612931728363,
        "meteor": 0.33333333333333337,
        "sbert_similarity": 0.5998560190200806
      }
    },
    {
      "sample_id": 0,
      "question": "What did Mel and her kids paint in their latest project in July 2023?",
      "prediction": "nature-inspired ones",
      "reference": "a sunset with a palm tree",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8419812917709351,
        "bert_recall": 0.8387597799301147,
        "bert_f1": 0.8403674364089966,
        "meteor": 0.0,
        "sbert_similarity": 0.22545360028743744
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline see at the council meeting for adoption?",
      "prediction": "so many people wanted to create loving homes for children in need.",
      "reference": "many people wanting to create loving homes for children in need",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8695652173913043,
        "rouge1_f": 0.9565217391304348,
        "rouge2_f": 0.9523809523809523,
        "rougeL_f": 0.9565217391304348,
        "bleu1": 0.7692307692307693,
        "bleu2": 0.7161148740394329,
        "bleu3": 0.6567784656647314,
        "bleu4": 0.6115380576901023,
        "bert_precision": 0.9590452313423157,
        "bert_recall": 0.9681168794631958,
        "bert_f1": 0.9635596871376038,
        "meteor": 0.9004504504504506,
        "sbert_similarity": 0.9466415643692017
      }
    },
    {
      "sample_id": 0,
      "question": "What do sunflowers represent according to Caroline?",
      "prediction": "Sunflowers mean warmth and happiness, right?",
      "reference": "warmth and happiness",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5714285714285715,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.375,
        "bleu2": 0.32732683535398854,
        "bleu3": 0.2649097550589377,
        "bleu4": 0.1374708101760565,
        "bert_precision": 0.8349170088768005,
        "bert_recall": 0.8961904048919678,
        "bert_f1": 0.8644692301750183,
        "meteor": 0.5681818181818182,
        "sbert_similarity": 0.5521316528320312
      }
    },
    {
      "sample_id": 0,
      "question": "Why are flowers important to Melanie?",
      "prediction": "They represent growth, beauty and remind us to appreciate the small moments.",
      "reference": "They remind her to appreciate the small moments and were a part of her wedding decor",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5925925925925926,
        "rouge1_f": 0.5714285714285715,
        "rouge2_f": 0.30769230769230765,
        "rougeL_f": 0.5,
        "bleu1": 0.4953587998572467,
        "bleu2": 0.36349398303898345,
        "bleu3": 0.30913919296629816,
        "bleu4": 0.25919218840980945,
        "bert_precision": 0.9071142077445984,
        "bert_recall": 0.8779828548431396,
        "bert_f1": 0.8923107981681824,
        "meteor": 0.4068550497121926,
        "sbert_similarity": 0.5540401935577393
      }
    },
    {
      "sample_id": 0,
      "question": "What inspired Caroline's painting for the art show?",
      "prediction": "I'm inspired seeing my work make a difference for the LGBTQ+ community.",
      "reference": "visiting an LGBTQ center and wanting to capture unity and strength",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.08333333333333334,
        "rouge2_f": 0.0,
        "rougeL_f": 0.08333333333333334,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8795872926712036,
        "bert_recall": 0.8643674850463867,
        "bert_f1": 0.8719109296798706,
        "meteor": 0.04504504504504504,
        "sbert_similarity": 0.6254662275314331
      }
    },
    {
      "sample_id": 0,
      "question": "How often does Melanie go to the beach with her kids?",
      "prediction": "usually only once or twice a year",
      "reference": "once or twice a year",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8333333333333333,
        "rouge1_f": 0.8333333333333333,
        "rouge2_f": 0.8,
        "rougeL_f": 0.8333333333333333,
        "bleu1": 0.7142857142857143,
        "bleu2": 0.6900655593423543,
        "bleu3": 0.6613898798842307,
        "bleu4": 0.6147881529512643,
        "bert_precision": 0.9254478216171265,
        "bert_recall": 0.9496266841888428,
        "bert_f1": 0.937381386756897,
        "meteor": 0.9576923076923077,
        "sbert_similarity": 0.9151639938354492
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie and her family see during their camping trip last year?",
      "prediction": "the Perseid meteor shower",
      "reference": "Perseid meteor shower",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8571428571428571,
        "rouge1_f": 0.8571428571428571,
        "rouge2_f": 0.8,
        "rougeL_f": 0.8571428571428571,
        "bleu1": 0.75,
        "bleu2": 0.7071067811865475,
        "bleu3": 0.63287829698514,
        "bleu4": 0.3976353643835253,
        "bert_precision": 0.9081102609634399,
        "bert_recall": 0.9284670352935791,
        "bert_f1": 0.9181758165359497,
        "meteor": 0.9498207885304659,
        "sbert_similarity": 0.968867301940918
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie feel while watching the meteor shower?",
      "prediction": "It felt like we were part of something huge and awe-inspiring.",
      "reference": "in awe of the universe",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.12500000000000003,
        "rouge1_f": 0.23529411764705882,
        "rouge2_f": 0.0,
        "rougeL_f": 0.11764705882352941,
        "bleu1": 0.08333333333333333,
        "bleu2": 0.027524094128159027,
        "bleu3": 0.020427282860665447,
        "bleu4": 0.017033186037639283,
        "bert_precision": 0.8544020652770996,
        "bert_recall": 0.8840765953063965,
        "bert_f1": 0.8689860701560974,
        "meteor": 0.0892857142857143,
        "sbert_similarity": 0.47578415274620056
      }
    },
    {
      "sample_id": 0,
      "question": "Whose birthday did Melanie celebrate recently?",
      "prediction": "my daughter's birthday",
      "reference": "Melanie's daughter",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.5714285714285715,
        "rouge2_f": 0.0,
        "rougeL_f": 0.28571428571428575,
        "bleu1": 0.5,
        "bleu2": 0.12909944487358058,
        "bleu3": 0.09635409769034631,
        "bleu4": 0.09554427922043669,
        "bert_precision": 0.883353054523468,
        "bert_recall": 0.9120131134986877,
        "bert_f1": 0.8974543213844299,
        "meteor": 0.0,
        "sbert_similarity": 0.4458889067173004
      }
    },
    {
      "sample_id": 0,
      "question": "Who performed at the concert at Melanie's daughter's birthday?",
      "prediction": "the concert surrounded by music",
      "reference": "Matt Patterson",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8294049501419067,
        "bert_recall": 0.835649847984314,
        "bert_f1": 0.8325156569480896,
        "meteor": 0.0,
        "sbert_similarity": -0.003110981546342373
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Melanie choose to use colors and patterns in her pottery project?",
      "prediction": "What gave you the idea for all the colors and patterns?",
      "reference": "She wanted to catch the eye and make people smile.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.20000000000000004,
        "rouge1_f": 0.1904761904761905,
        "rouge2_f": 0.0,
        "rougeL_f": 0.1904761904761905,
        "bleu1": 0.16666666666666669,
        "bleu2": 0.03892494720807617,
        "bleu3": 0.025677367760996977,
        "bleu4": 0.020255986027125642,
        "bert_precision": 0.8669111728668213,
        "bert_recall": 0.8893816471099854,
        "bert_f1": 0.8780026435852051,
        "meteor": 0.14851485148514848,
        "sbert_similarity": 0.19293510913848877
      }
    },
    {
      "sample_id": 0,
      "question": "What pet does Caroline have?",
      "prediction": "Caroline doesn't specify a pet, but mentions that pets bring joy.",
      "reference": "guinea pig",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8335453271865845,
        "bert_recall": 0.7803289890289307,
        "bert_f1": 0.806059718132019,
        "meteor": 0.0,
        "sbert_similarity": 0.2590315043926239
      }
    },
    {
      "sample_id": 0,
      "question": "What pets does Melanie have?",
      "prediction": "a pup and a kitty",
      "reference": "Two cats and a dog",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4444444444444445,
        "rouge1_f": 0.4000000000000001,
        "rouge2_f": 0.25,
        "rougeL_f": 0.4000000000000001,
        "bleu1": 0.4,
        "bleu2": 0.316227766016838,
        "bleu3": 0.1522474354853864,
        "bleu4": 0.11362193664674995,
        "bert_precision": 0.9334430694580078,
        "bert_recall": 0.9434006810188293,
        "bert_f1": 0.9383955001831055,
        "meteor": 0.37500000000000006,
        "sbert_similarity": 0.7613354325294495
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Oliver hide his bone once?",
      "prediction": "in my slipper",
      "reference": "In Melanie's slipper",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.5714285714285715,
        "rouge2_f": 0.0,
        "rougeL_f": 0.5714285714285715,
        "bleu1": 0.47768754038252614,
        "bleu2": 0.13082012065333476,
        "bleu3": 0.10909005447984235,
        "bleu4": 0.09681772177713914,
        "bert_precision": 0.9412859678268433,
        "bert_recall": 0.9195079803466797,
        "bert_f1": 0.9302695393562317,
        "meteor": 0.3333333333333333,
        "sbert_similarity": 0.6715267896652222
      }
    },
    {
      "sample_id": 0,
      "question": "What activity did Caroline used to do with her dad?",
      "prediction": "I went to a LGBTQ support group yesterday and it was so powerful.",
      "reference": "Horseback riding",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.824206531047821,
        "bert_recall": 0.766730785369873,
        "bert_f1": 0.7944304347038269,
        "meteor": 0.0,
        "sbert_similarity": -0.016255512833595276
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline make for a local church?",
      "prediction": "taking in kids in need",
      "reference": "a stained glass window",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8185700178146362,
        "bert_recall": 0.8263210654258728,
        "bert_f1": 0.8224273324012756,
        "meteor": 0.0,
        "sbert_similarity": -0.004190757870674133
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline find in her neighborhood during her walk?",
      "prediction": "this cool rainbow sidewalk for Pride Month",
      "reference": "a rainbow sidewalk",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4,
        "rouge2_f": 0.25,
        "rougeL_f": 0.4,
        "bleu1": 0.2857142857142857,
        "bleu2": 0.2182178902359924,
        "bleu3": 0.1006949130683619,
        "bleu4": 0.06985342056580097,
        "bert_precision": 0.881126880645752,
        "bert_recall": 0.9606527090072632,
        "bert_f1": 0.9191728830337524,
        "meteor": 0.5514705882352942,
        "sbert_similarity": 0.7868509888648987
      }
    },
    {
      "sample_id": 0,
      "question": "Which song motivates Caroline to be courageous?",
      "prediction": "\"Brave\" by Sara Bareilles has a lot of significance for me. It's about being courageous and fighting for what's right.",
      "reference": "Brave by Sara Bareilles",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2608695652173913,
        "rouge1_f": 0.3076923076923077,
        "rouge2_f": 0.25,
        "rougeL_f": 0.3076923076923077,
        "bleu1": 0.15384615384615385,
        "bleu2": 0.11094003924504585,
        "bleu3": 0.08208968293684403,
        "bleu4": 0.03864198149136354,
        "bert_precision": 0.849393904209137,
        "bert_recall": 0.9284551739692688,
        "bert_f1": 0.8871666193008423,
        "meteor": 0.5257936507936508,
        "sbert_similarity": 0.6410201787948608
      }
    },
    {
      "sample_id": 0,
      "question": "Which  classical musicians does Melanie enjoy listening to?",
      "prediction": "Bach and Mozart",
      "reference": "Bach and Mozart",
      "category": 4,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 0.9999998807907104,
        "bert_recall": 0.9999998807907104,
        "bert_f1": 0.9999998807907104,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "Who is Melanie a fan of in terms of modern music?",
      "prediction": "Ed Sheeran's \"Perfect\"",
      "reference": "Ed Sheeran",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.3333333333333333,
        "bleu2": 0.25819888974716115,
        "bleu3": 0.12111838948674812,
        "bleu4": 0.08633400213704504,
        "bert_precision": 0.8977776765823364,
        "bert_recall": 0.9811890721321106,
        "bert_f1": 0.9376319646835327,
        "meteor": 0.2380952380952381,
        "sbert_similarity": 0.705544114112854
      }
    },
    {
      "sample_id": 0,
      "question": "How long has Melanie been creating art?",
      "prediction": "Seven years now",
      "reference": "7 years",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0.3333333333333333,
        "bleu2": 0.12909944487358058,
        "bleu3": 0.12111838948674812,
        "bleu4": 0.11362193664674995,
        "bert_precision": 0.9228770732879639,
        "bert_recall": 0.9635453224182129,
        "bert_f1": 0.9427728056907654,
        "meteor": 0.8928571428571429,
        "sbert_similarity": 0.8659798502922058
      }
    },
    {
      "sample_id": 0,
      "question": "What precautionary sign did Melanie see at the caf?",
      "prediction": "a sign posted on a door stating that someone is not being able to leave",
      "reference": "A sign stating that someone is not being able to leave",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.88,
        "rouge1_f": 0.846153846153846,
        "rouge2_f": 0.75,
        "rougeL_f": 0.846153846153846,
        "bleu1": 0.7333333333333333,
        "bleu2": 0.6866065623255951,
        "bleu3": 0.6360749521034652,
        "bleu4": 0.5968774175634496,
        "bert_precision": 0.9468196630477905,
        "bert_recall": 0.9803704619407654,
        "bert_f1": 0.9633030295372009,
        "meteor": 0.955125416847905,
        "sbert_similarity": 0.8908344507217407
      }
    },
    {
      "sample_id": 0,
      "question": "What advice does Caroline give for getting started with adoption?",
      "prediction": "Do your research and find an adoption agency or lawyer. They'll help with the process and provide all the info. Gather documents like references, financial info and medical checks. Don't forget to prepare emotionally, since the wait can be hard.",
      "reference": "Do research, find an adoption agency or lawyer, gather necessary documents, and prepare emotionally.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5306122448979592,
        "rouge1_f": 0.46428571428571436,
        "rouge2_f": 0.2222222222222222,
        "rougeL_f": 0.46428571428571436,
        "bleu1": 0.3333333333333333,
        "bleu2": 0.2062842492517587,
        "bleu3": 0.15758588611896324,
        "bleu4": 0.12532443621763048,
        "bert_precision": 0.8881880640983582,
        "bert_recall": 0.9453724026679993,
        "bert_f1": 0.9158885478973389,
        "meteor": 0.49568644950171065,
        "sbert_similarity": 0.8916807174682617
      }
    },
    {
      "sample_id": 0,
      "question": "What setback did Melanie face in October 2023?",
      "prediction": "Last month I got hurt and had to take a break from pottery.",
      "reference": "She got hurt and had to take a break from pottery.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8333333333333333,
        "rouge1_f": 0.8333333333333333,
        "rouge2_f": 0.8181818181818182,
        "rougeL_f": 0.8333333333333333,
        "bleu1": 0.7857142857142857,
        "bleu2": 0.7774288420142415,
        "bleu3": 0.7702048427774233,
        "bleu4": 0.7577395672414201,
        "bert_precision": 0.964232325553894,
        "bert_recall": 0.9778257608413696,
        "bert_f1": 0.9709814190864563,
        "meteor": 0.8924107142857142,
        "sbert_similarity": 0.6955679655075073
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie do to keep herself busy during her pottery break?",
      "prediction": "I just signed up for a pottery class yesterday. It's like therapy for me, letting me express myself and get creative.",
      "reference": "Read a book and paint.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.16666666666666666,
        "rouge1_f": 0.14814814814814814,
        "rouge2_f": 0.0,
        "rougeL_f": 0.14814814814814814,
        "bleu1": 0.12000000000000001,
        "bleu2": 0.022360679774997897,
        "bleu3": 0.013529754476103547,
        "bleu4": 0.009970222994544455,
        "bert_precision": 0.8442370891571045,
        "bert_recall": 0.8771370053291321,
        "bert_f1": 0.8603726625442505,
        "meteor": 0.15151515151515152,
        "sbert_similarity": 0.35499078035354614
      }
    },
    {
      "sample_id": 0,
      "question": "What painting did Melanie show to Caroline on October 13, 2023?",
      "prediction": "a painting of a sunset with a pink sky",
      "reference": "A painting inspired by sunsets with a pink sky.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.7777777777777778,
        "rouge2_f": 0.625,
        "rougeL_f": 0.7777777777777778,
        "bleu1": 0.596559544542913,
        "bleu2": 0.5166357204442371,
        "bleu3": 0.4118628201097518,
        "bleu4": 0.31762152032055835,
        "bert_precision": 0.9549791216850281,
        "bert_recall": 0.9441507458686829,
        "bert_f1": 0.9495340585708618,
        "meteor": 0.625,
        "sbert_similarity": 0.9587686657905579
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of painting did Caroline share with Melanie on October 13, 2023?",
      "prediction": "a painting of a sunset with a pink sky",
      "reference": "An abstract painting with blue streaks on a wall.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.375,
        "rouge1_f": 0.3333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.3333333333333333,
        "bleu1": 0.2982797722714565,
        "bleu2": 0.057761629525894614,
        "bleu3": 0.03609050795723058,
        "bleu4": 0.028240990488565418,
        "bert_precision": 0.9109269380569458,
        "bert_recall": 0.912687361240387,
        "bert_f1": 0.9118062853813171,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.5040775537490845
      }
    },
    {
      "sample_id": 0,
      "question": "What was the poetry reading that Caroline attended about?",
      "prediction": "It was a transgender poetry reading where transgender people shared their stories through poetry.",
      "reference": "It was a transgender poetry reading where transgender people shared their stories.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.9565217391304348,
        "rouge1_f": 0.923076923076923,
        "rouge2_f": 0.9166666666666666,
        "rougeL_f": 0.923076923076923,
        "bleu1": 0.8666666666666667,
        "bleu2": 0.8251983888449983,
        "bleu3": 0.8078434700407627,
        "bleu4": 0.7916963878457504,
        "bert_precision": 0.9864803552627563,
        "bert_recall": 0.9956105351448059,
        "bert_f1": 0.9910244345664978,
        "meteor": 0.9013006367700853,
        "sbert_similarity": 0.9938866496086121
      }
    },
    {
      "sample_id": 0,
      "question": "What did the posters at the poetry reading say?",
      "prediction": "trans lives matter",
      "reference": "\"Trans Lives Matter\"",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.3333333333333333,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 0.513417119032592,
        "bleu2": 0.513417119032592,
        "bleu3": 0.513417119032592,
        "bleu4": 0.288715663092199,
        "bert_precision": 0.9173699617385864,
        "bert_recall": 0.887461245059967,
        "bert_f1": 0.902167797088623,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.9525076746940613
      }
    },
    {
      "sample_id": 0,
      "question": "What does Caroline's drawing symbolize for her?",
      "prediction": "Art gives me so much joy. It helps me show my feelings and freeze gorgeous moments, like a bouquet of flowers.",
      "reference": "Freedom and being true to herself.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.07692307692307691,
        "rouge1_f": 0.07407407407407407,
        "rouge2_f": 0.0,
        "rougeL_f": 0.07407407407407407,
        "bleu1": 0.08333333333333333,
        "bleu2": 0.019034674690672018,
        "bleu3": 0.01234526788340704,
        "bleu4": 0.009410489957951634,
        "bert_precision": 0.8542191982269287,
        "bert_recall": 0.8676896095275879,
        "bert_f1": 0.8609017133712769,
        "meteor": 0.06666666666666667,
        "sbert_similarity": 0.23548130691051483
      }
    },
    {
      "sample_id": 0,
      "question": "How do Melanie and Caroline describe their journey through life together?",
      "prediction": "Life's tough but it's worth it when we have things that make us happy. Let's keep motivating and helping each other out as we journey through life.",
      "reference": "An ongoing adventure of learning and growing.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.060606060606060615,
        "rouge1_f": 0.05405405405405406,
        "rouge2_f": 0.0,
        "rougeL_f": 0.05405405405405406,
        "bleu1": 0.0625,
        "bleu2": 0.014199045856176616,
        "bleu3": 0.009184193658263872,
        "bleu4": 0.006938247178254633,
        "bert_precision": 0.8456097841262817,
        "bert_recall": 0.8823357224464417,
        "bert_f1": 0.8635823726654053,
        "meteor": 0.05555555555555555,
        "sbert_similarity": 0.16717743873596191
      }
    },
    {
      "sample_id": 0,
      "question": "What happened to Melanie's son on their road trip?",
      "prediction": "my son got into an accident",
      "reference": "He got into an accident",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.7272727272727272,
        "rouge1_f": 0.7272727272727272,
        "rouge2_f": 0.6666666666666665,
        "rougeL_f": 0.7272727272727272,
        "bleu1": 0.6666666666666666,
        "bleu2": 0.6324555320336759,
        "bleu3": 0.5879493283318652,
        "bleu4": 0.5081327481546147,
        "bert_precision": 0.9562538862228394,
        "bert_recall": 0.9748107194900513,
        "bert_f1": 0.9654431343078613,
        "meteor": 0.778186274509804,
        "sbert_similarity": 0.7852286100387573
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie's son handle the accident?",
      "prediction": "We were all freaked when my son got into an accident. We were so lucky he was okay.",
      "reference": "He was scared but reassured by his family",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.16666666666666666,
        "rouge1_f": 0.15384615384615383,
        "rouge2_f": 0.08333333333333333,
        "rougeL_f": 0.15384615384615383,
        "bleu1": 0.10000000000000002,
        "bleu2": 0.07254762501100116,
        "bleu3": 0.0318985825417419,
        "bleu4": 0.020364851292391,
        "bert_precision": 0.8774306774139404,
        "bert_recall": 0.8723105192184448,
        "bert_f1": 0.8748630881309509,
        "meteor": 0.20833333333333334,
        "sbert_similarity": 0.4867149293422699
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie feel about her family after the accident?",
      "prediction": "They mean the world to me and I'm so thankful to have them.",
      "reference": "They are important and mean the world to her",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5714285714285715,
        "rouge1_f": 0.5217391304347826,
        "rouge2_f": 0.2857142857142857,
        "rougeL_f": 0.43478260869565216,
        "bleu1": 0.4,
        "bleu2": 0.29277002188455997,
        "bleu3": 0.23968792281200063,
        "bleu4": 0.18207052811092134,
        "bert_precision": 0.9114428758621216,
        "bert_recall": 0.9386458396911621,
        "bert_f1": 0.9248443245887756,
        "meteor": 0.5437352245862884,
        "sbert_similarity": 0.4780944585800171
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie's children handle the accident?",
      "prediction": "They were scared but we reassured them and explained their brother would be OK. They're tough kids.",
      "reference": "They were scared but resilient",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.3636363636363636,
        "rouge1_f": 0.3478260869565218,
        "rouge2_f": 0.2857142857142857,
        "rougeL_f": 0.3478260869565218,
        "bleu1": 0.21052631578947367,
        "bleu2": 0.1873171623163388,
        "bleu3": 0.16337776502819226,
        "bleu4": 0.12673718536830808,
        "bert_precision": 0.8778965473175049,
        "bert_recall": 0.9136024713516235,
        "bert_f1": 0.8953936696052551,
        "meteor": 0.6401209677419355,
        "sbert_similarity": 0.5933233499526978
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie feel after the accident?",
      "prediction": "I was really scared when we got into the accident. Thankfully, my son's ok and that was a reminder that life is precious and to cherish our family.",
      "reference": "Grateful and thankful for her family",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.12903225806451613,
        "rouge1_f": 0.17142857142857143,
        "rouge2_f": 0.0,
        "rougeL_f": 0.1142857142857143,
        "bleu1": 0.0625,
        "bleu2": 0.014199045856176616,
        "bleu3": 0.009184193658263872,
        "bleu4": 0.006938247178254633,
        "bert_precision": 0.8429198265075684,
        "bert_recall": 0.8544175624847412,
        "bert_f1": 0.8486297130584717,
        "meteor": 0.06097560975609757,
        "sbert_similarity": 0.2561253607273102
      }
    },
    {
      "sample_id": 0,
      "question": "What was Melanie's reaction to her children enjoying the Grand Canyon?",
      "prediction": "they enjoyed the Grand Canyon a lot!",
      "reference": "She was happy and thankful",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8625913858413696,
        "bert_recall": 0.8752247095108032,
        "bert_f1": 0.8688621520996094,
        "meteor": 0.0,
        "sbert_similarity": 0.20662693679332733
      }
    },
    {
      "sample_id": 0,
      "question": "What do Melanie's family give her?",
      "prediction": "so much joy and love",
      "reference": "Strength and motivation",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.25,
        "rouge2_f": 0.0,
        "rougeL_f": 0.25,
        "bleu1": 0.2,
        "bleu2": 0.07071067811865477,
        "bleu3": 0.05665132701906204,
        "bleu4": 0.05372849659117709,
        "bert_precision": 0.836017906665802,
        "bert_recall": 0.8752844333648682,
        "bert_f1": 0.8552007079124451,
        "meteor": 0.15625,
        "sbert_similarity": 0.1353309452533722
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie feel about her family supporting her?",
      "prediction": "their love and support really helped me through tough times.",
      "reference": "She appreciated them a lot",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8692599534988403,
        "bert_recall": 0.9059286117553711,
        "bert_f1": 0.8872155547142029,
        "meteor": 0.0,
        "sbert_similarity": 0.4095594584941864
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie do after the road trip to relax?",
      "prediction": "The kids loved it and it was a nice way to relax after the road trip.",
      "reference": "Went on a nature walk or hike",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.09523809523809523,
        "rouge1_f": 0.08695652173913043,
        "rouge2_f": 0.0,
        "rougeL_f": 0.08695652173913043,
        "bleu1": 0.0588235294117647,
        "bleu2": 0.019174124721184262,
        "bleu3": 0.014076093604378503,
        "bleu4": 0.011502783619900045,
        "bert_precision": 0.8499734997749329,
        "bert_recall": 0.8401774168014526,
        "bert_f1": 0.8450470566749573,
        "meteor": 0.06329113924050632,
        "sbert_similarity": 0.31323838233947754
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline realize after her charity race?",
      "prediction": "self-care is important",
      "reference": "self-care is important",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What are Melanie's plans for the summer with respect to adoption?",
      "prediction": "Not mentioned in the conversation",
      "reference": "researching adoption agencies",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8703113198280334,
        "bert_recall": 0.86725914478302,
        "bert_f1": 0.8687825798988342,
        "meteor": 0.0,
        "sbert_similarity": 0.010256895795464516
      }
    },
    {
      "sample_id": 0,
      "question": "What type of individuals does the adoption agency Melanie is considering support?",
      "prediction": "LGBTQ+ individuals",
      "reference": "LGBTQ+ individuals",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 0.46773514128719823,
        "bleu4": 0.316227766016838,
        "bert_precision": 1.0000001192092896,
        "bert_recall": 1.0000001192092896,
        "bert_f1": 1.0000001192092896,
        "meteor": 0.9375,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Melanie choose the adoption agency?",
      "prediction": "because of their inclusivity and support for LGBTQ+ individuals",
      "reference": "because of their inclusivity and support for LGBTQ+ individuals",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9993141289437586,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What is Melanie excited about in her adoption process?",
      "prediction": "creating a family for kids who need one",
      "reference": "creating a family for kids who need one",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9990234375,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie's necklace symbolize?",
      "prediction": "Not mentioned in the conversation",
      "reference": "love, faith, and strength",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8847731351852417,
        "bert_recall": 0.8560529947280884,
        "bert_f1": 0.8701761364936829,
        "meteor": 0.0,
        "sbert_similarity": 0.04011678695678711
      }
    },
    {
      "sample_id": 0,
      "question": "What country is Melanie's grandma from?",
      "prediction": "Sweden",
      "reference": "Sweden",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 0.9999998807907104,
        "bert_recall": 0.9999998807907104,
        "bert_f1": 0.9999998807907104,
        "meteor": 0.5,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What was grandma's gift to Melanie?",
      "prediction": "Not mentioned in the conversation",
      "reference": "necklace",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8458927273750305,
        "bert_recall": 0.8909749388694763,
        "bert_f1": 0.8678487539291382,
        "meteor": 0.0,
        "sbert_similarity": 0.17644499242305756
      }
    },
    {
      "sample_id": 0,
      "question": "What was grandpa's gift to Caroline?",
      "prediction": "necklace",
      "reference": "necklace",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 0.9999998807907104,
        "bert_recall": 0.9999998807907104,
        "bert_f1": 0.9999998807907104,
        "meteor": 0.5,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What is Caroline's hand-painted bowl a reminder of?",
      "prediction": "art and self-expression",
      "reference": "art and self-expression",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline and her family do while camping?",
      "prediction": "explored nature, roasted marshmallows, and went on a hike",
      "reference": "explored nature, roasted marshmallows, and went on a hike",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9993141289437586,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of counseling and mental health services is Melanie interested in pursuing?",
      "prediction": "Not mentioned in the conversation",
      "reference": "working with trans people, helping them accept themselves and supporting their mental health",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8718170523643494,
        "bert_recall": 0.8251791000366211,
        "bert_f1": 0.8478571772575378,
        "meteor": 0.0,
        "sbert_similarity": 0.05818859860301018
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of counseling workshop did Melanie attend recently?",
      "prediction": "Not mentioned in the conversation",
      "reference": "LGBTQ+ counseling workshop",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.880815327167511,
        "bert_recall": 0.8225635886192322,
        "bert_f1": 0.8506934642791748,
        "meteor": 0.0,
        "sbert_similarity": 0.11074965447187424
      }
    },
    {
      "sample_id": 0,
      "question": "What motivated Melanie to pursue counseling?",
      "prediction": "her own journey and the support she received, and how counseling improved her life",
      "reference": "her own journey and the support she received, and how counseling improved her life",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9998177842565598,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of place does Melanie want to create for people?",
      "prediction": "a safe and inviting place for people to grow",
      "reference": "a safe and inviting place for people to grow",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9993141289437586,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "Did Caroline make the black and white bowl in the photo?",
      "prediction": "Yes",
      "reference": "Yes",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.5,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What are the new shoes that Caroline got used for?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Running",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8501412272453308,
        "bert_recall": 0.8962053060531616,
        "bert_f1": 0.872565746307373,
        "meteor": 0.0,
        "sbert_similarity": 0.16544069349765778
      }
    },
    {
      "sample_id": 0,
      "question": "What is Caroline's reason for getting into running?",
      "prediction": "To de-stress and clear her mind",
      "reference": "To de-stress and clear her mind",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9976851851851852,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What does Caroline say running has been great for?",
      "prediction": "Her mental health",
      "reference": "Her mental health",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie see at the council meeting for adoption?",
      "prediction": "many people wanting to create loving homes for children in need",
      "reference": "many people wanting to create loving homes for children in need",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9996243425995492,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What inspired Melanie's painting for the art show?",
      "prediction": "Not mentioned in the conversation",
      "reference": "visiting an LGBTQ center and wanting to capture unity and strength",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8672130703926086,
        "bert_recall": 0.8251693844795227,
        "bert_f1": 0.8456689715385437,
        "meteor": 0.0,
        "sbert_similarity": -0.0016055628657341003
      }
    },
    {
      "sample_id": 0,
      "question": "What inspired Caroline's sculpture for the art show?",
      "prediction": "Not mentioned in the conversation",
      "reference": "visiting an LGBTQ center and wanting to capture unity and strength",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8672130703926086,
        "bert_recall": 0.8251693844795227,
        "bert_f1": 0.8456689715385437,
        "meteor": 0.0,
        "sbert_similarity": -0.0016055628657341003
      }
    },
    {
      "sample_id": 0,
      "question": "How often does Caroline go to the beach with her kids?",
      "prediction": "Not mentioned in the conversation",
      "reference": "once or twice a year",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8639419078826904,
        "bert_recall": 0.807560920715332,
        "bert_f1": 0.8348005414009094,
        "meteor": 0.0,
        "sbert_similarity": 0.053056757897138596
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline and her family see during their camping trip last year?",
      "prediction": "Perseid meteor shower",
      "reference": "Perseid meteor shower",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "How did Caroline feel while watching the meteor shower?",
      "prediction": "in awe of the universe",
      "reference": "in awe of the universe",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.996,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Caroline choose to use colors and patterns in her pottery project?",
      "prediction": "She wanted to catch the eye and make people smile.",
      "reference": "She wanted to catch the eye and make people smile.",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9995,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "Is Oscar Melanie's pet?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Yes",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8480531573295593,
        "bert_recall": 0.8904053568840027,
        "bert_f1": 0.86871337890625,
        "meteor": 0.0,
        "sbert_similarity": 0.11724157631397247
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Oscar hide his bone once?",
      "prediction": "In Melanie's slipper",
      "reference": "In Melanie's slipper",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What activity did Melanie used to do with her dad?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Horseback riding",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8533903360366821,
        "bert_recall": 0.7734709978103638,
        "bert_f1": 0.8114676475524902,
        "meteor": 0.0,
        "sbert_similarity": 0.05627931281924248
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie make for a local church?",
      "prediction": "Not mentioned in the conversation",
      "reference": "a stained glass window",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8690840005874634,
        "bert_recall": 0.8363252282142639,
        "bert_f1": 0.852389931678772,
        "meteor": 0.0,
        "sbert_similarity": 0.036170121282339096
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie find in her neighborhood during her walk?",
      "prediction": "Not mentioned in the conversation",
      "reference": "a rainbow sidewalk",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8700211048126221,
        "bert_recall": 0.8560808897018433,
        "bert_f1": 0.8629946708679199,
        "meteor": 0.0,
        "sbert_similarity": -0.048551276326179504
      }
    },
    {
      "sample_id": 0,
      "question": "Which song motivates Melanie to be courageous?",
      "prediction": "Brave by Sara Bareilles",
      "reference": "Brave by Sara Bareilles",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9921875,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What type of instrument does Caroline play?",
      "prediction": "acoustic guitar",
      "reference": "clarinet and violin",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8520889282226562,
        "bert_recall": 0.8274807929992676,
        "bert_f1": 0.8396046161651611,
        "meteor": 0.0,
        "sbert_similarity": 0.35477539896965027
      }
    },
    {
      "sample_id": 0,
      "question": "Which classical musicians does Caroline enjoy listening to?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Bach and Mozart",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8735333681106567,
        "bert_recall": 0.8278999924659729,
        "bert_f1": 0.8501047492027283,
        "meteor": 0.0,
        "sbert_similarity": 0.1029241755604744
      }
    },
    {
      "sample_id": 0,
      "question": "Who is Caroline a fan of in terms of modern music?",
      "prediction": "Ed Sheeran",
      "reference": "Ed Sheeran",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 0.46773514128719823,
        "bleu4": 0.316227766016838,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9375,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What precautionary sign did Caroline see at the caf?",
      "prediction": "A sign stating that someone is not being able to leave.",
      "reference": "A sign stating that someone is not being able to leave",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 0.9166666666666666,
        "bleu2": 0.9128709291752768,
        "bleu3": 0.9094319693204537,
        "bleu4": 0.9036020036098448,
        "bert_precision": 0.9948994517326355,
        "bert_recall": 0.9944372773170471,
        "bert_f1": 0.9946683049201965,
        "meteor": 0.9086363636363638,
        "sbert_similarity": 0.9854938387870789
      }
    },
    {
      "sample_id": 0,
      "question": "What setback did Caroline face recently?",
      "prediction": "She got hurt and had to take a break from pottery.",
      "reference": "She got hurt and had to take a break from pottery.",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9996243425995492,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What does Caroline do to keep herself busy during her pottery break?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Read a book and paint.",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8759545683860779,
        "bert_recall": 0.8547960519790649,
        "bert_f1": 0.8652459979057312,
        "meteor": 0.0,
        "sbert_similarity": 0.08983373641967773
      }
    },
    {
      "sample_id": 0,
      "question": "What was the poetry reading that Melanie attended about?",
      "prediction": "It was a transgender poetry reading where transgender people shared their stories.",
      "reference": "It was a transgender poetry reading where transgender people shared their stories.",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9997106481481481,
        "sbert_similarity": 1.000000238418579
      }
    },
    {
      "sample_id": 0,
      "question": "What happened to Caroline's son on their road trip?",
      "prediction": "He got into an accident",
      "reference": "He got into an accident",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.996,
        "sbert_similarity": 0.9999999403953552
      }
    },
    {
      "sample_id": 0,
      "question": "How did Caroline's son handle the accident?",
      "prediction": "Not mentioned in the conversation",
      "reference": "He was scared but reassured by his family",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8755667209625244,
        "bert_recall": 0.8454297780990601,
        "bert_f1": 0.8602343797683716,
        "meteor": 0.0,
        "sbert_similarity": 0.12110542505979538
      }
    },
    {
      "sample_id": 0,
      "question": "How did Caroline feel about her family after the accident?",
      "prediction": "They are important and mean the world to her",
      "reference": "They are important and mean the world to her",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9993141289437586,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "How did Caroline's children handle the accident?",
      "prediction": "They were scared but resilient.",
      "reference": "They were scared but resilient",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 0.8333333333333334,
        "bleu2": 0.816496580927726,
        "bleu3": 0.7955364837549187,
        "bleu4": 0.7598356856515925,
        "bert_precision": 0.9941954016685486,
        "bert_recall": 0.9930402040481567,
        "bert_f1": 0.9936175346374512,
        "meteor": 0.7937500000000002,
        "sbert_similarity": 0.9903228282928467
      }
    },
    {
      "sample_id": 0,
      "question": "How did Caroline feel after the accident?",
      "prediction": "Grateful and thankful for her family",
      "reference": "Grateful and thankful for her family",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9976851851851852,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What was Caroline's reaction to her children enjoying the Grand Canyon?",
      "prediction": "Not mentioned in the conversation",
      "reference": "She was happy and thankful",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8730798959732056,
        "bert_recall": 0.8435055017471313,
        "bert_f1": 0.8580379486083984,
        "meteor": 0.0,
        "sbert_similarity": 0.026393620297312737
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline do after the road trip to relax?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Went on a nature walk or hike",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8826771974563599,
        "bert_recall": 0.8326032161712646,
        "bert_f1": 0.8569092750549316,
        "meteor": 0.0,
        "sbert_similarity": 0.06870593130588531
      }
    },
    {
      "sample_id": 0,
      "question": "What does Caroline love most about camping with her family?",
      "prediction": "Being present and bonding with her family",
      "reference": "Being present and bonding with her family",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0000001192092896,
        "bert_recall": 1.0000001192092896,
        "bert_f1": 1.0000001192092896,
        "meteor": 0.9985422740524781,
        "sbert_similarity": 1.0
      }
    }
  ]
}