{
  "sample_idx": 0,
  "total_questions": 199,
  "individual_results": [
    {
      "sample_id": 0,
      "question": "When did Caroline go to the LGBTQ support group?",
      "prediction": "8 May, 2023",
      "reference": "7 May 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5,
        "bleu2": 0.12909944487358058,
        "bleu3": 0.09635409769034631,
        "bleu4": 0.09554427922043669,
        "bert_precision": 0.9594281315803528,
        "bert_recall": 0.9838892221450806,
        "bert_f1": 0.9715046882629395,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.8955165147781372
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie paint a sunrise?",
      "prediction": "last year",
      "reference": 2022,
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8694188594818115,
        "bert_recall": 0.9111441373825073,
        "bert_f1": 0.8897925615310669,
        "meteor": 0.0,
        "sbert_similarity": 0.3672372102737427
      }
    },
    {
      "sample_id": 0,
      "question": "What fields would Caroline be likely to pursue in her educaton?",
      "prediction": "counseling or working in mental health",
      "reference": "Psychology, counseling certification",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2222222222222222,
        "rouge1_f": 0.2222222222222222,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2222222222222222,
        "bleu1": 0.16666666666666669,
        "bleu2": 0.05773502691896258,
        "bleu3": 0.04506819749679463,
        "bleu4": 0.040824829046386304,
        "bert_precision": 0.830034613609314,
        "bert_recall": 0.8526803851127625,
        "bert_f1": 0.8412051796913147,
        "meteor": 0.15151515151515152,
        "sbert_similarity": 0.6807615756988525
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline research?",
      "prediction": "Researching adoption agencies — it's been a dream to have a family and give a loving home to kids who need it.",
      "reference": "Adoption agencies",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.1904761904761905,
        "rouge1_f": 0.16666666666666669,
        "rouge2_f": 0.0909090909090909,
        "rougeL_f": 0.16666666666666669,
        "bleu1": 0.08333333333333333,
        "bleu2": 0.06019292654288461,
        "bleu3": 0.026393714719473722,
        "bleu4": 0.016734480530603443,
        "bert_precision": 0.8226029872894287,
        "bert_recall": 0.9132906198501587,
        "bert_f1": 0.8655779361724854,
        "meteor": 0.4687500000000001,
        "sbert_similarity": 0.7278667688369751
      }
    },
    {
      "sample_id": 0,
      "question": "What is Caroline's identity?",
      "prediction": "Caroline shares her transgender journey.",
      "reference": "Transgender woman",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.28571428571428575,
        "rouge1_f": 0.28571428571428575,
        "rouge2_f": 0.0,
        "rougeL_f": 0.28571428571428575,
        "bleu1": 0.16666666666666669,
        "bleu2": 0.05773502691896258,
        "bleu3": 0.04506819749679463,
        "bleu4": 0.040824829046386304,
        "bert_precision": 0.8729468584060669,
        "bert_recall": 0.8757948875427246,
        "bert_f1": 0.8743685483932495,
        "meteor": 0.21739130434782608,
        "sbert_similarity": 0.5824557542800903
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie run a charity race?",
      "prediction": "last Saturday on 25 May, 2023",
      "reference": "The sunday before 25 May 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.5,
        "rouge2_f": 0.4000000000000001,
        "rougeL_f": 0.5,
        "bleu1": 0.42857142857142855,
        "bleu2": 0.26726124191242434,
        "bleu3": 0.11511121735118796,
        "bleu4": 0.07730551756939454,
        "bert_precision": 0.9261570572853088,
        "bert_recall": 0.9238791465759277,
        "bert_f1": 0.9250167608261108,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.8712271451950073
      }
    },
    {
      "sample_id": 0,
      "question": "When is Melanie planning on going camping?",
      "prediction": "next month",
      "reference": "June 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8738223314285278,
        "bert_recall": 0.8416210412979126,
        "bert_f1": 0.8574194312095642,
        "meteor": 0.0,
        "sbert_similarity": 0.5679936408996582
      }
    },
    {
      "sample_id": 0,
      "question": "What is Caroline's relationship status?",
      "prediction": "Caroline, awesome news that you two are getting along!",
      "reference": "Single",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7976087927818298,
        "bert_recall": 0.8368960618972778,
        "bert_f1": 0.8167802691459656,
        "meteor": 0.0,
        "sbert_similarity": 0.17531538009643555
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline give a speech at a school?",
      "prediction": "9 June, 2023",
      "reference": "The week before 9 June 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5714285714285715,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.45489799478447507,
        "bleu2": 0.30326532985631666,
        "bleu3": 0.14283448174223617,
        "bleu4": 0.11404605374835301,
        "bert_precision": 0.927920937538147,
        "bert_recall": 0.8829274773597717,
        "bert_f1": 0.9048652052879333,
        "meteor": 0.17543859649122806,
        "sbert_similarity": 0.8582826256752014
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline meet up with her friends, family, and mentors?",
      "prediction": "last week from 9 June 2023",
      "reference": "The week before 9 June 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.4000000000000001,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.6666666666666666,
        "bleu2": 0.5163977794943222,
        "bleu3": 0.4091569047284194,
        "bleu4": 0.21711852081087685,
        "bert_precision": 0.9625175595283508,
        "bert_recall": 0.9625175595283508,
        "bert_f1": 0.9625175595283508,
        "meteor": 0.625,
        "sbert_similarity": 0.8749597668647766
      }
    },
    {
      "sample_id": 0,
      "question": "How long has Caroline had her current group of friends for?",
      "prediction": "since her transition three years ago",
      "reference": "4 years",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.25,
        "rouge2_f": 0.0,
        "rougeL_f": 0.25,
        "bleu1": 0.16666666666666669,
        "bleu2": 0.05773502691896258,
        "bleu3": 0.04506819749679463,
        "bleu4": 0.040824829046386304,
        "bert_precision": 0.8464937210083008,
        "bert_recall": 0.8919313549995422,
        "bert_f1": 0.8686187863349915,
        "meteor": 0.20833333333333334,
        "sbert_similarity": 0.5051943063735962
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Caroline move from 4 years ago?",
      "prediction": "Caroline shares her own journey, the struggles I had and how much I've developed since coming out.",
      "reference": "Sweden",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8093576431274414,
        "bert_recall": 0.8676226139068604,
        "bert_f1": 0.8374779224395752,
        "meteor": 0.0,
        "sbert_similarity": 0.045841362327337265
      }
    },
    {
      "sample_id": 0,
      "question": "How long ago was Caroline's 18th birthday?",
      "prediction": "about 5 months ago",
      "reference": "10 years ago",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.28571428571428575,
        "rouge1_f": 0.28571428571428575,
        "rouge2_f": 0.0,
        "rougeL_f": 0.28571428571428575,
        "bleu1": 0.25,
        "bleu2": 0.09128709291752769,
        "bleu3": 0.07665320007195604,
        "bleu4": 0.08034284189446518,
        "bert_precision": 0.8926935791969299,
        "bert_recall": 0.9124635457992554,
        "bert_f1": 0.9024702906608582,
        "meteor": 0.16129032258064518,
        "sbert_similarity": 0.7105165123939514
      }
    },
    {
      "sample_id": 0,
      "question": "What career path has Caroline decided to persue?",
      "prediction": "Gonna continue my edu and check out career options, which is pretty exciting!",
      "reference": "counseling or mental health for Transgender people",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.809053897857666,
        "bert_recall": 0.7935500144958496,
        "bert_f1": 0.8012269735336304,
        "meteor": 0.0,
        "sbert_similarity": 0.051940012723207474
      }
    },
    {
      "sample_id": 0,
      "question": "Would Caroline still want to pursue counseling as a career if she hadn't received support growing up?",
      "prediction": "It made me realize how important it is for others to have a support system.",
      "reference": "Likely no",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8260351419448853,
        "bert_recall": 0.8123531341552734,
        "bert_f1": 0.8191370368003845,
        "meteor": 0.0,
        "sbert_similarity": 0.07408450543880463
      }
    },
    {
      "sample_id": 0,
      "question": "What activities does Melanie partake in?",
      "prediction": "camping with family",
      "reference": "pottery, camping, painting, swimming",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.28571428571428575,
        "rouge1_f": 0.28571428571428575,
        "rouge2_f": 0.0,
        "rougeL_f": 0.28571428571428575,
        "bleu1": 0.08786571270524224,
        "bleu2": 0.03403024420100487,
        "bleu3": 0.031926460841892726,
        "bleu4": 0.029950417327249696,
        "bert_precision": 0.8320567607879639,
        "bert_recall": 0.8174170255661011,
        "bert_f1": 0.8246719241142273,
        "meteor": 0.0,
        "sbert_similarity": 0.42267897725105286
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie sign up for a pottery class?",
      "prediction": "yesterday, 2 July 2023",
      "reference": "2 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8571428571428571,
        "rouge1_f": 0.8571428571428571,
        "rouge2_f": 0.8,
        "rougeL_f": 0.8571428571428571,
        "bleu1": 0.6,
        "bleu2": 0.5477225575051662,
        "bleu3": 0.4677351412871982,
        "bleu4": 0.26591479484724945,
        "bert_precision": 0.9257256984710693,
        "bert_recall": 0.9683472514152527,
        "bert_f1": 0.9465569257736206,
        "meteor": 0.9498207885304659,
        "sbert_similarity": 0.8997114896774292
      }
    },
    {
      "sample_id": 0,
      "question": "When is Caroline going to the transgender conference?",
      "prediction": "this month",
      "reference": "July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8705527782440186,
        "bert_recall": 0.8371520042419434,
        "bert_f1": 0.853525698184967,
        "meteor": 0.0,
        "sbert_similarity": 0.48674145340919495
      }
    },
    {
      "sample_id": 0,
      "question": "Where has Melanie camped?",
      "prediction": "in the mountains",
      "reference": "beach, mountains, forest",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.3333333333333333,
        "rouge1_f": 0.3333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.3333333333333333,
        "bleu1": 0.17113903967753066,
        "bleu2": 0.06628186505570068,
        "bleu3": 0.0621842545921536,
        "bleu4": 0.05833544737207805,
        "bert_precision": 0.904266357421875,
        "bert_recall": 0.8439556360244751,
        "bert_f1": 0.8730707168579102,
        "meteor": 0.0,
        "sbert_similarity": 0.6089510917663574
      }
    },
    {
      "sample_id": 0,
      "question": "What do Melanie's kids like?",
      "prediction": "My kids are so excited about summer break!",
      "reference": "dinosaurs, nature",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8026418685913086,
        "bert_recall": 0.7877829074859619,
        "bert_f1": 0.7951429486274719,
        "meteor": 0.0,
        "sbert_similarity": 0.062211863696575165
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go to the museum?",
      "prediction": "not mentioned",
      "reference": "5 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8378820419311523,
        "bert_recall": 0.8006629943847656,
        "bert_f1": 0.8188498020172119,
        "meteor": 0.0,
        "sbert_similarity": 0.14808136224746704
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline have a picnic?",
      "prediction": "not mentioned",
      "reference": "The week before 6 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8298377990722656,
        "bert_recall": 0.7741222381591797,
        "bert_f1": 0.801012396812439,
        "meteor": 0.0,
        "sbert_similarity": 0.1857881397008896
      }
    },
    {
      "sample_id": 0,
      "question": "Would Caroline likely have Dr. Seuss books on her bookshelf?",
      "prediction": "I've got lots of kids' books- classics, stories from different cultures, educational books, all of that.",
      "reference": "Yes, since she collects classic children's books",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.09090909090909091,
        "rouge1_f": 0.15999999999999998,
        "rouge2_f": 0.0,
        "rougeL_f": 0.15999999999999998,
        "bleu1": 0.0909090909090909,
        "bleu2": 0.020806259464411975,
        "bleu3": 0.013510398157576722,
        "bleu4": 0.010331208012220438,
        "bert_precision": 0.8653687238693237,
        "bert_recall": 0.8898049592971802,
        "bert_f1": 0.877416729927063,
        "meteor": 0.0,
        "sbert_similarity": 0.5071794390678406
      }
    },
    {
      "sample_id": 0,
      "question": "What books has Melanie read?",
      "prediction": "reading that book you recommended a while ago",
      "reference": "\"Nothing is Impossible\", \"Charlotte's Web\"",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8435624837875366,
        "bert_recall": 0.8262186050415039,
        "bert_f1": 0.8348004817962646,
        "meteor": 0.0,
        "sbert_similarity": 0.18770763278007507
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie do to destress?",
      "prediction": "I've been running farther to de-stress, which has been great for my headspace.",
      "reference": "Running, pottery",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.14285714285714285,
        "rouge1_f": 0.11764705882352941,
        "rouge2_f": 0.0,
        "rougeL_f": 0.11764705882352941,
        "bleu1": 0.12500000000000003,
        "bleu2": 0.028867513459481287,
        "bleu3": 0.018864614597621485,
        "bleu4": 0.014628063653657535,
        "bert_precision": 0.8261620998382568,
        "bert_recall": 0.8199148178100586,
        "bert_f1": 0.8230265974998474,
        "meteor": 0.0,
        "sbert_similarity": 0.23419292271137238
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline go to the LGBTQ conference?",
      "prediction": "10 July, 2023",
      "reference": "10 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 0.75,
        "bleu2": 0.49999999999999994,
        "bleu3": 0.23549424823785386,
        "bleu4": 0.1880301546543197,
        "bert_precision": 0.9584363102912903,
        "bert_recall": 0.9826313853263855,
        "bert_f1": 0.9703831076622009,
        "meteor": 0.3333333333333333,
        "sbert_similarity": 0.9868618845939636
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie read the book \"nothing is impossible\"?",
      "prediction": "tough, but I'm doing ok. Been reading that book you recommended a while ago",
      "reference": 2022,
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8080123662948608,
        "bert_recall": 0.8358606100082397,
        "bert_f1": 0.8217006325721741,
        "meteor": 0.0,
        "sbert_similarity": 0.08193553984165192
      }
    },
    {
      "sample_id": 0,
      "question": "Would Caroline pursue writing as a career option?",
      "prediction": "Gonna continue my edu and check out career options, which is pretty exciting!",
      "reference": "LIkely no; though she likes reading, she wants to be a counselor",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0.0625,
        "bleu2": 0.02041241452319315,
        "bleu3": 0.015007489164383502,
        "bleu4": 0.012300686288463768,
        "bert_precision": 0.8412824869155884,
        "bert_recall": 0.8411259651184082,
        "bert_f1": 0.8412042260169983,
        "meteor": 0.04132231404958677,
        "sbert_similarity": 0.2692645788192749
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline go to the adoption meeting?",
      "prediction": "week of 23 August, 2023",
      "reference": "The friday before 15 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.1818181818181818,
        "rouge1_f": 0.1818181818181818,
        "rouge2_f": 0.0,
        "rougeL_f": 0.1818181818181818,
        "bleu1": 0.16666666666666669,
        "bleu2": 0.05773502691896258,
        "bleu3": 0.04506819749679463,
        "bleu4": 0.040824829046386304,
        "bert_precision": 0.9105764627456665,
        "bert_recall": 0.8803166151046753,
        "bert_f1": 0.8951908946037292,
        "meteor": 0.0847457627118644,
        "sbert_similarity": 0.7885981202125549
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go to the pottery workshop?",
      "prediction": "Last Fri, 14 July 2023.",
      "reference": "The Friday before 15 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.3636363636363636,
        "rouge1_f": 0.3636363636363636,
        "rouge2_f": 0.22222222222222224,
        "rougeL_f": 0.3636363636363636,
        "bleu1": 0.2857142857142857,
        "bleu2": 0.2182178902359924,
        "bleu3": 0.1006949130683619,
        "bleu4": 0.06985342056580097,
        "bert_precision": 0.9500450491905212,
        "bert_recall": 0.9305702447891235,
        "bert_f1": 0.9402068257331848,
        "meteor": 0.0847457627118644,
        "sbert_similarity": 0.6620309352874756
      }
    },
    {
      "sample_id": 0,
      "question": "Would Melanie be considered a member of the LGBTQ community?",
      "prediction": "The context does not explicitly state whether Melanie identifies as a member of the LGBTQ community.",
      "reference": "Likely no, she does not refer to herself as part of it",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2962962962962963,
        "rouge1_f": 0.28571428571428575,
        "rouge2_f": 0.07692307692307691,
        "rougeL_f": 0.28571428571428575,
        "bleu1": 0.23529411764705885,
        "bleu2": 0.12126781251816653,
        "bleu3": 0.047551250592422656,
        "bleu4": 0.028927969316143217,
        "bert_precision": 0.875496506690979,
        "bert_recall": 0.8695504069328308,
        "bert_f1": 0.8725133538246155,
        "meteor": 0.2545362903225807,
        "sbert_similarity": 0.5297941565513611
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go camping in June?",
      "prediction": "last week on 27 June, 2023",
      "reference": "The week before 27 June 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.4000000000000001,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5714285714285714,
        "bleu2": 0.3086066999241838,
        "bleu3": 0.12657485247324374,
        "bleu4": 0.08307018474412793,
        "bert_precision": 0.9519211649894714,
        "bert_recall": 0.951376736164093,
        "bert_f1": 0.9516488909721375,
        "meteor": 0.25,
        "sbert_similarity": 0.8657471537590027
      }
    },
    {
      "sample_id": 0,
      "question": "What LGBTQ+ events has Caroline participated in?",
      "prediction": "LGBTQ+ pride parade, LGBTQ conference, LGBTQ art show.",
      "reference": "Pride parade, school speech, support group",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.30769230769230765,
        "rouge1_f": 0.28571428571428575,
        "rouge2_f": 0.16666666666666666,
        "rougeL_f": 0.28571428571428575,
        "bleu1": 0.36363636363636365,
        "bleu2": 0.26967994498529685,
        "bleu3": 0.20392012162530065,
        "bleu4": 0.10025157431478134,
        "bert_precision": 0.848969578742981,
        "bert_recall": 0.88850998878479,
        "bert_f1": 0.8682898283004761,
        "meteor": 0.30241935483870974,
        "sbert_similarity": 0.6340700387954712
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline go to a pride parade during the summer?",
      "prediction": "last week on 3 July, 2023",
      "reference": "The week before 3 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.4000000000000001,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5714285714285714,
        "bleu2": 0.3086066999241838,
        "bleu3": 0.12657485247324374,
        "bleu4": 0.08307018474412793,
        "bert_precision": 0.9398698806762695,
        "bert_recall": 0.9500017166137695,
        "bert_f1": 0.944908618927002,
        "meteor": 0.25,
        "sbert_similarity": 0.8780369758605957
      }
    },
    {
      "sample_id": 0,
      "question": "What events has Caroline participated in to help children?",
      "prediction": "I'm researching adoption agencies — it's been a dream to have a family and give a loving home to kids who need it.",
      "reference": "Mentoring program, school speech",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8212481141090393,
        "bert_recall": 0.8266173601150513,
        "bert_f1": 0.8239239454269409,
        "meteor": 0.0,
        "sbert_similarity": 0.234554260969162
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go camping in July?",
      "prediction": "two weekends ago",
      "reference": "two weekends before 17 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4444444444444444,
        "rouge1_f": 0.4444444444444444,
        "rouge2_f": 0.28571428571428575,
        "rougeL_f": 0.4444444444444444,
        "bleu1": 0.24525296078096154,
        "bleu2": 0.21239529438966132,
        "bleu3": 0.11974448045963429,
        "bleu4": 0.08839449202722564,
        "bert_precision": 0.832532525062561,
        "bert_recall": 0.8024148941040039,
        "bert_f1": 0.8171963095664978,
        "meteor": 0.3289473684210526,
        "sbert_similarity": 0.5797645449638367
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline join a mentorship program?",
      "prediction": "last weekend on 17 July, 2023",
      "reference": "The weekend before 17 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.4000000000000001,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5714285714285714,
        "bleu2": 0.3086066999241838,
        "bleu3": 0.12657485247324374,
        "bleu4": 0.08307018474412793,
        "bert_precision": 0.9435288906097412,
        "bert_recall": 0.9519094228744507,
        "bert_f1": 0.9477006196975708,
        "meteor": 0.25,
        "sbert_similarity": 0.8952682018280029
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie paint recently?",
      "prediction": "a painting of a sunset with a pink sky inspired by the sunsets",
      "reference": "sunset",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.16666666666666669,
        "rouge1_f": 0.14285714285714288,
        "rouge2_f": 0.0,
        "rougeL_f": 0.14285714285714288,
        "bleu1": 0.07692307692307693,
        "bleu2": 0.025318484177091663,
        "bleu3": 0.018733084686676876,
        "bleu4": 0.01553712569276035,
        "bert_precision": 0.786596417427063,
        "bert_recall": 0.8505093455314636,
        "bert_f1": 0.817305326461792,
        "meteor": 0.22727272727272732,
        "sbert_similarity": 0.613101601600647
      }
    },
    {
      "sample_id": 0,
      "question": "What activities has Melanie done with her family?",
      "prediction": "played games, ate good food, and just hung out together; went camping in the mountains; spent time together at the beach",
      "reference": "Pottery, painting, camping, museum, swimming, hiking",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.07692307692307691,
        "rouge1_f": 0.07407407407407407,
        "rouge2_f": 0.0,
        "rougeL_f": 0.07407407407407407,
        "bleu1": 0.12000000000000001,
        "bleu2": 0.022360679774997897,
        "bleu3": 0.013529754476103547,
        "bleu4": 0.009970222994544455,
        "bert_precision": 0.8343892693519592,
        "bert_recall": 0.8313767313957214,
        "bert_f1": 0.8328803181648254,
        "meteor": 0.0,
        "sbert_similarity": 0.3735466003417969
      }
    },
    {
      "sample_id": 0,
      "question": "In what ways is Caroline participating in the LGBTQ community?",
      "prediction": "I just joined a new LGBTQ activist group, I'm meeting so many cool people who are as passionate as I am about rights and community support, and I talked about my transgender journey and encouraged students to get involved in the LGBTQ community.",
      "reference": "Joining activist group, going to pride parades, participating in an art show, mentoring program",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.16326530612244897,
        "rouge1_f": 0.17241379310344826,
        "rouge2_f": 0.03571428571428571,
        "rougeL_f": 0.17241379310344826,
        "bleu1": 0.12765957446808512,
        "bleu2": 0.07450111597299126,
        "bleu3": 0.0512940870003452,
        "bleu4": 0.02300991908919148,
        "bert_precision": 0.8408874273300171,
        "bert_recall": 0.8506088852882385,
        "bert_f1": 0.8457202315330505,
        "meteor": 0.25230111768573305,
        "sbert_similarity": 0.6109696626663208
      }
    },
    {
      "sample_id": 0,
      "question": "How many times has Melanie gone to the beach in 2023?",
      "prediction": "usually only once or twice a year",
      "reference": 2,
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7833176851272583,
        "bert_recall": 0.8847258687019348,
        "bert_f1": 0.8309392333030701,
        "meteor": 0.0,
        "sbert_similarity": 0.17895732820034027
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline join a new activist group?",
      "prediction": "last Tues, 20 July, 2023",
      "reference": "The Tuesday before 20 July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5454545454545454,
        "rouge1_f": 0.5454545454545454,
        "rouge2_f": 0.4444444444444445,
        "rougeL_f": 0.5454545454545454,
        "bleu1": 0.42857142857142855,
        "bleu2": 0.26726124191242434,
        "bleu3": 0.11511121735118796,
        "bleu4": 0.07730551756939454,
        "bert_precision": 0.9173559546470642,
        "bert_recall": 0.9167336225509644,
        "bert_f1": 0.9170446991920471,
        "meteor": 0.1694915254237288,
        "sbert_similarity": 0.7121883630752563
      }
    },
    {
      "sample_id": 0,
      "question": "Would Melanie be more interested in going to a national park or a theme park?",
      "prediction": "Melanie enjoys outdoor activities and family time, as indicated by her conversations about camping and exploring nature.",
      "reference": "National park; she likes the outdoors",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.08695652173913045,
        "rouge2_f": 0.0,
        "rougeL_f": 0.08695652173913045,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.866499125957489,
        "bert_recall": 0.9010094404220581,
        "bert_f1": 0.8834173679351807,
        "meteor": 0.07042253521126761,
        "sbert_similarity": 0.5823978185653687
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of art does Caroline make?",
      "prediction": "Caroline's art is about expressing her trans experience.",
      "reference": "abstract art",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2,
        "rouge1_f": 0.1818181818181818,
        "rouge2_f": 0.0,
        "rougeL_f": 0.1818181818181818,
        "bleu1": 0.10000000000000002,
        "bleu2": 0.03333333333333335,
        "bleu3": 0.024950558772614845,
        "bleu4": 0.021105340631872645,
        "bert_precision": 0.8517217636108398,
        "bert_recall": 0.8896167278289795,
        "bert_f1": 0.8702569007873535,
        "meteor": 0.19230769230769235,
        "sbert_similarity": 0.39067336916923523
      }
    },
    {
      "sample_id": 0,
      "question": "When is Melanie's daughter's birthday?",
      "prediction": "Last night was amazing! We celebrated my daughter's birthday on 14 August, 2023.",
      "reference": "13 August",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.13333333333333336,
        "rouge1_f": 0.125,
        "rouge2_f": 0.0,
        "rougeL_f": 0.125,
        "bleu1": 0.0588235294117647,
        "bleu2": 0.019174124721184262,
        "bleu3": 0.014076093604378503,
        "bleu4": 0.011502783619900045,
        "bert_precision": 0.8342491388320923,
        "bert_recall": 0.8856385350227356,
        "bert_f1": 0.8591760993003845,
        "meteor": 0.0,
        "sbert_similarity": 0.45030805468559265
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline attend a pride parade in August?",
      "prediction": "Last Friday, 11 August 2023.",
      "reference": "The Friday before 14 August 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5454545454545454,
        "rouge1_f": 0.5454545454545454,
        "rouge2_f": 0.22222222222222224,
        "rougeL_f": 0.5454545454545454,
        "bleu1": 0.42857142857142855,
        "bleu2": 0.26726124191242434,
        "bleu3": 0.11511121735118796,
        "bleu4": 0.07730551756939454,
        "bert_precision": 0.9570767879486084,
        "bert_recall": 0.9393693208694458,
        "bert_f1": 0.9481403827667236,
        "meteor": 0.0847457627118644,
        "sbert_similarity": 0.8430665731430054
      }
    },
    {
      "sample_id": 0,
      "question": "Would Melanie be considered an ally to the transgender community?",
      "prediction": "Yes, Melanie expresses support and encouragement for Caroline's journey and advocacy for the trans community.",
      "reference": "Yes, she is supportive",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.11764705882352941,
        "rouge1_f": 0.2,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2,
        "bleu1": 0.11111111111111109,
        "bleu2": 0.08084520834544433,
        "bleu3": 0.035619862080836485,
        "bleu4": 0.02284411468856457,
        "bert_precision": 0.8644393682479858,
        "bert_recall": 0.9041561484336853,
        "bert_f1": 0.8838518857955933,
        "meteor": 0.19607843137254904,
        "sbert_similarity": 0.5013671517372131
      }
    },
    {
      "sample_id": 0,
      "question": "Who supports Caroline when she has a negative experience?",
      "prediction": "the help I got from friends, family and people I looked up to was invaluable.",
      "reference": "Her mentors, family, and friends",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.3157894736842105,
        "rouge1_f": 0.3,
        "rouge2_f": 0.11111111111111112,
        "rougeL_f": 0.2,
        "bleu1": 0.23529411764705885,
        "bleu2": 0.12126781251816653,
        "bleu3": 0.047551250592422656,
        "bleu4": 0.028927969316143217,
        "bert_precision": 0.8728057742118835,
        "bert_recall": 0.9062387347221375,
        "bert_f1": 0.8892080783843994,
        "meteor": 0.08333333333333336,
        "sbert_similarity": 0.3344835042953491
      }
    },
    {
      "sample_id": 0,
      "question": "What types of pottery have Melanie and her kids made?",
      "prediction": "they all made our own pots",
      "reference": "bowls, cup",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8443215489387512,
        "bert_recall": 0.8551404476165771,
        "bert_f1": 0.8496966361999512,
        "meteor": 0.0,
        "sbert_similarity": 0.2735532224178314
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline and Melanie go to a pride fesetival together?",
      "prediction": "last year",
      "reference": 2022,
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8694188594818115,
        "bert_recall": 0.9111441373825073,
        "bert_f1": 0.8897925615310669,
        "meteor": 0.0,
        "sbert_similarity": 0.3672372102737427
      }
    },
    {
      "sample_id": 0,
      "question": "What would Caroline's political leaning likely be?",
      "prediction": "supporting the LGBTQ community and advocating for inclusion",
      "reference": "Liberal",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7917811870574951,
        "bert_recall": 0.849275529384613,
        "bert_f1": 0.8195211887359619,
        "meteor": 0.0,
        "sbert_similarity": 0.25190961360931396
      }
    },
    {
      "sample_id": 0,
      "question": "What has Melanie painted?",
      "prediction": "a painting of a sunset with a palm tree, inspired by the sunsets",
      "reference": "Horse, sunset, sunrise",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.14285714285714288,
        "rouge1_f": 0.125,
        "rouge2_f": 0.0,
        "rougeL_f": 0.125,
        "bleu1": 0.14285714285714285,
        "bleu2": 0.033149677206589796,
        "bleu3": 0.021746357799665227,
        "bleu4": 0.0169861974906263,
        "bert_precision": 0.8441637754440308,
        "bert_recall": 0.8676645755767822,
        "bert_f1": 0.8557528853416443,
        "meteor": 0.0,
        "sbert_similarity": 0.45792075991630554
      }
    },
    {
      "sample_id": 0,
      "question": "What are Melanie's pets' names?",
      "prediction": "Luna and Oliver",
      "reference": "Oliver, Luna, Bailey",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.3333333333333333,
        "bleu1": 0.3422780793550613,
        "bleu2": 0.09373671250115519,
        "bleu3": 0.07816643970700751,
        "bleu4": 0.069372929071742,
        "bert_precision": 0.9074835181236267,
        "bert_recall": 0.8730452060699463,
        "bert_f1": 0.8899312615394592,
        "meteor": 0.0,
        "sbert_similarity": 0.8309195041656494
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline apply to adoption agencies?",
      "prediction": "3:31 pm on 23 August, 2023",
      "reference": "The week of 23 August 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.4615384615384615,
        "rouge2_f": 0.3636363636363636,
        "rougeL_f": 0.4615384615384615,
        "bleu1": 0.42857142857142855,
        "bleu2": 0.26726124191242434,
        "bleu3": 0.11511121735118796,
        "bleu4": 0.07730551756939454,
        "bert_precision": 0.8762966990470886,
        "bert_recall": 0.8888362050056458,
        "bert_f1": 0.88252192735672,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.7408578991889954
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline draw a self-portrait?",
      "prediction": "last week on 23 August, 2023",
      "reference": "The week before 23 August 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.4000000000000001,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5714285714285714,
        "bleu2": 0.3086066999241838,
        "bleu3": 0.12657485247324374,
        "bleu4": 0.08307018474412793,
        "bert_precision": 0.9407691955566406,
        "bert_recall": 0.9499505162239075,
        "bert_f1": 0.9453375935554504,
        "meteor": 0.25,
        "sbert_similarity": 0.8732798099517822
      }
    },
    {
      "sample_id": 0,
      "question": "What subject have Caroline and Melanie both painted?",
      "prediction": "painting",
      "reference": "Sunsets",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8751157522201538,
        "bert_recall": 0.8036508560180664,
        "bert_f1": 0.8378621935844421,
        "meteor": 0.0,
        "sbert_similarity": 0.2805110216140747
      }
    },
    {
      "sample_id": 0,
      "question": "What symbols are important to Caroline?",
      "prediction": "love, faith, strength, courage, and resilience",
      "reference": "Rainbow flag, transgender symbol",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0.10000000000000002,
        "bleu2": 0.03333333333333335,
        "bleu3": 0.024950558772614845,
        "bleu4": 0.021105340631872645,
        "bert_precision": 0.8275966048240662,
        "bert_recall": 0.8361068964004517,
        "bert_f1": 0.8318299651145935,
        "meteor": 0.0,
        "sbert_similarity": 0.12641161680221558
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline encounter people on a hike and have a negative experience?",
      "prediction": "1:33 pm on 25 August, 2023",
      "reference": "The week before 25 August 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.4615384615384615,
        "rouge2_f": 0.3636363636363636,
        "rougeL_f": 0.4615384615384615,
        "bleu1": 0.42857142857142855,
        "bleu2": 0.26726124191242434,
        "bleu3": 0.11511121735118796,
        "bleu4": 0.07730551756939454,
        "bert_precision": 0.8786819577217102,
        "bert_recall": 0.8855028748512268,
        "bert_f1": 0.8820792436599731,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.7329950928688049
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie make a plate in pottery class?",
      "prediction": "25 August, 2023",
      "reference": "24 August 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5,
        "bleu2": 0.12909944487358058,
        "bleu3": 0.09635409769034631,
        "bleu4": 0.09554427922043669,
        "bert_precision": 0.9609243869781494,
        "bert_recall": 0.9851833581924438,
        "bert_f1": 0.9729026556015015,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.9536036252975464
      }
    },
    {
      "sample_id": 0,
      "question": "Would Caroline be considered religious?",
      "prediction": "The content mentions a necklace with a cross and a heart, which could suggest a connection to religious themes.",
      "reference": "Somewhat, but not extremely religious",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.09523809523809523,
        "rouge1_f": 0.08333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.08333333333333333,
        "bleu1": 0.09523809523809525,
        "bleu2": 0.02182178902359924,
        "bleu3": 0.0141800886003256,
        "bleu4": 0.010862721615727716,
        "bert_precision": 0.8419584035873413,
        "bert_recall": 0.8363639116287231,
        "bert_f1": 0.8391518592834473,
        "meteor": 0.078125,
        "sbert_similarity": 0.3255873918533325
      }
    },
    {
      "sample_id": 0,
      "question": "What instruments does Melanie play?",
      "prediction": "I play clarinet!",
      "reference": "clarinet and violin",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.3333333333333333,
        "rouge1_f": 0.3333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.3333333333333333,
        "bleu1": 0.25,
        "bleu2": 0.09128709291752769,
        "bleu3": 0.07665320007195604,
        "bleu4": 0.08034284189446518,
        "bert_precision": 0.862211287021637,
        "bert_recall": 0.86649489402771,
        "bert_f1": 0.8643478155136108,
        "meteor": 0.0,
        "sbert_similarity": 0.7264347076416016
      }
    },
    {
      "sample_id": 0,
      "question": "What musical artists/bands has Melanie seen?",
      "prediction": "the pic was from a show I went to",
      "reference": "Summer Sounds, Matt Patterson",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8301588296890259,
        "bert_recall": 0.8347885608673096,
        "bert_f1": 0.832467257976532,
        "meteor": 0.0,
        "sbert_similarity": 0.09366821497678757
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go to the park?",
      "prediction": "28 August, 2023",
      "reference": "27 August 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5,
        "bleu2": 0.12909944487358058,
        "bleu3": 0.09635409769034631,
        "bleu4": 0.09554427922043669,
        "bert_precision": 0.961275577545166,
        "bert_recall": 0.985350489616394,
        "bert_f1": 0.9731642007827759,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.9726508259773254
      }
    },
    {
      "sample_id": 0,
      "question": "When is Caroline's youth center putting on a talent show?",
      "prediction": "next month from 28 August, 2023",
      "reference": "September 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.25,
        "rouge2_f": 0.0,
        "rougeL_f": 0.25,
        "bleu1": 0.14285714285714285,
        "bleu2": 0.048795003647426664,
        "bleu3": 0.037468614372419724,
        "bleu4": 0.033031643180138064,
        "bert_precision": 0.8200242519378662,
        "bert_recall": 0.9160984754562378,
        "bert_f1": 0.8654030561447144,
        "meteor": 0.20833333333333334,
        "sbert_similarity": 0.7289587259292603
      }
    },
    {
      "sample_id": 0,
      "question": "Would Melanie likely enjoy the song \"The Four Seasons\" by Vivaldi?",
      "prediction": "I'm a fan of both classical like Bach and Mozart",
      "reference": "Yes; it's classical music",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.14285714285714288,
        "rouge1_f": 0.12500000000000003,
        "rouge2_f": 0.0,
        "rougeL_f": 0.12500000000000003,
        "bleu1": 0.0909090909090909,
        "bleu2": 0.03015113445777637,
        "bleu3": 0.022461584318318094,
        "bleu4": 0.018850319022747353,
        "bert_precision": 0.8566728830337524,
        "bert_recall": 0.8774058818817139,
        "bert_f1": 0.8669154047966003,
        "meteor": 0.10869565217391304,
        "sbert_similarity": 0.5529869794845581
      }
    },
    {
      "sample_id": 0,
      "question": "What are some changes Caroline has faced during her transition journey?",
      "prediction": "Transitioning wasn't easy and acceptance wasn't either, but the help I got from friends, family and people I looked up to was invaluable.",
      "reference": "Changes to her body, losing unsupportive friends",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.14814814814814817,
        "rouge1_f": 0.125,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0625,
        "bleu1": 0.10714285714285714,
        "bleu2": 0.01992047682223989,
        "bleu3": 0.012039171932923394,
        "bleu4": 0.008839374326825921,
        "bert_precision": 0.8465014100074768,
        "bert_recall": 0.8606994152069092,
        "bert_f1": 0.8535414338111877,
        "meteor": 0.05813953488372092,
        "sbert_similarity": 0.15646661818027496
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie do with her family on hikes?",
      "prediction": "We explored nature, roasted marshmallows around the campfire and even went on a hike.",
      "reference": "Roast marshmallows, tell stories",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.11111111111111112,
        "rouge1_f": 0.22222222222222224,
        "rouge2_f": 0.125,
        "rougeL_f": 0.22222222222222224,
        "bleu1": 0.12500000000000003,
        "bleu2": 0.028867513459481287,
        "bleu3": 0.018864614597621485,
        "bleu4": 0.014628063653657535,
        "bert_precision": 0.8740320205688477,
        "bert_recall": 0.8853223323822021,
        "bert_f1": 0.8796409368515015,
        "meteor": 0.1,
        "sbert_similarity": 0.6628168225288391
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline go biking with friends?",
      "prediction": "last weekend, 13 September 2023",
      "reference": "The weekend before 13 September 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.7272727272727272,
        "rouge1_f": 0.7272727272727272,
        "rouge2_f": 0.4444444444444445,
        "rougeL_f": 0.7272727272727272,
        "bleu1": 0.6666666666666666,
        "bleu2": 0.5163977794943222,
        "bleu3": 0.4091569047284194,
        "bleu4": 0.21711852081087685,
        "bert_precision": 0.9573115110397339,
        "bert_recall": 0.9493043422698975,
        "bert_f1": 0.953291118144989,
        "meteor": 0.4990583804143125,
        "sbert_similarity": 0.9144020080566406
      }
    },
    {
      "sample_id": 0,
      "question": "How long has Melanie been practicing art?",
      "prediction": "Seven years now.",
      "reference": "Since 2016",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8721544146537781,
        "bert_recall": 0.8533461093902588,
        "bert_f1": 0.8626477122306824,
        "meteor": 0.0,
        "sbert_similarity": 0.49278581142425537
      }
    },
    {
      "sample_id": 0,
      "question": "What personality traits might Melanie say Caroline has?",
      "prediction": "caring, kind, supportive, inspiring",
      "reference": "Thoughtful, authentic, driven",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0.2857142857142857,
        "bleu2": 0.06900655593423542,
        "bleu3": 0.047098549390932394,
        "bleu4": 0.039281465090051315,
        "bert_precision": 0.8981035947799683,
        "bert_recall": 0.8892410397529602,
        "bert_f1": 0.8936503529548645,
        "meteor": 0.0,
        "sbert_similarity": 0.5590651035308838
      }
    },
    {
      "sample_id": 0,
      "question": "What transgender-specific events has Caroline attended?",
      "prediction": "I went to a transgender conference this month.",
      "reference": "Poetry reading, conference",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.18181818181818182,
        "rouge1_f": 0.18181818181818182,
        "rouge2_f": 0.0,
        "rougeL_f": 0.18181818181818182,
        "bleu1": 0.11111111111111109,
        "bleu2": 0.03726779962499649,
        "bleu3": 0.028067124621919234,
        "bleu4": 0.023980296761827107,
        "bert_precision": 0.8721335530281067,
        "bert_recall": 0.8624255061149597,
        "bert_f1": 0.8672524094581604,
        "meteor": 0.14285714285714288,
        "sbert_similarity": 0.28248071670532227
      }
    },
    {
      "sample_id": 0,
      "question": "What book did Melanie read from Caroline's suggestion?",
      "prediction": "the book you recommended a while ago",
      "reference": "\"Becoming Nicole\"",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8305060863494873,
        "bert_recall": 0.8312390446662903,
        "bert_f1": 0.8308724761009216,
        "meteor": 0.0,
        "sbert_similarity": 0.10312722623348236
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie's friend adopt a child?",
      "prediction": "last year",
      "reference": 2022,
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8694188594818115,
        "bert_recall": 0.9111441373825073,
        "bert_f1": 0.8897925615310669,
        "meteor": 0.0,
        "sbert_similarity": 0.3672372102737427
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie get hurt?",
      "prediction": "Sorry to hear that, Melanie. I hope you're okay.",
      "reference": "September 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8115320205688477,
        "bert_recall": 0.7853717803955078,
        "bert_f1": 0.798237681388855,
        "meteor": 0.0,
        "sbert_similarity": 0.005050720646977425
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie's family go on a roadtrip?",
      "prediction": "last week",
      "reference": "The weekend before 20 October 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8611711859703064,
        "bert_recall": 0.791596531867981,
        "bert_f1": 0.8249194622039795,
        "meteor": 0.0,
        "sbert_similarity": 0.4094058871269226
      }
    },
    {
      "sample_id": 0,
      "question": "How many children does Melanie have?",
      "prediction": "Melanie has kids.",
      "reference": 3,
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.870073139667511,
        "bert_recall": 0.8693737983703613,
        "bert_f1": 0.8697233200073242,
        "meteor": 0.0,
        "sbert_similarity": 0.08939890563488007
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie go on a hike after the roadtrip?",
      "prediction": "yesterday",
      "reference": "19 October 2023",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8904602527618408,
        "bert_recall": 0.7936492562294006,
        "bert_f1": 0.8392722010612488,
        "meteor": 0.0,
        "sbert_similarity": 0.3886603116989136
      }
    },
    {
      "sample_id": 0,
      "question": "Would Melanie go on another roadtrip soon?",
      "prediction": "Great chatting with you! Feel free to reach out any time.",
      "reference": "Likely no; since this one went badly",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.830012857913971,
        "bert_recall": 0.8269873857498169,
        "bert_f1": 0.8284973502159119,
        "meteor": 0.0,
        "sbert_similarity": 0.015637483447790146
      }
    },
    {
      "sample_id": 0,
      "question": "What items has Melanie bought?",
      "prediction": "Melanie has not mentioned any items she has bought.",
      "reference": "Figurines, shoes",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8526350855827332,
        "bert_recall": 0.7853319644927979,
        "bert_f1": 0.8176007270812988,
        "meteor": 0.0,
        "sbert_similarity": 0.2766370475292206
      }
    },
    {
      "sample_id": 0,
      "question": "When did Caroline pass the adoption interview?",
      "prediction": "22 October, 2023",
      "reference": "The Friday before 22 October 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5714285714285715,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.45489799478447507,
        "bleu2": 0.30326532985631666,
        "bleu3": 0.14283448174223617,
        "bleu4": 0.11404605374835301,
        "bert_precision": 0.9337132573127747,
        "bert_recall": 0.8866832256317139,
        "bert_f1": 0.9095907211303711,
        "meteor": 0.17543859649122806,
        "sbert_similarity": 0.8385580778121948
      }
    },
    {
      "sample_id": 0,
      "question": "When did Melanie buy the figurines?",
      "prediction": "yesterday",
      "reference": "21 October 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8914521932601929,
        "bert_recall": 0.7940015196800232,
        "bert_f1": 0.8399096727371216,
        "meteor": 0.0,
        "sbert_similarity": 0.39764299988746643
      }
    },
    {
      "sample_id": 0,
      "question": "Would Caroline want to move back to her home country soon?",
      "prediction": "The context does not indicate any desire from Caroline to move back to her home country soon.",
      "reference": "No; she's in the process of adopting children.",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.08333333333333333,
        "rouge1_f": 0.07692307692307691,
        "rouge2_f": 0.0,
        "rougeL_f": 0.07692307692307691,
        "bleu1": 0.11111111111111109,
        "bleu2": 0.02556549962824567,
        "bleu3": 0.016660661223010558,
        "bleu4": 0.01284618972676772,
        "bert_precision": 0.8599077463150024,
        "bert_recall": 0.8778246641159058,
        "bert_f1": 0.868773877620697,
        "meteor": 0.05617977528089888,
        "sbert_similarity": 0.289794385433197
      }
    },
    {
      "sample_id": 0,
      "question": "What did the charity race raise awareness for?",
      "prediction": "mental health",
      "reference": "mental health",
      "category": 4,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 0.46773514128719823,
        "bleu4": 0.316227766016838,
        "bert_precision": 0.9999998807907104,
        "bert_recall": 0.9999998807907104,
        "bert_f1": 0.9999998807907104,
        "meteor": 0.9375,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie realize after the charity race?",
      "prediction": "It was really rewarding. Really made me think about taking care of our minds.",
      "reference": "self-care is important",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.11111111111111112,
        "rouge2_f": 0.0,
        "rougeL_f": 0.11111111111111112,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.867790937423706,
        "bert_recall": 0.8920974731445312,
        "bert_f1": 0.8797763586044312,
        "meteor": 0.0,
        "sbert_similarity": 0.23238077759742737
      }
    },
    {
      "sample_id": 0,
      "question": "How does Melanie prioritize self-care?",
      "prediction": "carving out some me-time each day - running, reading, or playing my violin.",
      "reference": "by carving out some me-time each day for activities like running, reading, or playing the violin",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.7586206896551724,
        "rouge1_f": 0.8000000000000002,
        "rouge2_f": 0.6428571428571429,
        "rougeL_f": 0.8000000000000002,
        "bleu1": 0.7170287333499838,
        "bleu2": 0.6495001340751807,
        "bleu3": 0.5992971745749234,
        "bleu4": 0.5425486407251953,
        "bert_precision": 0.9555229544639587,
        "bert_recall": 0.9435347318649292,
        "bert_f1": 0.949491024017334,
        "meteor": 0.6343949044585987,
        "sbert_similarity": 0.8080756068229675
      }
    },
    {
      "sample_id": 0,
      "question": "What are Caroline's plans for the summer?",
      "prediction": "I'm thrilled to make a family for kids who need one.",
      "reference": "researching adoption agencies",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.842076301574707,
        "bert_recall": 0.8522364497184753,
        "bert_f1": 0.8471258282661438,
        "meteor": 0.0,
        "sbert_similarity": 0.2639468312263489
      }
    },
    {
      "sample_id": 0,
      "question": "What type of individuals does the adoption agency Caroline is considering support?",
      "prediction": "LGBTQ+ folks with adoption.",
      "reference": "LGBTQ+ individuals",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.3333333333333333,
        "rouge1_f": 0.3333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.3333333333333333,
        "bleu1": 0.2,
        "bleu2": 0.07071067811865477,
        "bleu3": 0.05665132701906204,
        "bleu4": 0.05372849659117709,
        "bert_precision": 0.9171934127807617,
        "bert_recall": 0.9533190131187439,
        "bert_f1": 0.9349073171615601,
        "meteor": 0.22727272727272727,
        "sbert_similarity": 0.7080492973327637
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Caroline choose the adoption agency?",
      "prediction": "I chose them 'cause they help LGBTQ+ folks with adoption. Their inclusivity and support really spoke to me.",
      "reference": "because of their inclusivity and support for LGBTQ+ individuals",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.3703703703703704,
        "rouge1_f": 0.3703703703703704,
        "rouge2_f": 0.24,
        "rougeL_f": 0.2962962962962963,
        "bleu1": 0.25,
        "bleu2": 0.19867985355975656,
        "bleu3": 0.16667923575277016,
        "bleu4": 0.12673718536830808,
        "bert_precision": 0.8836987018585205,
        "bert_recall": 0.9078872203826904,
        "bert_f1": 0.8956297039985657,
        "meteor": 0.48888888888888904,
        "sbert_similarity": 0.531123697757721
      }
    },
    {
      "sample_id": 0,
      "question": "What is Caroline excited about in the adoption process?",
      "prediction": "I'm thrilled to make a family for kids who need one.",
      "reference": "creating a family for kids who need one",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.7368421052631579,
        "rouge1_f": 0.7000000000000001,
        "rouge2_f": 0.6666666666666665,
        "rougeL_f": 0.7000000000000001,
        "bleu1": 0.5384615384615384,
        "bleu2": 0.5188745216627708,
        "bleu3": 0.4999673727050369,
        "bleu4": 0.4703709593866897,
        "bert_precision": 0.929789125919342,
        "bert_recall": 0.9455828666687012,
        "bert_f1": 0.9376195073127747,
        "meteor": 0.7212182061579651,
        "sbert_similarity": 0.7122130393981934
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie think about Caroline's decision to adopt?",
      "prediction": "Congrats, Caroline! Adoption sounds awesome. I'm so happy for you.",
      "reference": "she thinks Caroline is doing something amazing and will be an awesome mom",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.17391304347826086,
        "rouge1_f": 0.16666666666666669,
        "rouge2_f": 0.0,
        "rougeL_f": 0.16666666666666669,
        "bleu1": 0.13333333333333333,
        "bleu2": 0.030860669992418384,
        "bleu3": 0.020202551616772847,
        "bleu4": 0.015718877363021206,
        "bert_precision": 0.8717911243438721,
        "bert_recall": 0.8734791278839111,
        "bert_f1": 0.8726342916488647,
        "meteor": 0.0,
        "sbert_similarity": 0.5733784437179565
      }
    },
    {
      "sample_id": 0,
      "question": "How long have Mel and her husband been married?",
      "prediction": "Congrats, Melanie! You both looked so great on your wedding day! Wishing you many happy years together!",
      "reference": "Mel and her husband have been married for 5 years.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.07692307692307693,
        "rouge1_f": 0.07407407407407408,
        "rouge2_f": 0.0,
        "rougeL_f": 0.07407407407407408,
        "bleu1": 0.047619047619047616,
        "bleu2": 0.01543033499620919,
        "bleu3": 0.011280777824436245,
        "bleu4": 0.009134423666564471,
        "bert_precision": 0.8278579115867615,
        "bert_recall": 0.8617347478866577,
        "bert_f1": 0.8444567322731018,
        "meteor": 0.0,
        "sbert_similarity": 0.2827930748462677
      }
    },
    {
      "sample_id": 0,
      "question": "What does Caroline's necklace symbolize?",
      "prediction": "love, faith and strength",
      "reference": "love, faith, and strength",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 0.8187307530779819,
        "bleu2": 0.7090416310250969,
        "bleu3": 0.5181569246973543,
        "bleu4": 0.2737591267534727,
        "bert_precision": 0.9906566739082336,
        "bert_recall": 0.9857159852981567,
        "bert_f1": 0.9881801009178162,
        "meteor": 0.6388888888888888,
        "sbert_similarity": 0.9917947053909302
      }
    },
    {
      "sample_id": 0,
      "question": "What country is Caroline's grandma from?",
      "prediction": "The context does not provide information about Caroline's grandma's country.",
      "reference": "Sweden",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8028202056884766,
        "bert_recall": 0.8221868276596069,
        "bert_f1": 0.8123881220817566,
        "meteor": 0.0,
        "sbert_similarity": 0.10720138251781464
      }
    },
    {
      "sample_id": 0,
      "question": "What was grandma's gift to Caroline?",
      "prediction": "a necklace",
      "reference": "necklace",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5,
        "bleu2": 0.223606797749979,
        "bleu3": 0.1740444189610778,
        "bleu4": 0.1495348781221221,
        "bert_precision": 0.8547325134277344,
        "bert_recall": 0.9164278507232666,
        "bert_f1": 0.8845056891441345,
        "meteor": 0.45454545454545453,
        "sbert_similarity": 0.9594278335571289
      }
    },
    {
      "sample_id": 0,
      "question": "What is Melanie's hand-painted bowl a reminder of?",
      "prediction": "art and self-expression",
      "reference": "art and self-expression",
      "category": 4,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie and her family do while camping?",
      "prediction": "explored nature, roasted marshmallows around the campfire and even went on a hike",
      "reference": "explored nature, roasted marshmallows, and went on a hike",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8181818181818181,
        "rouge1_f": 0.8181818181818181,
        "rouge2_f": 0.6,
        "rougeL_f": 0.8181818181818181,
        "bleu1": 0.7142857142857143,
        "bleu2": 0.6201736729460422,
        "bleu3": 0.5464986398614002,
        "bleu4": 0.45723134461864345,
        "bert_precision": 0.9513475894927979,
        "bert_recall": 0.9753820300102234,
        "bert_f1": 0.9632148742675781,
        "meteor": 0.828623670212766,
        "sbert_similarity": 0.912758469581604
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of counseling and mental health services is Caroline interested in pursuing?",
      "prediction": "I'm thinking of working with trans people, helping them accept themselves and supporting their mental health.",
      "reference": "working with trans people, helping them accept themselves and supporting their mental health",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.896551724137931,
        "rouge1_f": 0.8666666666666666,
        "rouge2_f": 0.8571428571428571,
        "rougeL_f": 0.8666666666666666,
        "bleu1": 0.7368421052631579,
        "bleu2": 0.7294955398698874,
        "bleu3": 0.7238967222455629,
        "bleu4": 0.7128736748247595,
        "bert_precision": 0.9448204040527344,
        "bert_recall": 0.9558389186859131,
        "bert_f1": 0.9502977728843689,
        "meteor": 0.9019945697577276,
        "sbert_similarity": 0.9358103275299072
      }
    },
    {
      "sample_id": 0,
      "question": "What workshop did Caroline attend recently?",
      "prediction": "I'm going to a transgender conference this month.",
      "reference": "LGBTQ+ counseling workshop",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8705583810806274,
        "bert_recall": 0.8293747305870056,
        "bert_f1": 0.8494677543640137,
        "meteor": 0.0,
        "sbert_similarity": 0.543421745300293
      }
    },
    {
      "sample_id": 0,
      "question": "What was discussed in the LGBTQ+ counseling workshop?",
      "prediction": "different therapeutic methods and how to best work with trans people",
      "reference": "therapeutic methods and how to best work with trans people",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.9523809523809523,
        "rouge1_f": 0.9523809523809523,
        "rouge2_f": 0.9473684210526316,
        "rougeL_f": 0.9523809523809523,
        "bleu1": 0.9090909090909091,
        "bleu2": 0.9045340337332909,
        "bleu3": 0.9002437389487007,
        "bleu4": 0.8931539818068694,
        "bert_precision": 0.980875551700592,
        "bert_recall": 0.9933834075927734,
        "bert_f1": 0.9870898723602295,
        "meteor": 0.9896039603960397,
        "sbert_similarity": 0.9858116507530212
      }
    },
    {
      "sample_id": 0,
      "question": "What motivated Caroline to pursue counseling?",
      "prediction": "I struggled with mental health, and support I got was really helpful. It made me realize how important it is for others to have a support system.",
      "reference": "her own journey and the support she received, and how counseling improved her life",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.16666666666666666,
        "rouge1_f": 0.14634146341463417,
        "rouge2_f": 0.0,
        "rougeL_f": 0.14634146341463417,
        "bleu1": 0.13333333333333333,
        "bleu2": 0.06780635036208103,
        "bleu3": 0.0263679455642362,
        "bleu4": 0.015703799285850036,
        "bert_precision": 0.8900625705718994,
        "bert_recall": 0.8927928805351257,
        "bert_f1": 0.891425609588623,
        "meteor": 0.13071895424836602,
        "sbert_similarity": 0.46682387590408325
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of place does Caroline want to create for people?",
      "prediction": "a loving home",
      "reference": "a safe and inviting place for people to grow",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.16666666666666666,
        "rouge1_f": 0.16666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.16666666666666666,
        "bleu1": 0.045111761078870896,
        "bleu2": 0.017471709937655493,
        "bleu3": 0.01639159154635143,
        "bleu4": 0.015377056977980369,
        "bert_precision": 0.8790748715400696,
        "bert_recall": 0.8513867855072021,
        "bert_f1": 0.8650093674659729,
        "meteor": 0.11904761904761904,
        "sbert_similarity": 0.3547641932964325
      }
    },
    {
      "sample_id": 0,
      "question": "Did Melanie make the black and white bowl in the photo?",
      "prediction": "Yeah, I made this bowl in my class.",
      "reference": "Yes",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8291473388671875,
        "bert_recall": 0.8540471196174622,
        "bert_f1": 0.8414130806922913,
        "meteor": 0.0,
        "sbert_similarity": 0.13204295933246613
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of books does Caroline have in her library?",
      "prediction": "lots of kids' books- classics, stories from different cultures, educational books",
      "reference": "kids' books - classics, stories from different cultures, educational books",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.7999999999999999,
        "rouge1_f": 0.9,
        "rouge2_f": 0.888888888888889,
        "rougeL_f": 0.9,
        "bleu1": 0.7857142857142857,
        "bleu2": 0.7375337578416624,
        "bleu3": 0.6846815074766505,
        "bleu4": 0.6450001140844255,
        "bert_precision": 0.9514201283454895,
        "bert_recall": 0.9638512134552002,
        "bert_f1": 0.9575954079627991,
        "meteor": 0.785891089108911,
        "sbert_similarity": 0.9294911623001099
      }
    },
    {
      "sample_id": 0,
      "question": "What was Melanie's favorite book from her childhood?",
      "prediction": "I loved reading \"Charlotte's Web\" as a kid.",
      "reference": "\"Charlotte's Web\"",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.5,
        "rouge2_f": 0.4,
        "rougeL_f": 0.5,
        "bleu1": 0.4166666666666667,
        "bleu2": 0.3892494720807615,
        "bleu3": 0.3605790708802296,
        "bleu4": 0.31702331385234306,
        "bert_precision": 0.9032477140426636,
        "bert_recall": 0.9491208791732788,
        "bert_f1": 0.9256163239479065,
        "meteor": 0.7211538461538463,
        "sbert_similarity": 0.729093611240387
      }
    },
    {
      "sample_id": 0,
      "question": "What book did Caroline recommend to Melanie?",
      "prediction": "the book you recommended a while ago",
      "reference": "\"Becoming Nicole\"",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8305060863494873,
        "bert_recall": 0.8312390446662903,
        "bert_f1": 0.8308724761009216,
        "meteor": 0.0,
        "sbert_similarity": 0.10312722623348236
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline take away from the book \"Becoming Nicole\"?",
      "prediction": "It made me feel connected and gave me a lot of hope for my own path.",
      "reference": "Lessons on self-acceptance and finding support",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.09523809523809522,
        "rouge1_f": 0.08695652173913043,
        "rouge2_f": 0.0,
        "rougeL_f": 0.08695652173913043,
        "bleu1": 0.0588235294117647,
        "bleu2": 0.019174124721184262,
        "bleu3": 0.014076093604378503,
        "bleu4": 0.011502783619900045,
        "bert_precision": 0.8656476736068726,
        "bert_recall": 0.8624590039253235,
        "bert_f1": 0.8640503287315369,
        "meteor": 0.14285714285714288,
        "sbert_similarity": 0.30920058488845825
      }
    },
    {
      "sample_id": 0,
      "question": "What are the new shoes that Melanie got used for?",
      "prediction": "Luna and Oliver! They are so sweet and playful - they really liven up the house!",
      "reference": "Running",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7969321608543396,
        "bert_recall": 0.840400755405426,
        "bert_f1": 0.818089485168457,
        "meteor": 0.20000000000000004,
        "sbert_similarity": -0.00491408072412014
      }
    },
    {
      "sample_id": 0,
      "question": "What is Melanie's reason for getting into running?",
      "prediction": "to de-stress, which has been great for my headspace.",
      "reference": "To de-stress and clear her mind",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.26666666666666666,
        "rouge1_f": 0.3529411764705882,
        "rouge2_f": 0.26666666666666666,
        "rougeL_f": 0.3529411764705882,
        "bleu1": 0.18181818181818182,
        "bleu2": 0.13483997249264845,
        "bleu3": 0.06036431606009924,
        "bleu4": 0.03986357128268015,
        "bert_precision": 0.9036515951156616,
        "bert_recall": 0.934339702129364,
        "bert_f1": 0.9187394976615906,
        "meteor": 0.07936507936507937,
        "sbert_similarity": 0.5493969321250916
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie say running has been great for?",
      "prediction": "de-stress and clear my mind",
      "reference": "Her mental health",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8677074313163757,
        "bert_recall": 0.8738518357276917,
        "bert_f1": 0.8707687854766846,
        "meteor": 0.0,
        "sbert_similarity": 0.34747812151908875
      }
    },
    {
      "sample_id": 0,
      "question": "What did Mel and her kids make during the pottery workshop?",
      "prediction": "we all made our own pots",
      "reference": "pots",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2857142857142857,
        "rouge1_f": 0.2857142857142857,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2857142857142857,
        "bleu1": 0.16666666666666669,
        "bleu2": 0.05773502691896258,
        "bleu3": 0.04506819749679463,
        "bleu4": 0.040824829046386304,
        "bert_precision": 0.8104043006896973,
        "bert_recall": 0.8825967311859131,
        "bert_f1": 0.8449613451957703,
        "meteor": 0.33333333333333337,
        "sbert_similarity": 0.6579083204269409
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of pot did Mel and her kids make with clay?",
      "prediction": "We all made our own pots.",
      "reference": "a cup with a dog face on it",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8792179822921753,
        "bert_recall": 0.8518564105033875,
        "bert_f1": 0.8653209805488586,
        "meteor": 0.0,
        "sbert_similarity": 0.09348639100790024
      }
    },
    {
      "sample_id": 0,
      "question": "What creative project do Mel and her kids do together besides pottery?",
      "prediction": "making something with clay",
      "reference": "painting",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8033450841903687,
        "bert_recall": 0.8686306476593018,
        "bert_f1": 0.8347132802009583,
        "meteor": 0.0,
        "sbert_similarity": 0.40311315655708313
      }
    },
    {
      "sample_id": 0,
      "question": "What did Mel and her kids paint in their latest project in July 2023?",
      "prediction": "nature-inspired ones",
      "reference": "a sunset with a palm tree",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8419812917709351,
        "bert_recall": 0.8387597799301147,
        "bert_f1": 0.8403674364089966,
        "meteor": 0.0,
        "sbert_similarity": 0.22545360028743744
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline see at the council meeting for adoption?",
      "prediction": "it was inspiring and emotional - so many people wanted to create loving homes for children in need.",
      "reference": "many people wanting to create loving homes for children in need",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6896551724137931,
        "rouge1_f": 0.7857142857142858,
        "rouge2_f": 0.7692307692307693,
        "rougeL_f": 0.7857142857142858,
        "bleu1": 0.5263157894736842,
        "bleu2": 0.4836508334066744,
        "bleu3": 0.4390690748074934,
        "bleu4": 0.4007781700028195,
        "bert_precision": 0.9040247797966003,
        "bert_recall": 0.9486033916473389,
        "bert_f1": 0.9257777333259583,
        "meteor": 0.8542735042735045,
        "sbert_similarity": 0.7657338380813599
      }
    },
    {
      "sample_id": 0,
      "question": "What do sunflowers represent according to Caroline?",
      "prediction": "Sunflowers mean warmth and happiness.",
      "reference": "warmth and happiness",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.7499999999999999,
        "rouge1_f": 0.7499999999999999,
        "rouge2_f": 0.6666666666666666,
        "rougeL_f": 0.7499999999999999,
        "bleu1": 0.5,
        "bleu2": 0.447213595499958,
        "bleu3": 0.3721003696282278,
        "bleu4": 0.20205155046766235,
        "bert_precision": 0.8473575115203857,
        "bert_recall": 0.9021205902099609,
        "bert_f1": 0.8738819360733032,
        "meteor": 0.5859375,
        "sbert_similarity": 0.555607259273529
      }
    },
    {
      "sample_id": 0,
      "question": "Why are flowers important to Melanie?",
      "prediction": "They represent growth, beauty and reminding us to appreciate the small moments.",
      "reference": "They remind her to appreciate the small moments and were a part of her wedding decor",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5185185185185186,
        "rouge1_f": 0.5714285714285715,
        "rouge2_f": 0.30769230769230765,
        "rougeL_f": 0.5,
        "bleu1": 0.43343894987509085,
        "bleu2": 0.34001748667142356,
        "bleu3": 0.29581263930152274,
        "bleu4": 0.25068244494498715,
        "bert_precision": 0.9044241309165955,
        "bert_recall": 0.8773373961448669,
        "bert_f1": 0.890674889087677,
        "meteor": 0.4068550497121926,
        "sbert_similarity": 0.5588934421539307
      }
    },
    {
      "sample_id": 0,
      "question": "What inspired Caroline's painting for the art show?",
      "prediction": "the energy and support at the LGBTQ support group",
      "reference": "visiting an LGBTQ center and wanting to capture unity and strength",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.23529411764705882,
        "rouge1_f": 0.19999999999999998,
        "rouge2_f": 0.0,
        "rougeL_f": 0.09999999999999999,
        "bleu1": 0.17794164509262397,
        "bleu2": 0.04220256668175114,
        "bleu3": 0.02825061695601845,
        "bleu4": 0.022835060540062107,
        "bert_precision": 0.8946270942687988,
        "bert_recall": 0.8748610019683838,
        "bert_f1": 0.8846336603164673,
        "meteor": 0.09259259259259259,
        "sbert_similarity": 0.6603058576583862
      }
    },
    {
      "sample_id": 0,
      "question": "How often does Melanie go to the beach with her kids?",
      "prediction": "usually only once or twice a year",
      "reference": "once or twice a year",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8333333333333333,
        "rouge1_f": 0.8333333333333333,
        "rouge2_f": 0.8,
        "rougeL_f": 0.8333333333333333,
        "bleu1": 0.7142857142857143,
        "bleu2": 0.6900655593423543,
        "bleu3": 0.6613898798842307,
        "bleu4": 0.6147881529512643,
        "bert_precision": 0.9254478216171265,
        "bert_recall": 0.9496266841888428,
        "bert_f1": 0.937381386756897,
        "meteor": 0.9576923076923077,
        "sbert_similarity": 0.9151639938354492
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie and her family see during their camping trip last year?",
      "prediction": "explored nature, roasted marshmallows around the campfire and even went on a hike. The view from the top was amazing!",
      "reference": "Perseid meteor shower",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.798589825630188,
        "bert_recall": 0.7676972150802612,
        "bert_f1": 0.7828388810157776,
        "meteor": 0.0,
        "sbert_similarity": 0.07423382997512817
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie feel while watching the meteor shower?",
      "prediction": "I felt tiny and in awe of the universe.",
      "reference": "in awe of the universe",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.7142857142857143,
        "rouge1_f": 0.7142857142857143,
        "rouge2_f": 0.6666666666666666,
        "rougeL_f": 0.7142857142857143,
        "bleu1": 0.5,
        "bleu2": 0.4714045207910317,
        "bleu3": 0.44042320075255215,
        "bleu4": 0.392814650900513,
        "bert_precision": 0.9067752957344055,
        "bert_recall": 0.9327743053436279,
        "bert_f1": 0.9195910692214966,
        "meteor": 0.7349537037037037,
        "sbert_similarity": 0.642244815826416
      }
    },
    {
      "sample_id": 0,
      "question": "Whose birthday did Melanie celebrate recently?",
      "prediction": "my daughter's birthday",
      "reference": "Melanie's daughter",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.5714285714285715,
        "rouge2_f": 0.0,
        "rougeL_f": 0.28571428571428575,
        "bleu1": 0.5,
        "bleu2": 0.12909944487358058,
        "bleu3": 0.09635409769034631,
        "bleu4": 0.09554427922043669,
        "bert_precision": 0.883353054523468,
        "bert_recall": 0.9120131134986877,
        "bert_f1": 0.8974543213844299,
        "meteor": 0.0,
        "sbert_similarity": 0.4458889067173004
      }
    },
    {
      "sample_id": 0,
      "question": "Who performed at the concert at Melanie's daughter's birthday?",
      "prediction": "the band",
      "reference": "Matt Patterson",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8773897886276245,
        "bert_recall": 0.855670154094696,
        "bert_f1": 0.8663939237594604,
        "meteor": 0.0,
        "sbert_similarity": 0.19170786440372467
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Melanie choose to use colors and patterns in her pottery project?",
      "prediction": "to express myself and get creative",
      "reference": "She wanted to catch the eye and make people smile.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.25,
        "rouge2_f": 0.0,
        "rougeL_f": 0.25,
        "bleu1": 0.14486606950235942,
        "bleu2": 0.03548479513233444,
        "bleu3": 0.024620565232033,
        "bleu4": 0.021099385422893017,
        "bert_precision": 0.8860491514205933,
        "bert_recall": 0.8924217224121094,
        "bert_f1": 0.8892240524291992,
        "meteor": 0.2662037037037037,
        "sbert_similarity": 0.34922677278518677
      }
    },
    {
      "sample_id": 0,
      "question": "What pet does Caroline have?",
      "prediction": "What pet do you have?",
      "reference": "guinea pig",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8025158643722534,
        "bert_recall": 0.7818561792373657,
        "bert_f1": 0.792051374912262,
        "meteor": 0.0,
        "sbert_similarity": 0.4818496108055115
      }
    },
    {
      "sample_id": 0,
      "question": "What pets does Melanie have?",
      "prediction": "a pup and a kitty; another cat named Bailey; a dog named Oliver",
      "reference": "Two cats and a dog",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4444444444444444,
        "rouge2_f": 0.25,
        "rougeL_f": 0.33333333333333337,
        "bleu1": 0.2,
        "bleu2": 0.1690308509457033,
        "bleu3": 0.062066354712031736,
        "bleu4": 0.036787632499277766,
        "bert_precision": 0.8599069118499756,
        "bert_recall": 0.9287892580032349,
        "bert_f1": 0.8930217623710632,
        "meteor": 0.5441810344827587,
        "sbert_similarity": 0.6244467496871948
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Oliver hide his bone once?",
      "prediction": "in my slipper",
      "reference": "In Melanie's slipper",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.5714285714285715,
        "rouge2_f": 0.0,
        "rougeL_f": 0.5714285714285715,
        "bleu1": 0.47768754038252614,
        "bleu2": 0.13082012065333476,
        "bleu3": 0.10909005447984235,
        "bleu4": 0.09681772177713914,
        "bert_precision": 0.9412859678268433,
        "bert_recall": 0.9195079803466797,
        "bert_f1": 0.9302695393562317,
        "meteor": 0.3333333333333333,
        "sbert_similarity": 0.6715267896652222
      }
    },
    {
      "sample_id": 0,
      "question": "What activity did Caroline used to do with her dad?",
      "prediction": "exploring nature",
      "reference": "Horseback riding",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8454052805900574,
        "bert_recall": 0.770124077796936,
        "bert_f1": 0.8060107231140137,
        "meteor": 0.0,
        "sbert_similarity": 0.24791064858436584
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline make for a local church?",
      "prediction": "a project that reflects personal growth and acceptance, specifically highlighting the journey of a transgender woman.",
      "reference": "a stained glass window",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.10526315789473685,
        "rouge1_f": 0.1,
        "rouge2_f": 0.0,
        "rougeL_f": 0.1,
        "bleu1": 0.05555555555555554,
        "bleu2": 0.018077538151554672,
        "bleu3": 0.013254163846385744,
        "bleu4": 0.010802314890908065,
        "bert_precision": 0.8402761220932007,
        "bert_recall": 0.831372857093811,
        "bert_f1": 0.8358007669448853,
        "meteor": 0.09615384615384617,
        "sbert_similarity": 0.05843723192811012
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline find in her neighborhood during her walk?",
      "prediction": "Caroline went biking and saw some pretty cool stuff.",
      "reference": "a rainbow sidewalk",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8589632511138916,
        "bert_recall": 0.8548451662063599,
        "bert_f1": 0.8568992614746094,
        "meteor": 0.0,
        "sbert_similarity": 0.17159998416900635
      }
    },
    {
      "sample_id": 0,
      "question": "Which song motivates Caroline to be courageous?",
      "prediction": "\"Brave\" by Sara Bareilles has a lot of significance for me. It's about being courageous and fighting for what's right.",
      "reference": "Brave by Sara Bareilles",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2608695652173913,
        "rouge1_f": 0.3076923076923077,
        "rouge2_f": 0.25,
        "rougeL_f": 0.3076923076923077,
        "bleu1": 0.15384615384615385,
        "bleu2": 0.11094003924504585,
        "bleu3": 0.08208968293684403,
        "bleu4": 0.03864198149136354,
        "bert_precision": 0.849393904209137,
        "bert_recall": 0.9284551739692688,
        "bert_f1": 0.8871666193008423,
        "meteor": 0.5257936507936508,
        "sbert_similarity": 0.6410201787948608
      }
    },
    {
      "sample_id": 0,
      "question": "Which  classical musicians does Melanie enjoy listening to?",
      "prediction": "Bach and Mozart",
      "reference": "Bach and Mozart",
      "category": 4,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 0.9999998807907104,
        "bert_recall": 0.9999998807907104,
        "bert_f1": 0.9999998807907104,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "Who is Melanie a fan of in terms of modern music?",
      "prediction": "Ed Sheeran's \"Perfect\"",
      "reference": "Ed Sheeran",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.3333333333333333,
        "bleu2": 0.25819888974716115,
        "bleu3": 0.12111838948674812,
        "bleu4": 0.08633400213704504,
        "bert_precision": 0.8977776765823364,
        "bert_recall": 0.9811890721321106,
        "bert_f1": 0.9376319646835327,
        "meteor": 0.2380952380952381,
        "sbert_similarity": 0.705544114112854
      }
    },
    {
      "sample_id": 0,
      "question": "How long has Melanie been creating art?",
      "prediction": "Seven years now",
      "reference": "7 years",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0.3333333333333333,
        "bleu2": 0.12909944487358058,
        "bleu3": 0.12111838948674812,
        "bleu4": 0.11362193664674995,
        "bert_precision": 0.9228770732879639,
        "bert_recall": 0.9635453224182129,
        "bert_f1": 0.9427728056907654,
        "meteor": 0.8928571428571429,
        "sbert_similarity": 0.8659798502922058
      }
    },
    {
      "sample_id": 0,
      "question": "What precautionary sign did Melanie see at the café?",
      "prediction": "[Image: a photo of a sign posted on a door stating that someone is not being able to leave]",
      "reference": "A sign stating that someone is not being able to leave",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.7142857142857143,
        "rouge1_f": 0.7333333333333334,
        "rouge2_f": 0.6428571428571429,
        "rougeL_f": 0.7333333333333334,
        "bleu1": 0.5,
        "bleu2": 0.46291004988627577,
        "bleu3": 0.4253732906611973,
        "bleu4": 0.3922967662532704,
        "bert_precision": 0.9042259454727173,
        "bert_recall": 0.9523999094963074,
        "bert_f1": 0.9276880025863647,
        "meteor": 0.8360169491525423,
        "sbert_similarity": 0.7837035655975342
      }
    },
    {
      "sample_id": 0,
      "question": "What advice does Caroline give for getting started with adoption?",
      "prediction": "I got lots of help from this adoption advice/assistance group I attended.",
      "reference": "Do research, find an adoption agency or lawyer, gather necessary documents, and prepare emotionally.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.08,
        "rouge1_f": 0.07407407407407408,
        "rouge2_f": 0.0,
        "rougeL_f": 0.07407407407407408,
        "bleu1": 0.10472498435744391,
        "bleu2": 0.024373413669121567,
        "bleu3": 0.01602923720716669,
        "bleu4": 0.0125774279703401,
        "bert_precision": 0.8628308773040771,
        "bert_recall": 0.8579295873641968,
        "bert_f1": 0.8603732585906982,
        "meteor": 0.07246376811594203,
        "sbert_similarity": 0.610055148601532
      }
    },
    {
      "sample_id": 0,
      "question": "What setback did Melanie face in October 2023?",
      "prediction": "The context does not mention any setbacks faced by Melanie in October 2023.",
      "reference": "She got hurt and had to take a break from pottery.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0.07142857142857141,
        "bleu2": 0.023440361546924773,
        "bleu3": 0.017300021018422027,
        "bleu4": 0.01428363257865929,
        "bert_precision": 0.8566171526908875,
        "bert_recall": 0.866167426109314,
        "bert_f1": 0.8613658547401428,
        "meteor": 0.0,
        "sbert_similarity": 0.23158907890319824
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie do to keep herself busy during her pottery break?",
      "prediction": "Pottery's a great way to relax.",
      "reference": "Read a book and paint.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.1818181818181818,
        "rouge1_f": 0.16666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.16666666666666666,
        "bleu1": 0.25,
        "bleu2": 0.059761430466719695,
        "bleu3": 0.04033183084278514,
        "bleu4": 0.03303164318013808,
        "bert_precision": 0.8657439351081848,
        "bert_recall": 0.865517258644104,
        "bert_f1": 0.865630567073822,
        "meteor": 0.09803921568627452,
        "sbert_similarity": 0.3434387445449829
      }
    },
    {
      "sample_id": 0,
      "question": "What painting did Melanie show to Caroline on October 13, 2023?",
      "prediction": "Melanie showed a painting that is awesome and has red and blue colors.",
      "reference": "A painting inspired by sunsets with a pink sky.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2,
        "rouge1_f": 0.18181818181818185,
        "rouge2_f": 0.1,
        "rougeL_f": 0.18181818181818185,
        "bleu1": 0.21428571428571425,
        "bleu2": 0.12838814775327384,
        "bleu3": 0.053149189341188084,
        "bleu4": 0.03342866121562732,
        "bert_precision": 0.8873969316482544,
        "bert_recall": 0.8833916187286377,
        "bert_f1": 0.8853897452354431,
        "meteor": 0.10638297872340426,
        "sbert_similarity": 0.4887833595275879
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of painting did Caroline share with Melanie on October 13, 2023?",
      "prediction": "a drawing",
      "reference": "An abstract painting with blue streaks on a wall.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.1818181818181818,
        "rouge1_f": 0.1818181818181818,
        "rouge2_f": 0.0,
        "rougeL_f": 0.1818181818181818,
        "bleu1": 0.00915781944436709,
        "bleu2": 0.004095501360654834,
        "bleu3": 0.003187734728290661,
        "bleu4": 0.002738826828955665,
        "bert_precision": 0.8979036808013916,
        "bert_recall": 0.8474633097648621,
        "bert_f1": 0.871954619884491,
        "meteor": 0.06024096385542168,
        "sbert_similarity": 0.4673636555671692
      }
    },
    {
      "sample_id": 0,
      "question": "What was the poetry reading that Caroline attended about?",
      "prediction": "It was a transgender poetry reading where transgender people shared their stories through poetry.",
      "reference": "It was a transgender poetry reading where transgender people shared their stories.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.9565217391304348,
        "rouge1_f": 0.923076923076923,
        "rouge2_f": 0.9166666666666666,
        "rougeL_f": 0.923076923076923,
        "bleu1": 0.8666666666666667,
        "bleu2": 0.8251983888449983,
        "bleu3": 0.8078434700407627,
        "bleu4": 0.7916963878457504,
        "bert_precision": 0.9864803552627563,
        "bert_recall": 0.9956105351448059,
        "bert_f1": 0.9910244345664978,
        "meteor": 0.9013006367700853,
        "sbert_similarity": 0.9938866496086121
      }
    },
    {
      "sample_id": 0,
      "question": "What did the posters at the poetry reading say?",
      "prediction": "the posters were amazing, so much pride and strength!",
      "reference": "\"Trans Lives Matter\"",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8240383267402649,
        "bert_recall": 0.8319058418273926,
        "bert_f1": 0.8279534578323364,
        "meteor": 0.13888888888888892,
        "sbert_similarity": 0.0876564010977745
      }
    },
    {
      "sample_id": 0,
      "question": "What does Caroline's drawing symbolize for her?",
      "prediction": "It helps me show my feelings and freeze gorgeous moments.",
      "reference": "Freedom and being true to herself.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.125,
        "rouge1_f": 0.125,
        "rouge2_f": 0.0,
        "rougeL_f": 0.125,
        "bleu1": 0.18181818181818182,
        "bleu2": 0.042640143271122095,
        "bleu3": 0.028234511901075607,
        "bleu4": 0.022416933501922302,
        "bert_precision": 0.8764674663543701,
        "bert_recall": 0.8756634593009949,
        "bert_f1": 0.876065194606781,
        "meteor": 0.078125,
        "sbert_similarity": 0.19184710085391998
      }
    },
    {
      "sample_id": 0,
      "question": "How do Melanie and Caroline describe their journey through life together?",
      "prediction": "Life's about learning and exploring.",
      "reference": "An ongoing adventure of learning and growing.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.3333333333333333,
        "rouge1_f": 0.30769230769230765,
        "rouge2_f": 0.1818181818181818,
        "rougeL_f": 0.30769230769230765,
        "bleu1": 0.37151909989293497,
        "bleu2": 0.23168286407366764,
        "bleu3": 0.09978737033508449,
        "bleu4": 0.0670144447096575,
        "bert_precision": 0.9239636063575745,
        "bert_recall": 0.9150422215461731,
        "bert_f1": 0.9194812774658203,
        "meteor": 0.275735294117647,
        "sbert_similarity": 0.6987754106521606
      }
    },
    {
      "sample_id": 0,
      "question": "What happened to Melanie's son on their road trip?",
      "prediction": "my son got into an accident. We were so lucky he was okay.",
      "reference": "He got into an accident",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5555555555555556,
        "rouge1_f": 0.5555555555555556,
        "rouge2_f": 0.375,
        "rougeL_f": 0.4444444444444444,
        "bleu1": 0.3333333333333333,
        "bleu2": 0.26726124191242434,
        "bleu3": 0.22569209116099667,
        "bleu4": 0.17395797375642233,
        "bert_precision": 0.8910011053085327,
        "bert_recall": 0.9416059255599976,
        "bert_f1": 0.915604829788208,
        "meteor": 0.646551724137931,
        "sbert_similarity": 0.5946983098983765
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie's son handle the accident?",
      "prediction": "We were all freaked when my son got into an accident. We were so lucky he was okay.",
      "reference": "He was scared but reassured by his family",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.16666666666666666,
        "rouge1_f": 0.15384615384615383,
        "rouge2_f": 0.08333333333333333,
        "rougeL_f": 0.15384615384615383,
        "bleu1": 0.10000000000000002,
        "bleu2": 0.07254762501100116,
        "bleu3": 0.0318985825417419,
        "bleu4": 0.020364851292391,
        "bert_precision": 0.8774306774139404,
        "bert_recall": 0.8723105192184448,
        "bert_f1": 0.8748630881309509,
        "meteor": 0.20833333333333334,
        "sbert_similarity": 0.4867149293422699
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie feel about her family after the accident?",
      "prediction": "Life's unpredictable, but moments like these remind us how important our loved ones are. Family's everything.",
      "reference": "They are important and mean the world to her",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.16,
        "rouge1_f": 0.14814814814814814,
        "rouge2_f": 0.0,
        "rougeL_f": 0.07407407407407407,
        "bleu1": 0.09523809523809525,
        "bleu2": 0.02182178902359924,
        "bleu3": 0.0141800886003256,
        "bleu4": 0.010862721615727716,
        "bert_precision": 0.8784343600273132,
        "bert_recall": 0.8875707983970642,
        "bert_f1": 0.8829789161682129,
        "meteor": 0.05154639175257732,
        "sbert_similarity": 0.3275715112686157
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie's children handle the accident?",
      "prediction": "I bet they bring lots of joy.",
      "reference": "They were scared but resilient",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.16666666666666666,
        "rouge1_f": 0.16666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.16666666666666666,
        "bleu1": 0.12500000000000003,
        "bleu2": 0.04225771273642583,
        "bleu3": 0.032085442892067474,
        "bleu4": 0.02777619034011792,
        "bert_precision": 0.87557053565979,
        "bert_recall": 0.8627548813819885,
        "bert_f1": 0.8691154718399048,
        "meteor": 0.09615384615384616,
        "sbert_similarity": 0.2957942485809326
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie feel after the accident?",
      "prediction": "we were all freaked when my son got into an accident. We were so lucky he was okay. It was a real scary experience. Thankfully it's over now.",
      "reference": "Grateful and thankful for her family",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.05714285714285715,
        "rouge2_f": 0.0,
        "rougeL_f": 0.05714285714285715,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8325330018997192,
        "bert_recall": 0.8271949291229248,
        "bert_f1": 0.8298553824424744,
        "meteor": 0.06097560975609757,
        "sbert_similarity": 0.06856709718704224
      }
    },
    {
      "sample_id": 0,
      "question": "What was Melanie's reaction to her children enjoying the Grand Canyon?",
      "prediction": "they enjoyed the Grand Canyon a lot!",
      "reference": "She was happy and thankful",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8625913858413696,
        "bert_recall": 0.8752247095108032,
        "bert_f1": 0.8688621520996094,
        "meteor": 0.0,
        "sbert_similarity": 0.20662693679332733
      }
    },
    {
      "sample_id": 0,
      "question": "What do Melanie's family give her?",
      "prediction": "joy and love",
      "reference": "Strength and motivation",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.3333333333333333,
        "rouge1_f": 0.3333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.3333333333333333,
        "bleu1": 0.3333333333333333,
        "bleu2": 0.12909944487358058,
        "bleu3": 0.12111838948674812,
        "bleu4": 0.11362193664674995,
        "bert_precision": 0.911570131778717,
        "bert_recall": 0.9261353611946106,
        "bert_f1": 0.9187950491905212,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.24030324816703796
      }
    },
    {
      "sample_id": 0,
      "question": "How did Melanie feel about her family supporting her?",
      "prediction": "they showed lots of love and support",
      "reference": "She appreciated them a lot",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.16666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.16666666666666666,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8683788776397705,
        "bert_recall": 0.8961789608001709,
        "bert_f1": 0.8820599317550659,
        "meteor": 0.09615384615384616,
        "sbert_similarity": 0.4513204097747803
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie do after the road trip to relax?",
      "prediction": "The kids loved it and it was a nice way to relax after the road trip.",
      "reference": "Went on a nature walk or hike",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.09523809523809523,
        "rouge1_f": 0.08695652173913043,
        "rouge2_f": 0.0,
        "rougeL_f": 0.08695652173913043,
        "bleu1": 0.0588235294117647,
        "bleu2": 0.019174124721184262,
        "bleu3": 0.014076093604378503,
        "bleu4": 0.011502783619900045,
        "bert_precision": 0.8499734997749329,
        "bert_recall": 0.8401774168014526,
        "bert_f1": 0.8450470566749573,
        "meteor": 0.06329113924050632,
        "sbert_similarity": 0.31323838233947754
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline realize after her charity race?",
      "prediction": "Not mentioned in the conversation",
      "reference": "self-care is important",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8778845071792603,
        "bert_recall": 0.876802921295166,
        "bert_f1": 0.8773433566093445,
        "meteor": 0.0,
        "sbert_similarity": 0.10229767113924026
      }
    },
    {
      "sample_id": 0,
      "question": "What are Melanie's plans for the summer with respect to adoption?",
      "prediction": "Not mentioned in the conversation",
      "reference": "researching adoption agencies",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8703113198280334,
        "bert_recall": 0.86725914478302,
        "bert_f1": 0.8687825798988342,
        "meteor": 0.0,
        "sbert_similarity": 0.010256895795464516
      }
    },
    {
      "sample_id": 0,
      "question": "What type of individuals does the adoption agency Melanie is considering support?",
      "prediction": "LGBTQ+ individuals",
      "reference": "LGBTQ+ individuals",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 0.46773514128719823,
        "bleu4": 0.316227766016838,
        "bert_precision": 1.0000001192092896,
        "bert_recall": 1.0000001192092896,
        "bert_f1": 1.0000001192092896,
        "meteor": 0.9375,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Melanie choose the adoption agency?",
      "prediction": "Not mentioned in the conversation",
      "reference": "because of their inclusivity and support for LGBTQ+ individuals",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8659257888793945,
        "bert_recall": 0.8060603737831116,
        "bert_f1": 0.8349213600158691,
        "meteor": 0.0,
        "sbert_similarity": 0.09916660189628601
      }
    },
    {
      "sample_id": 0,
      "question": "What is Melanie excited about in her adoption process?",
      "prediction": "Not mentioned in the conversation",
      "reference": "creating a family for kids who need one",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8648308515548706,
        "bert_recall": 0.8169586658477783,
        "bert_f1": 0.840213418006897,
        "meteor": 0.0,
        "sbert_similarity": -0.060941942036151886
      }
    },
    {
      "sample_id": 0,
      "question": "What does Melanie's necklace symbolize?",
      "prediction": "Not mentioned in the conversation",
      "reference": "love, faith, and strength",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8847731351852417,
        "bert_recall": 0.8560529947280884,
        "bert_f1": 0.8701761364936829,
        "meteor": 0.0,
        "sbert_similarity": 0.04011678695678711
      }
    },
    {
      "sample_id": 0,
      "question": "What country is Melanie's grandma from?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Sweden",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8494402170181274,
        "bert_recall": 0.8910872340202332,
        "bert_f1": 0.8697655200958252,
        "meteor": 0.0,
        "sbert_similarity": 0.1274150013923645
      }
    },
    {
      "sample_id": 0,
      "question": "What was grandma's gift to Melanie?",
      "prediction": "Not mentioned in the conversation",
      "reference": "necklace",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8458927273750305,
        "bert_recall": 0.8909749388694763,
        "bert_f1": 0.8678487539291382,
        "meteor": 0.0,
        "sbert_similarity": 0.17644499242305756
      }
    },
    {
      "sample_id": 0,
      "question": "What was grandpa's gift to Caroline?",
      "prediction": "necklace",
      "reference": "necklace",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 0.9999998807907104,
        "bert_recall": 0.9999998807907104,
        "bert_f1": 0.9999998807907104,
        "meteor": 0.5,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What is Caroline's hand-painted bowl a reminder of?",
      "prediction": "art and self-expression",
      "reference": "art and self-expression",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline and her family do while camping?",
      "prediction": "explored nature, roasted marshmallows, and went on a hike",
      "reference": "explored nature, roasted marshmallows, and went on a hike",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9993141289437586,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of counseling and mental health services is Melanie interested in pursuing?",
      "prediction": "Not mentioned in the conversation",
      "reference": "working with trans people, helping them accept themselves and supporting their mental health",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8718170523643494,
        "bert_recall": 0.8251791000366211,
        "bert_f1": 0.8478571772575378,
        "meteor": 0.0,
        "sbert_similarity": 0.05818859860301018
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of counseling workshop did Melanie attend recently?",
      "prediction": "LGBTQ+ counseling workshop",
      "reference": "LGBTQ+ counseling workshop",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What motivated Melanie to pursue counseling?",
      "prediction": "Not mentioned in the conversation",
      "reference": "her own journey and the support she received, and how counseling improved her life",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.11764705882352941,
        "rouge1_f": 0.10526315789473682,
        "rouge2_f": 0.0,
        "rougeL_f": 0.10526315789473682,
        "bleu1": 0.027067056647322542,
        "bleu2": 0.009569649651041096,
        "bleu3": 0.007666923387854731,
        "bleu4": 0.007271361304044331,
        "bert_precision": 0.8843756914138794,
        "bert_recall": 0.8464586734771729,
        "bert_f1": 0.8650018572807312,
        "meteor": 0.038167938931297704,
        "sbert_similarity": 0.004239106550812721
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of place does Melanie want to create for people?",
      "prediction": "a safe and inviting place for people to grow",
      "reference": "a safe and inviting place for people to grow",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9993141289437586,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "Did Caroline make the black and white bowl in the photo?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Yes",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8480531573295593,
        "bert_recall": 0.8904053568840027,
        "bert_f1": 0.86871337890625,
        "meteor": 0.0,
        "sbert_similarity": 0.11724157631397247
      }
    },
    {
      "sample_id": 0,
      "question": "What are the new shoes that Caroline got used for?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Running",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8501412272453308,
        "bert_recall": 0.8962053060531616,
        "bert_f1": 0.872565746307373,
        "meteor": 0.0,
        "sbert_similarity": 0.16544069349765778
      }
    },
    {
      "sample_id": 0,
      "question": "What is Caroline's reason for getting into running?",
      "prediction": "To de-stress and clear her mind",
      "reference": "To de-stress and clear her mind",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9976851851851852,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What does Caroline say running has been great for?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Her mental health",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8695220351219177,
        "bert_recall": 0.8530551195144653,
        "bert_f1": 0.8612099289894104,
        "meteor": 0.0,
        "sbert_similarity": 0.20801006257534027
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie see at the council meeting for adoption?",
      "prediction": "many people wanting to create loving homes for children in need",
      "reference": "many people wanting to create loving homes for children in need",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9996243425995492,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What inspired Melanie's painting for the art show?",
      "prediction": "Not mentioned in the conversation",
      "reference": "visiting an LGBTQ center and wanting to capture unity and strength",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8672130703926086,
        "bert_recall": 0.8251693844795227,
        "bert_f1": 0.8456689715385437,
        "meteor": 0.0,
        "sbert_similarity": -0.0016055628657341003
      }
    },
    {
      "sample_id": 0,
      "question": "What inspired Caroline's sculpture for the art show?",
      "prediction": "visiting an LGBTQ center and wanting to capture unity and strength",
      "reference": "visiting an LGBTQ center and wanting to capture unity and strength",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9996243425995492,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "How often does Caroline go to the beach with her kids?",
      "prediction": "Not mentioned in the conversation",
      "reference": "once or twice a year",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8639419078826904,
        "bert_recall": 0.807560920715332,
        "bert_f1": 0.8348005414009094,
        "meteor": 0.0,
        "sbert_similarity": 0.053056757897138596
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline and her family see during their camping trip last year?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Perseid meteor shower",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8497328758239746,
        "bert_recall": 0.7694872617721558,
        "bert_f1": 0.8076216578483582,
        "meteor": 0.0,
        "sbert_similarity": 0.033341631293296814
      }
    },
    {
      "sample_id": 0,
      "question": "How did Caroline feel while watching the meteor shower?",
      "prediction": "in awe of the universe",
      "reference": "in awe of the universe",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.996,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Caroline choose to use colors and patterns in her pottery project?",
      "prediction": "Not mentioned in the conversation",
      "reference": "She wanted to catch the eye and make people smile.",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.13333333333333333,
        "rouge1_f": 0.13333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.13333333333333333,
        "bleu1": 0.060238842382440407,
        "bleu2": 0.02129764696972561,
        "bleu3": 0.01706305179528683,
        "bleu4": 0.016182712188007015,
        "bert_precision": 0.8825768828392029,
        "bert_recall": 0.872012197971344,
        "bert_f1": 0.8772627115249634,
        "meteor": 0.052631578947368425,
        "sbert_similarity": 0.04110638052225113
      }
    },
    {
      "sample_id": 0,
      "question": "Is Oscar Melanie's pet?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Yes",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8480531573295593,
        "bert_recall": 0.8904053568840027,
        "bert_f1": 0.86871337890625,
        "meteor": 0.0,
        "sbert_similarity": 0.11724157631397247
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Oscar hide his bone once?",
      "prediction": "In Melanie's slipper",
      "reference": "In Melanie's slipper",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What activity did Melanie used to do with her dad?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Horseback riding",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8533903360366821,
        "bert_recall": 0.7734709978103638,
        "bert_f1": 0.8114676475524902,
        "meteor": 0.0,
        "sbert_similarity": 0.05627931281924248
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie make for a local church?",
      "prediction": "Not mentioned in the conversation",
      "reference": "a stained glass window",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8690840005874634,
        "bert_recall": 0.8363252282142639,
        "bert_f1": 0.852389931678772,
        "meteor": 0.0,
        "sbert_similarity": 0.036170121282339096
      }
    },
    {
      "sample_id": 0,
      "question": "What did Melanie find in her neighborhood during her walk?",
      "prediction": "Not mentioned in the conversation",
      "reference": "a rainbow sidewalk",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8700211048126221,
        "bert_recall": 0.8560808897018433,
        "bert_f1": 0.8629946708679199,
        "meteor": 0.0,
        "sbert_similarity": -0.048551276326179504
      }
    },
    {
      "sample_id": 0,
      "question": "Which song motivates Melanie to be courageous?",
      "prediction": "Brave by Sara Bareilles",
      "reference": "Brave by Sara Bareilles",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9921875,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What type of instrument does Caroline play?",
      "prediction": "Not mentioned in the conversation",
      "reference": "clarinet and violin",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8583568930625916,
        "bert_recall": 0.7918204069137573,
        "bert_f1": 0.8237472772598267,
        "meteor": 0.0,
        "sbert_similarity": 0.012888399884104729
      }
    },
    {
      "sample_id": 0,
      "question": "Which classical musicians does Caroline enjoy listening to?",
      "prediction": "Bach and Mozart",
      "reference": "Bach and Mozart",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 0.9999998807907104,
        "bert_recall": 0.9999998807907104,
        "bert_f1": 0.9999998807907104,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "Who is Caroline a fan of in terms of modern music?",
      "prediction": "Ed Sheeran",
      "reference": "Ed Sheeran",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 0.46773514128719823,
        "bleu4": 0.316227766016838,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9375,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What precautionary sign did Caroline see at the café?",
      "prediction": "A sign stating that someone is not being able to leave",
      "reference": "A sign stating that someone is not being able to leave",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9996243425995492,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What setback did Caroline face recently?",
      "prediction": "Not mentioned in the conversation",
      "reference": "She got hurt and had to take a break from pottery.",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.886946439743042,
        "bert_recall": 0.8621916770935059,
        "bert_f1": 0.874393880367279,
        "meteor": 0.0,
        "sbert_similarity": 0.03774170204997063
      }
    },
    {
      "sample_id": 0,
      "question": "What does Caroline do to keep herself busy during her pottery break?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Read a book and paint.",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8759545683860779,
        "bert_recall": 0.8547960519790649,
        "bert_f1": 0.8652459979057312,
        "meteor": 0.0,
        "sbert_similarity": 0.08983373641967773
      }
    },
    {
      "sample_id": 0,
      "question": "What was the poetry reading that Melanie attended about?",
      "prediction": "Not mentioned in the conversation",
      "reference": "It was a transgender poetry reading where transgender people shared their stories.",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8824484944343567,
        "bert_recall": 0.8453162908554077,
        "bert_f1": 0.8634833097457886,
        "meteor": 0.0,
        "sbert_similarity": 0.08634094893932343
      }
    },
    {
      "sample_id": 0,
      "question": "What happened to Caroline's son on their road trip?",
      "prediction": "He got into an accident",
      "reference": "He got into an accident",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.996,
        "sbert_similarity": 0.9999999403953552
      }
    },
    {
      "sample_id": 0,
      "question": "How did Caroline's son handle the accident?",
      "prediction": "Not mentioned in the conversation",
      "reference": "He was scared but reassured by his family",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8755667209625244,
        "bert_recall": 0.8454297780990601,
        "bert_f1": 0.8602343797683716,
        "meteor": 0.0,
        "sbert_similarity": 0.12110542505979538
      }
    },
    {
      "sample_id": 0,
      "question": "How did Caroline feel about her family after the accident?",
      "prediction": "They are important and mean the world to her",
      "reference": "They are important and mean the world to her",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9993141289437586,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "How did Caroline's children handle the accident?",
      "prediction": "Not mentioned in the conversation",
      "reference": "They were scared but resilient",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8781700134277344,
        "bert_recall": 0.8506824970245361,
        "bert_f1": 0.8642077445983887,
        "meteor": 0.0,
        "sbert_similarity": 0.07462234795093536
      }
    },
    {
      "sample_id": 0,
      "question": "How did Caroline feel after the accident?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Grateful and thankful for her family",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8705778121948242,
        "bert_recall": 0.819611668586731,
        "bert_f1": 0.8443263173103333,
        "meteor": 0.0,
        "sbert_similarity": 0.012023823335766792
      }
    },
    {
      "sample_id": 0,
      "question": "What was Caroline's reaction to her children enjoying the Grand Canyon?",
      "prediction": "Not mentioned in the conversation",
      "reference": "She was happy and thankful",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8730798959732056,
        "bert_recall": 0.8435055017471313,
        "bert_f1": 0.8580379486083984,
        "meteor": 0.0,
        "sbert_similarity": 0.026393620297312737
      }
    },
    {
      "sample_id": 0,
      "question": "What did Caroline do after the road trip to relax?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Went on a nature walk or hike",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8826771974563599,
        "bert_recall": 0.8326032161712646,
        "bert_f1": 0.8569092750549316,
        "meteor": 0.0,
        "sbert_similarity": 0.06870593130588531
      }
    },
    {
      "sample_id": 0,
      "question": "What does Caroline love most about camping with her family?",
      "prediction": "Being present and bonding with her family",
      "reference": "Being present and bonding with her family",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0000001192092896,
        "bert_recall": 1.0000001192092896,
        "bert_f1": 1.0000001192092896,
        "meteor": 0.9985422740524781,
        "sbert_similarity": 1.0
      }
    }
  ]
}