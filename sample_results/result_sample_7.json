{
  "sample_idx": 7,
  "total_questions": 239,
  "individual_results": [
    {
      "sample_id": 0,
      "question": "What kind of project was Jolene working on in the beginning of January 2023?",
      "prediction": "engineering project - neat solutions",
      "reference": "electricity engineering project",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.5714285714285715,
        "rouge2_f": 0.4,
        "rougeL_f": 0.5714285714285715,
        "bleu1": 0.4,
        "bleu2": 0.316227766016838,
        "bleu3": 0.1522474354853864,
        "bleu4": 0.11362193664674995,
        "bert_precision": 0.9007556438446045,
        "bert_recall": 0.9145104885101318,
        "bert_f1": 0.9075809717178345,
        "meteor": 0.5859375,
        "sbert_similarity": 0.49516618251800537
      }
    },
    {
      "sample_id": 0,
      "question": "Which of Deborah`s family and friends have passed away?",
      "prediction": "her dad and her mother",
      "reference": "mother, father, her friend Karlie",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4444444444444445,
        "rouge1_f": 0.4000000000000001,
        "rouge2_f": 0.0,
        "rougeL_f": 0.20000000000000004,
        "bleu1": 0.26812801841425576,
        "bleu2": 0.06703200460356394,
        "bleu3": 0.04773447970124341,
        "bleu4": 0.04282963710525157,
        "bert_precision": 0.8900191783905029,
        "bert_recall": 0.8550959229469299,
        "bert_f1": 0.8722081184387207,
        "meteor": 0.10000000000000002,
        "sbert_similarity": 0.7003157138824463
      }
    },
    {
      "sample_id": 0,
      "question": "When did Deborah`s mother pass away?",
      "prediction": "a few years ago",
      "reference": "a few years before 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666665,
        "rouge1_f": 0.6666666666666665,
        "rouge2_f": 0.5714285714285715,
        "rougeL_f": 0.6666666666666665,
        "bleu1": 0.5841005873035536,
        "bleu2": 0.5506953149031837,
        "bleu3": 0.49288611328092413,
        "bleu4": 0.3096787331587729,
        "bert_precision": 0.8752714991569519,
        "bert_recall": 0.8604716062545776,
        "bert_f1": 0.8678085207939148,
        "meteor": 0.600907029478458,
        "sbert_similarity": 0.507144570350647
      }
    },
    {
      "sample_id": 0,
      "question": "When did Jolene`s mother pass away?",
      "prediction": "last year",
      "reference": "in 2022",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8903499245643616,
        "bert_recall": 0.8903499245643616,
        "bert_f1": 0.8903499245643616,
        "meteor": 0.0,
        "sbert_similarity": 0.4300100803375244
      }
    },
    {
      "sample_id": 0,
      "question": "When did Jolene's mom gift her a pendant?",
      "prediction": "in 2010",
      "reference": "in 2010",
      "category": 2,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 0.46773514128719823,
        "bleu4": 0.316227766016838,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9375,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "In what country did Jolene's mother buy her the pendant?",
      "prediction": "in Paris",
      "reference": "In France",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.5,
        "rouge2_f": 0.0,
        "rougeL_f": 0.5,
        "bleu1": 0.5,
        "bleu2": 0.223606797749979,
        "bleu3": 0.1740444189610778,
        "bleu4": 0.1495348781221221,
        "bert_precision": 0.9529480934143066,
        "bert_recall": 0.9529480934143066,
        "bert_f1": 0.9529480934143066,
        "meteor": 0.25,
        "sbert_similarity": 0.8453105688095093
      }
    },
    {
      "sample_id": 0,
      "question": "What symbolic gifts do Deborah and Jolene have from their mothers?",
      "prediction": "Deborah has a pendant that reminds her of her mother, and Jolene has a pendant that her mother gave her in 2010 in Paris.",
      "reference": "pendants",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.07999999999999999,
        "rouge2_f": 0.0,
        "rougeL_f": 0.07999999999999999,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8016173243522644,
        "bert_recall": 0.8038001656532288,
        "bert_f1": 0.802707314491272,
        "meteor": 0.15151515151515152,
        "sbert_similarity": 0.464483380317688
      }
    },
    {
      "sample_id": 0,
      "question": "Which country were Jolene and her mother visiting in 2010?",
      "prediction": "not mentioned",
      "reference": "France",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8303878307342529,
        "bert_recall": 0.8996553421020508,
        "bert_f1": 0.8636349439620972,
        "meteor": 0.0,
        "sbert_similarity": 0.18729925155639648
      }
    },
    {
      "sample_id": 0,
      "question": "What helped Deborah find peace when grieving deaths of her loved ones?",
      "prediction": "spending time in the garden to find some comfort, yoga helped me find peace, finding ways to keep her memory alive, artwork can bring back powerful emotions.",
      "reference": "yoga, old photos, the roses and dahlias in a flower garden, nature",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.21621621621621623,
        "rouge1_f": 0.20512820512820512,
        "rouge2_f": 0.0,
        "rougeL_f": 0.10256410256410256,
        "bleu1": 0.2258064516129032,
        "bleu2": 0.027435163058436723,
        "bleu3": 0.01434470564414865,
        "bleu4": 0.009812163258584559,
        "bert_precision": 0.8367709517478943,
        "bert_recall": 0.8353767991065979,
        "bert_f1": 0.8360732793807983,
        "meteor": 0.07407407407407407,
        "sbert_similarity": 0.6391858458518982
      }
    },
    {
      "sample_id": 0,
      "question": "When did Deborah's father pass away?",
      "prediction": "25 January, 2023",
      "reference": "January 25, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 1.0,
        "bleu2": 0.5773502691896257,
        "bleu3": 0.2589465250642332,
        "bleu4": 0.20205155046766235,
        "bert_precision": 0.9396669864654541,
        "bert_recall": 0.9406899213790894,
        "bert_f1": 0.9401781558990479,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.9727412462234497
      }
    },
    {
      "sample_id": 0,
      "question": "When was Deborah's parents' wedding?",
      "prediction": "1993",
      "reference": "in 1993",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.36787944117144233,
        "bleu2": 0.11633369384516798,
        "bleu3": 0.08048325236348887,
        "bleu4": 0.06541924356118012,
        "bert_precision": 0.9139392375946045,
        "bert_recall": 0.8701047897338867,
        "bert_f1": 0.8914834856987,
        "meteor": 0.2631578947368421,
        "sbert_similarity": 0.8767057061195374
      }
    },
    {
      "sample_id": 0,
      "question": "Is Deborah married?",
      "prediction": "The content does not indicate whether Deborah is married.",
      "reference": "yes",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7942672967910767,
        "bert_recall": 0.8070852160453796,
        "bert_f1": 0.8006249666213989,
        "meteor": 0.0,
        "sbert_similarity": -0.05199442803859711
      }
    },
    {
      "sample_id": 0,
      "question": "When did Deborah receive an appreciation letter from her community?",
      "prediction": "27 January, 2023",
      "reference": "January 26, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.75,
        "bleu2": 0.49999999999999994,
        "bleu3": 0.23549424823785386,
        "bleu4": 0.1880301546543197,
        "bert_precision": 0.9431314468383789,
        "bert_recall": 0.9427858591079712,
        "bert_f1": 0.942958652973175,
        "meteor": 0.16666666666666666,
        "sbert_similarity": 0.961574375629425
      }
    },
    {
      "sample_id": 0,
      "question": "What places give Deborah peace?",
      "prediction": "Sitting in that spot by the window gives me peace; I like to come to this spot by the water near my mom's old house.",
      "reference": "sitting in a spot by the window in her Mom's house, sitting by the beach, Bali, forest trail in a nearby park",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4324324324324324,
        "rouge1_f": 0.44897959183673475,
        "rouge2_f": 0.2553191489361702,
        "rougeL_f": 0.36734693877551017,
        "bleu1": 0.39285714285714285,
        "bleu2": 0.29546842014263947,
        "bleu3": 0.19183860158168095,
        "bleu4": 0.1280220256953781,
        "bert_precision": 0.8835722208023071,
        "bert_recall": 0.8764047622680664,
        "bert_f1": 0.8799738883972168,
        "meteor": 0.343796711509716,
        "sbert_similarity": 0.5309560894966125
      }
    },
    {
      "sample_id": 0,
      "question": "What were Deborah's mother's hobbies?",
      "prediction": "reading was one of her hobbies.",
      "reference": "reading, traveling, art, cooking",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2,
        "rouge1_f": 0.2,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2,
        "bleu1": 0.14285714285714285,
        "bleu2": 0.048795003647426664,
        "bleu3": 0.037468614372419724,
        "bleu4": 0.033031643180138064,
        "bert_precision": 0.8394798040390015,
        "bert_recall": 0.7779601812362671,
        "bert_f1": 0.8075500130653381,
        "meteor": 0.0,
        "sbert_similarity": 0.4805126190185547
      }
    },
    {
      "sample_id": 0,
      "question": "What pets does Jolene have?",
      "prediction": "snakes",
      "reference": "snakes",
      "category": 4,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.5,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What are the names of Jolene's snakes?",
      "prediction": "Susie and Seraphim",
      "reference": "Susie, Seraphim",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8,
        "rouge1_f": 0.8,
        "rouge2_f": 0.0,
        "rougeL_f": 0.8,
        "bleu1": 0.6666666666666666,
        "bleu2": 0.18257418583505536,
        "bleu3": 0.1522474354853864,
        "bleu4": 0.13512001548070346,
        "bert_precision": 0.9420279860496521,
        "bert_recall": 0.9420279860496521,
        "bert_f1": 0.9420279860496521,
        "meteor": 0.2380952380952381,
        "sbert_similarity": 0.917330265045166
      }
    },
    {
      "sample_id": 0,
      "question": "When did Jolene buy her pet Seraphim?",
      "prediction": "day before yesterday from 26 June 2023",
      "reference": "in 2022",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7956005334854126,
        "bert_recall": 0.8933190107345581,
        "bert_f1": 0.8416328430175781,
        "meteor": 0.0,
        "sbert_similarity": 0.5163872241973877
      }
    },
    {
      "sample_id": 0,
      "question": "In what country did Jolene buy snake Seraphim?",
      "prediction": "The context does not specify the country where Jolene bought snake Seraphim.",
      "reference": "In France",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8087595105171204,
        "bert_recall": 0.8309645056724548,
        "bert_f1": 0.8197116851806641,
        "meteor": 0.0,
        "sbert_similarity": 0.22848404943943024
      }
    },
    {
      "sample_id": 0,
      "question": "How many times has Jolene been to France?",
      "prediction": "I bought it a year ago in Paris.",
      "reference": "two times",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8478602766990662,
        "bert_recall": 0.8322152495384216,
        "bert_f1": 0.8399648666381836,
        "meteor": 0.0,
        "sbert_similarity": 0.07102334499359131
      }
    },
    {
      "sample_id": 0,
      "question": "Which games have Jolene and her partner played together?",
      "prediction": "we played the game \"Detroit\" on the console and we love playing \"It Takes Two\" together!",
      "reference": "Detroit, Walking Dead, Battlefield 1, It Takes Two, Overcooked 2",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.08333333333333333,
        "rouge1_f": 0.3076923076923077,
        "rouge2_f": 0.16666666666666669,
        "rougeL_f": 0.3076923076923077,
        "bleu1": 0.19047619047619047,
        "bleu2": 0.13801311186847087,
        "bleu3": 0.10241386152405135,
        "bleu4": 0.04857956790684703,
        "bert_precision": 0.8579739928245544,
        "bert_recall": 0.8557990789413452,
        "bert_f1": 0.8568851947784424,
        "meteor": 0.04716981132075472,
        "sbert_similarity": 0.5486001968383789
      }
    },
    {
      "sample_id": 0,
      "question": "When do Jolene and her partner plan to complete the game \"Walking Dead\"?",
      "prediction": "next Saturday",
      "reference": "Saturday after 27 January, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.28571428571428575,
        "rouge1_f": 0.28571428571428575,
        "rouge2_f": 0.0,
        "rougeL_f": 0.28571428571428575,
        "bleu1": 0.06766764161830635,
        "bleu2": 0.030261889307125377,
        "bleu3": 0.02355435073584915,
        "bleu4": 0.020237345084409754,
        "bert_precision": 0.8855602741241455,
        "bert_recall": 0.8156474828720093,
        "bert_f1": 0.8491672873497009,
        "meteor": 0.10638297872340426,
        "sbert_similarity": 0.6846433877944946
      }
    },
    {
      "sample_id": 0,
      "question": "When did Deborah meet Anna?",
      "prediction": "yesterday, 1 February, 2023",
      "reference": "31 January, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.28571428571428575,
        "rouge1_f": 0.28571428571428575,
        "rouge2_f": 0.0,
        "rougeL_f": 0.28571428571428575,
        "bleu1": 0.3333333333333333,
        "bleu2": 0.25819888974716115,
        "bleu3": 0.12111838948674812,
        "bleu4": 0.08633400213704504,
        "bert_precision": 0.9340639114379883,
        "bert_recall": 0.9596068859100342,
        "bert_f1": 0.9466631412506104,
        "meteor": 0.16129032258064518,
        "sbert_similarity": 0.8269302248954773
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Jolene sometimes put off doing yoga?",
      "prediction": "I've been doing them sporadically for about 3 years now.",
      "reference": "She's more interested in playing video games",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8526101112365723,
        "bert_recall": 0.858076810836792,
        "bert_f1": 0.8553347587585449,
        "meteor": 0.0,
        "sbert_similarity": 0.10766670107841492
      }
    },
    {
      "sample_id": 0,
      "question": "What new yoga poses did Deborah try?",
      "prediction": "Dancer Pose (Natarajasana)",
      "reference": "Warrior II, Dancer Pose (Natarajasana), Tree pose",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6,
        "bleu1": 0.301194211912202,
        "bleu2": 0.301194211912202,
        "bleu3": 0.301194211912202,
        "bleu4": 0.301194211912202,
        "bert_precision": 0.9622845649719238,
        "bert_recall": 0.9185789823532104,
        "bert_f1": 0.9399240016937256,
        "meteor": 0.15151515151515152,
        "sbert_similarity": 0.7920750975608826
      }
    },
    {
      "sample_id": 0,
      "question": "What are Jolene's favorite books?",
      "prediction": "I'd love to hear your thoughts.",
      "reference": "Sapiens, Avalanche by Neal Stephenson",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8257796764373779,
        "bert_recall": 0.7985783219337463,
        "bert_f1": 0.8119512796401978,
        "meteor": 0.0,
        "sbert_similarity": 0.11321403086185455
      }
    },
    {
      "sample_id": 0,
      "question": "Which book did Jolene read in January 2023?",
      "prediction": "Reading was one of her hobbies.",
      "reference": "Avalanche by Neal Stephenson",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8416898250579834,
        "bert_recall": 0.8155964016914368,
        "bert_f1": 0.8284377455711365,
        "meteor": 0.0,
        "sbert_similarity": 0.10190653055906296
      }
    },
    {
      "sample_id": 0,
      "question": "When was Jolene in Bogota?",
      "prediction": "last summer",
      "reference": "in summer 2022",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0.3032653298563167,
        "bleu2": 0.13562437855552414,
        "bleu3": 0.10556327625176448,
        "bleu4": 0.09069748827745895,
        "bert_precision": 0.9141435623168945,
        "bert_recall": 0.8921791315078735,
        "bert_f1": 0.9030278325080872,
        "meteor": 0.17241379310344826,
        "sbert_similarity": 0.5721912384033203
      }
    },
    {
      "sample_id": 0,
      "question": "In what country was Jolene during summer 2022?",
      "prediction": "The context does not provide information about the country where Jolene was during summer 2022.",
      "reference": "Colombia",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8014283180236816,
        "bert_recall": 0.8197374939918518,
        "bert_f1": 0.8104795217514038,
        "meteor": 0.0,
        "sbert_similarity": 0.11507361382246017
      }
    },
    {
      "sample_id": 0,
      "question": "When did Jolene have a mini-retreat to reflect on her career?",
      "prediction": "Last Wednesday, 9 February, 2023",
      "reference": "Wednesday before 9 February, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8000000000000002,
        "rouge1_f": 0.8000000000000002,
        "rouge2_f": 0.5,
        "rougeL_f": 0.8000000000000002,
        "bleu1": 0.7142857142857143,
        "bleu2": 0.5976143046671969,
        "bleu3": 0.5261597794341889,
        "bleu4": 0.4347208719449914,
        "bert_precision": 0.9215463995933533,
        "bert_recall": 0.9220494031906128,
        "bert_f1": 0.9217978715896606,
        "meteor": 0.5888888888888889,
        "sbert_similarity": 0.9271985292434692
      }
    },
    {
      "sample_id": 0,
      "question": "When did Jolene have a dinner and drinks with her friends?",
      "prediction": "last night - 21 February, 2023",
      "reference": "21 February, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.7499999999999999,
        "rouge2_f": 0.6666666666666666,
        "rougeL_f": 0.7499999999999999,
        "bleu1": 0.5714285714285714,
        "bleu2": 0.5345224838248488,
        "bleu3": 0.4888069165703076,
        "bleu4": 0.41113361690051975,
        "bert_precision": 0.9130351543426514,
        "bert_recall": 0.9370933175086975,
        "bert_f1": 0.9249078631401062,
        "meteor": 0.8922558922558923,
        "sbert_similarity": 0.7692477107048035
      }
    },
    {
      "sample_id": 0,
      "question": "When was the last photo of Deborah and Karlie taken?",
      "prediction": "last summer",
      "reference": "in summer 2022",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0.3032653298563167,
        "bleu2": 0.13562437855552414,
        "bleu3": 0.10556327625176448,
        "bleu4": 0.09069748827745895,
        "bert_precision": 0.9141435623168945,
        "bert_recall": 0.8921791315078735,
        "bert_f1": 0.9030278325080872,
        "meteor": 0.17241379310344826,
        "sbert_similarity": 0.5721912384033203
      }
    },
    {
      "sample_id": 0,
      "question": "When was Deborah in Bali?",
      "prediction": "last year",
      "reference": "in 2022",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8903499245643616,
        "bert_recall": 0.8903499245643616,
        "bert_f1": 0.8903499245643616,
        "meteor": 0.0,
        "sbert_similarity": 0.4300100803375244
      }
    },
    {
      "sample_id": 0,
      "question": "How long have Jolene and her partner been together?",
      "prediction": "The dialogue does not explicitly mention how long Jolene and her partner have been together.",
      "reference": "for three years",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8223179578781128,
        "bert_recall": 0.8376016616821289,
        "bert_f1": 0.8298894166946411,
        "meteor": 0.0,
        "sbert_similarity": 0.16401098668575287
      }
    },
    {
      "sample_id": 0,
      "question": "Which year did Jolene and her partner start dating?",
      "prediction": "two years ago",
      "reference": "2020",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7638366222381592,
        "bert_recall": 0.8419572114944458,
        "bert_f1": 0.8009966611862183,
        "meteor": 0.0,
        "sbert_similarity": 0.39606285095214844
      }
    },
    {
      "sample_id": 0,
      "question": "When did Deborah go for her first morning jog in a nearby park?",
      "prediction": "yesterday, 25 February, 2023",
      "reference": "24 February, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5714285714285715,
        "rouge1_f": 0.5714285714285715,
        "rouge2_f": 0.4,
        "rougeL_f": 0.5714285714285715,
        "bleu1": 0.5,
        "bleu2": 0.447213595499958,
        "bleu3": 0.3721003696282278,
        "bleu4": 0.20205155046766235,
        "bert_precision": 0.9442534446716309,
        "bert_recall": 0.9774687886238098,
        "bert_f1": 0.9605740904808044,
        "meteor": 0.6048387096774195,
        "sbert_similarity": 0.8928964138031006
      }
    },
    {
      "sample_id": 0,
      "question": "How old is Jolene?",
      "prediction": "The content does not specify Jolene's age.",
      "reference": "likely no more than 30; since she's in school",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.11111111111111112,
        "rouge2_f": 0.0,
        "rougeL_f": 0.11111111111111112,
        "bleu1": 0.08897082254631197,
        "bleu2": 0.02984172108414368,
        "bleu3": 0.022474396477098004,
        "bleu4": 0.019201920550239778,
        "bert_precision": 0.8581125736236572,
        "bert_recall": 0.8390934467315674,
        "bert_f1": 0.8484964370727539,
        "meteor": 0.0,
        "sbert_similarity": 0.46942955255508423
      }
    },
    {
      "sample_id": 0,
      "question": "When did Jolene take Seraphim to the park?",
      "prediction": "last Sunday, 26 February 2023",
      "reference": "Sunday before 2 March, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4000000000000001,
        "rouge1_f": 0.4000000000000001,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4000000000000001,
        "bleu1": 0.5,
        "bleu2": 0.10000000000000002,
        "bleu3": 0.06476199262714716,
        "bleu4": 0.05372849659117709,
        "bert_precision": 0.8947439789772034,
        "bert_recall": 0.8934895396232605,
        "bert_f1": 0.8941162824630737,
        "meteor": 0.10000000000000002,
        "sbert_similarity": 0.8800313472747803
      }
    },
    {
      "sample_id": 0,
      "question": "When did Deborah start the yoga class in the neighborhood?",
      "prediction": "11 March, 2023",
      "reference": "Friday before 13 March, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.5,
        "rouge2_f": 0.3333333333333333,
        "rougeL_f": 0.5,
        "bleu1": 0.45489799478447507,
        "bleu2": 0.4288819424803534,
        "bleu3": 0.3838600909882049,
        "bleu4": 0.24117803988461298,
        "bert_precision": 0.9520367383956909,
        "bert_recall": 0.9125669598579407,
        "bert_f1": 0.9318840503692627,
        "meteor": 0.39062499999999994,
        "sbert_similarity": 0.8101233839988708
      }
    },
    {
      "sample_id": 0,
      "question": "What time management techniques do Deborah and Jolene use?",
      "prediction": "break it into smaller pieces, set goals for yourself, use planners or schedulers, create a daily schedule or to-do list, and maintain a routine.",
      "reference": "the Pomodoro Technique - 25 minutes work and 5-minute break, scheduler or to-do list, The Eisenhower Matrix, bullet journal",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.3111111111111111,
        "rouge2_f": 0.186046511627907,
        "rougeL_f": 0.2666666666666666,
        "bleu1": 0.27586206896551724,
        "bleu2": 0.1719204765183758,
        "bleu3": 0.13252752166636678,
        "bleu4": 0.09579371674972276,
        "bert_precision": 0.88422030210495,
        "bert_recall": 0.8531892895698547,
        "bert_f1": 0.8684276938438416,
        "meteor": 0.2482051282051282,
        "sbert_similarity": 0.49022918939590454
      }
    },
    {
      "sample_id": 0,
      "question": "Does Deborah live close to the beach or the mountains?",
      "prediction": "Deborah loves a beach nearby.",
      "reference": "beach",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.33333333333333337,
        "rouge1_f": 0.33333333333333337,
        "rouge2_f": 0.0,
        "rougeL_f": 0.33333333333333337,
        "bleu1": 0.16666666666666669,
        "bleu2": 0.05773502691896258,
        "bleu3": 0.04506819749679463,
        "bleu4": 0.040824829046386304,
        "bert_precision": 0.842881441116333,
        "bert_recall": 0.8701379895210266,
        "bert_f1": 0.8562929034233093,
        "meteor": 0.35714285714285715,
        "sbert_similarity": 0.5495856404304504
      }
    },
    {
      "sample_id": 0,
      "question": "What ways do Deborah and Jolene use to enhance their yoga practice?",
      "prediction": "They enhance their yoga practice through meditation, mindfulness, and attending retreats.",
      "reference": "candles, music, essential oils",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0.14285714285714285,
        "bleu2": 0.033149677206589796,
        "bleu3": 0.021746357799665227,
        "bleu4": 0.0169861974906263,
        "bert_precision": 0.8470668792724609,
        "bert_recall": 0.8189827799797058,
        "bert_f1": 0.8327881097793579,
        "meteor": 0.0,
        "sbert_similarity": 0.2257765531539917
      }
    },
    {
      "sample_id": 0,
      "question": "What music pieces does Deborah listen to during her yoga practice?",
      "prediction": "The provided context does not mention any specific music pieces that Deborah listens to during her yoga practice.",
      "reference": "Savana, Sleep",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.823219358921051,
        "bert_recall": 0.8077802658081055,
        "bert_f1": 0.815426766872406,
        "meteor": 0.0,
        "sbert_similarity": 0.19413132965564728
      }
    },
    {
      "sample_id": 0,
      "question": "When did Deborah go for a bicycle ride with Anna?",
      "prediction": "last week on 9 April, 2023",
      "reference": "first week of April, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5454545454545454,
        "rouge1_f": 0.5454545454545454,
        "rouge2_f": 0.22222222222222224,
        "rougeL_f": 0.5454545454545454,
        "bleu1": 0.5714285714285714,
        "bleu2": 0.4364357804719847,
        "bleu3": 0.34016320005192946,
        "bleu4": 0.17567205239427922,
        "bert_precision": 0.9256477355957031,
        "bert_recall": 0.9397284984588623,
        "bert_f1": 0.9326349496841431,
        "meteor": 0.5010893246187365,
        "sbert_similarity": 0.775262176990509
      }
    },
    {
      "sample_id": 0,
      "question": "When did Deborah go to an art show with Anna?",
      "prediction": "9 April, 2023",
      "reference": "on 9 April, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8571428571428571,
        "rouge1_f": 0.8571428571428571,
        "rouge2_f": 0.8,
        "rougeL_f": 0.8571428571428571,
        "bleu1": 0.7788007830714049,
        "bleu2": 0.7788007830714049,
        "bleu3": 0.7788007830714049,
        "bleu4": 0.7788007830714049,
        "bert_precision": 0.9859722852706909,
        "bert_recall": 0.9616531133651733,
        "bert_f1": 0.9736608862876892,
        "meteor": 0.754985754985755,
        "sbert_similarity": 0.9489181041717529
      }
    },
    {
      "sample_id": 0,
      "question": "When did Jolene finish her robotics project?",
      "prediction": "1 February, 2023",
      "reference": "May 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0.25,
        "bleu2": 0.09128709291752769,
        "bleu3": 0.07665320007195604,
        "bleu4": 0.08034284189446518,
        "bert_precision": 0.8839268684387207,
        "bert_recall": 0.9462015628814697,
        "bert_f1": 0.9140046834945679,
        "meteor": 0.2380952380952381,
        "sbert_similarity": 0.7903925776481628
      }
    },
    {
      "sample_id": 0,
      "question": "How long did Jolene work on the robotics project given to her by her Professor?",
      "prediction": "From February 1 to June 6, approximately 4 months.",
      "reference": "four months",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.1818181818181818,
        "rouge1_f": 0.1818181818181818,
        "rouge2_f": 0.0,
        "rougeL_f": 0.1818181818181818,
        "bleu1": 0.0909090909090909,
        "bleu2": 0.03015113445777637,
        "bleu3": 0.022461584318318094,
        "bleu4": 0.018850319022747353,
        "bert_precision": 0.8344206809997559,
        "bert_recall": 0.9160614013671875,
        "bert_f1": 0.8733372092247009,
        "meteor": 0.1851851851851852,
        "sbert_similarity": 0.6687402725219727
      }
    },
    {
      "sample_id": 0,
      "question": "When did Jolene do yoga at Talkeetna?",
      "prediction": "6 June, 2023",
      "reference": "on 5 June, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5714285714285715,
        "rouge1_f": 0.5714285714285715,
        "rouge2_f": 0.4,
        "rougeL_f": 0.5714285714285715,
        "bleu1": 0.5841005873035536,
        "bleu2": 0.5506953149031837,
        "bleu3": 0.49288611328092413,
        "bleu4": 0.3096787331587729,
        "bert_precision": 0.9831874370574951,
        "bert_recall": 0.9581049680709839,
        "bert_f1": 0.9704841375350952,
        "meteor": 0.48076923076923084,
        "sbert_similarity": 0.8578799962997437
      }
    },
    {
      "sample_id": 0,
      "question": "Which US state did Jolene visit during her internship?",
      "prediction": "The context does not mention which US state Jolene visited during her internship.",
      "reference": "Alaska",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8036243915557861,
        "bert_recall": 0.8196306824684143,
        "bert_f1": 0.81154865026474,
        "meteor": 0.0,
        "sbert_similarity": 0.14570185542106628
      }
    },
    {
      "sample_id": 0,
      "question": "How long has Jolene been doing yoga and meditation?",
      "prediction": "It looks like it's really helping you regroup and recharge.",
      "reference": "about 3 years",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8239805102348328,
        "bert_recall": 0.841121256351471,
        "bert_f1": 0.8324626684188843,
        "meteor": 0.0,
        "sbert_similarity": 0.027839768677949905
      }
    },
    {
      "sample_id": 0,
      "question": "Which year did Jolene start practicing yoga?",
      "prediction": "2023",
      "reference": "2020",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8424988985061646,
        "bert_recall": 0.922377347946167,
        "bert_f1": 0.8806304335594177,
        "meteor": 0.0,
        "sbert_similarity": 0.6698889136314392
      }
    },
    {
      "sample_id": 0,
      "question": "When did Jolene buy a new aquarium for Seraphim?",
      "prediction": "day before yesterday, 24 June 2023",
      "reference": "24 June, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5714285714285715,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.5714285714285714,
        "bleu2": 0.3086066999241838,
        "bleu3": 0.12657485247324374,
        "bleu4": 0.08307018474412793,
        "bert_precision": 0.8658697009086609,
        "bert_recall": 0.9259538054466248,
        "bert_f1": 0.894904375076294,
        "meteor": 0.30303030303030304,
        "sbert_similarity": 0.8298050761222839
      }
    },
    {
      "sample_id": 0,
      "question": "When did Jolene lose a lot of progress in her work?",
      "prediction": "Things have been intense lately.",
      "reference": "last week of July 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8472898006439209,
        "bert_recall": 0.7674919366836548,
        "bert_f1": 0.8054192066192627,
        "meteor": 0.0,
        "sbert_similarity": 0.1528318226337433
      }
    },
    {
      "sample_id": 0,
      "question": "When did Jolene adopt her snake Susie?",
      "prediction": "two years ago from 1 August, 2023",
      "reference": "in 2021",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7879084348678589,
        "bert_recall": 0.841375470161438,
        "bert_f1": 0.8137646913528442,
        "meteor": 0.0,
        "sbert_similarity": 0.5592303276062012
      }
    },
    {
      "sample_id": 0,
      "question": "Which pet did Jolene adopt first - Susie or Seraphim?",
      "prediction": "Susie",
      "reference": "Susie",
      "category": 2,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 1.0000001192092896,
        "bert_recall": 1.0000001192092896,
        "bert_f1": 1.0000001192092896,
        "meteor": 0.5,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "Which pet did Jolene adopt more recently - Susie or Seraphim?",
      "prediction": "Susie",
      "reference": "Seraphim",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.86436927318573,
        "bert_recall": 0.8297716975212097,
        "bert_f1": 0.8467172980308533,
        "meteor": 0.0,
        "sbert_similarity": 0.18705560266971588
      }
    },
    {
      "sample_id": 0,
      "question": "When did Deborah lead a meditation session during the sunset?",
      "prediction": "last week during sunset",
      "reference": "week before 16 August, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.22222222222222224,
        "rouge1_f": 0.22222222222222224,
        "rouge2_f": 0.0,
        "rougeL_f": 0.22222222222222224,
        "bleu1": 0.15163266492815836,
        "bleu2": 0.05536842069051654,
        "bleu3": 0.04649251600872798,
        "bleu4": 0.04873039689743777,
        "bert_precision": 0.8243478536605835,
        "bert_recall": 0.8087025880813599,
        "bert_f1": 0.816450297832489,
        "meteor": 0.10204081632653061,
        "sbert_similarity": 0.5083128213882446
      }
    },
    {
      "sample_id": 0,
      "question": "When did Jolene gift her partner a new console?",
      "prediction": "on the 17th",
      "reference": "17 August, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8572453856468201,
        "bert_recall": 0.8301688432693481,
        "bert_f1": 0.843489944934845,
        "meteor": 0.0,
        "sbert_similarity": 0.542698860168457
      }
    },
    {
      "sample_id": 0,
      "question": "What games does Jolene recommend for Deborah?",
      "prediction": "Zelda BOTW for Switch and Animal Crossing: New Horizons.",
      "reference": "Zelda BOTW for Switch , Animal Crossing: New Horizons, Overcooked 2",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8421052631578948,
        "rouge1_f": 0.8421052631578948,
        "rouge2_f": 0.7058823529411765,
        "rougeL_f": 0.8421052631578948,
        "bleu1": 0.6821614784251477,
        "bleu2": 0.6309737603615639,
        "bleu3": 0.5713736858916096,
        "bleu4": 0.49002024561623275,
        "bert_precision": 0.9679371118545532,
        "bert_recall": 0.9367302656173706,
        "bert_f1": 0.9520779848098755,
        "meteor": 0.6405895691609977,
        "sbert_similarity": 0.9071618914604187
      }
    },
    {
      "sample_id": 0,
      "question": "What do Deborah and her husband do together?",
      "prediction": "We would come here and chat about dreams and life.",
      "reference": "play detective games together, spend time outdoors and explore nature",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.10526315789473685,
        "rouge1_f": 0.10000000000000002,
        "rouge2_f": 0.0,
        "rougeL_f": 0.10000000000000002,
        "bleu1": 0.0909090909090909,
        "bleu2": 0.03015113445777637,
        "bleu3": 0.022461584318318094,
        "bleu4": 0.018850319022747353,
        "bert_precision": 0.8729782700538635,
        "bert_recall": 0.8565540313720703,
        "bert_f1": 0.8646882176399231,
        "meteor": 0.05000000000000001,
        "sbert_similarity": 0.20460130274295807
      }
    },
    {
      "sample_id": 0,
      "question": "When did Deborah go to a yoga retreat near her mom's place?",
      "prediction": "last week on 24 August, 2023",
      "reference": "a week before 24 August,2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.4000000000000001,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.2857142857142857,
        "bleu2": 0.06900655593423542,
        "bleu3": 0.047098549390932394,
        "bleu4": 0.039281465090051315,
        "bert_precision": 0.9411522150039673,
        "bert_recall": 0.9411522150039673,
        "bert_f1": 0.9411522150039673,
        "meteor": 0.19607843137254904,
        "sbert_similarity": 0.8626920580863953
      }
    },
    {
      "sample_id": 0,
      "question": "What projects is Jolene planning for next year?",
      "prediction": "Which projects are you most interested in getting involved in?",
      "reference": "developing renewable energy finding ways to supply clean water to those with limited access",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8342926502227783,
        "bert_recall": 0.838653564453125,
        "bert_f1": 0.836467444896698,
        "meteor": 0.036764705882352935,
        "sbert_similarity": 0.1972414255142212
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Deborah get her cats?",
      "prediction": "Deborah took Max when her mother passed away.",
      "reference": "Luna is from the shelter and Max is her mother's cat",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.22222222222222224,
        "rouge1_f": 0.3,
        "rouge2_f": 0.1111111111111111,
        "rougeL_f": 0.3,
        "bleu1": 0.23884377019126307,
        "bleu2": 0.1462613413027904,
        "bleu3": 0.0617850083534277,
        "bleu4": 0.04021333017266262,
        "bert_precision": 0.8899678587913513,
        "bert_recall": 0.8751718401908875,
        "bert_f1": 0.882507860660553,
        "meteor": 0.09345794392523364,
        "sbert_similarity": 0.49032628536224365
      }
    },
    {
      "sample_id": 0,
      "question": "How old are Deborah's cats?",
      "prediction": "Max is 8 years old, and Luna is 5 years old.",
      "reference": "Max is 8 years old and Luna is 5 years old",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 0.8461538461538461,
        "bleu2": 0.7966275068156915,
        "bleu3": 0.7413977502861777,
        "bleu4": 0.6703420896351792,
        "bert_precision": 0.9890674352645874,
        "bert_recall": 0.9905351400375366,
        "bert_f1": 0.989800751209259,
        "meteor": 0.813692480359147,
        "sbert_similarity": 0.9887447357177734
      }
    },
    {
      "sample_id": 0,
      "question": "Does Deborah like cats?",
      "prediction": "I don't like dogs, that's why I have cats.",
      "reference": "Yes",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8051110506057739,
        "bert_recall": 0.852225661277771,
        "bert_f1": 0.827998697757721,
        "meteor": 0.0,
        "sbert_similarity": 0.01391302328556776
      }
    },
    {
      "sample_id": 0,
      "question": "Which country was Jolene located in during the last week of August 2023?",
      "prediction": "Nice job, Jolene! Take care of yourself and embrace new beginnings.",
      "reference": "Brazil",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8061942458152771,
        "bert_recall": 0.8215805888175964,
        "bert_f1": 0.813814640045166,
        "meteor": 0.0,
        "sbert_similarity": 0.01153085008263588
      }
    },
    {
      "sample_id": 0,
      "question": "When did Jolene and her partner return home from Rio de Janeiro?",
      "prediction": "yesterday, 29 August 2023",
      "reference": "29 August, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8571428571428571,
        "rouge1_f": 0.8571428571428571,
        "rouge2_f": 0.8,
        "rougeL_f": 0.8571428571428571,
        "bleu1": 0.8,
        "bleu2": 0.447213595499958,
        "bleu3": 0.19137706264177992,
        "bleu4": 0.13512001548070346,
        "bert_precision": 0.9327859878540039,
        "bert_recall": 0.9564762711524963,
        "bert_f1": 0.9444826245307922,
        "meteor": 0.32258064516129037,
        "sbert_similarity": 0.91507488489151
      }
    },
    {
      "sample_id": 0,
      "question": "What was Jolene doing with her partner in Rio de Janeiro?",
      "prediction": "we checked out some cool yoga classes",
      "reference": "they went on excursions, checked out some cool yoga classes, visited a lot of delicious cafes, visited an old temple",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.46153846153846156,
        "rouge1_f": 0.4444444444444444,
        "rouge2_f": 0.39999999999999997,
        "rougeL_f": 0.4444444444444444,
        "bleu1": 0.08717262197505157,
        "bleu2": 0.08595336441773133,
        "bleu3": 0.08455208907913989,
        "bleu4": 0.08228727908938598,
        "bert_precision": 0.9460654258728027,
        "bert_recall": 0.8881661891937256,
        "bert_f1": 0.9162019491195679,
        "meteor": 0.2663101604278074,
        "sbert_similarity": 0.48339390754699707
      }
    },
    {
      "sample_id": 0,
      "question": "When did Deborah visit Brazil?",
      "prediction": "three years ago",
      "reference": "2020",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7629268765449524,
        "bert_recall": 0.8417840003967285,
        "bert_f1": 0.800417959690094,
        "meteor": 0.0,
        "sbert_similarity": 0.2990548014640808
      }
    },
    {
      "sample_id": 0,
      "question": "Have Deborah and Jolene been to Rio de Janeiro?",
      "prediction": "Yes, Jolene recently got back from an awesome trip to Rio de Janeiro.",
      "reference": "yes",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.14285714285714288,
        "rouge1_f": 0.14285714285714288,
        "rouge2_f": 0.0,
        "rougeL_f": 0.14285714285714288,
        "bleu1": 0.06666666666666667,
        "bleu2": 0.02182178902359924,
        "bleu3": 0.016071866876084712,
        "bleu4": 0.013217947626377298,
        "bert_precision": 0.8038678765296936,
        "bert_recall": 0.8311744928359985,
        "bert_f1": 0.817293107509613,
        "meteor": 0.0,
        "sbert_similarity": 0.18952134251594543
      }
    },
    {
      "sample_id": 0,
      "question": "Is the friend who wrote Deborah the motivational quote no longer alive?",
      "prediction": "This was written to me by a friend who, unfortunately, will never be able to support me.",
      "reference": "likely yes",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.813536524772644,
        "bert_recall": 0.8093586564064026,
        "bert_f1": 0.8114421963691711,
        "meteor": 0.0,
        "sbert_similarity": 0.05755259841680527
      }
    },
    {
      "sample_id": 0,
      "question": "When did Deborah go to a community meetup?",
      "prediction": "last Friday, 1 September 2023",
      "reference": "last week of August 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4000000000000001,
        "rouge1_f": 0.4000000000000001,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4000000000000001,
        "bleu1": 0.3333333333333333,
        "bleu2": 0.08164965809277261,
        "bleu3": 0.05665132701906204,
        "bleu4": 0.048549177170732344,
        "bert_precision": 0.8897172808647156,
        "bert_recall": 0.9141716957092285,
        "bert_f1": 0.9017786979675293,
        "meteor": 0.20000000000000004,
        "sbert_similarity": 0.8720508813858032
      }
    },
    {
      "sample_id": 0,
      "question": "When did Jolene's parents give her first console?",
      "prediction": "When I was 10, my parents got me that",
      "reference": "when she was 10",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.46153846153846156,
        "rouge1_f": 0.46153846153846156,
        "rouge2_f": 0.18181818181818182,
        "rougeL_f": 0.46153846153846156,
        "bleu1": 0.3,
        "bleu2": 0.18257418583505533,
        "bleu3": 0.07665320007195604,
        "bleu4": 0.04939382737115371,
        "bert_precision": 0.8847492933273315,
        "bert_recall": 0.9439194202423096,
        "bert_f1": 0.9133771061897278,
        "meteor": 0.22222222222222224,
        "sbert_similarity": 0.510070264339447
      }
    },
    {
      "sample_id": 0,
      "question": "Did Jolene teach herself how to play the console?",
      "prediction": "Even as a child I learned to play on my own.",
      "reference": "yes",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8236777782440186,
        "bert_recall": 0.8261803388595581,
        "bert_f1": 0.8249272108078003,
        "meteor": 0.0,
        "sbert_similarity": 0.14910681545734406
      }
    },
    {
      "sample_id": 0,
      "question": "What do Deborah and Jolene plan to try when they meet in a new cafe?",
      "prediction": "fresh pastries",
      "reference": "coffee and fresh pastries",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.36787944117144233,
        "bleu2": 0.36787944117144233,
        "bleu3": 0.1720701423929801,
        "bleu4": 0.11633369384516798,
        "bert_precision": 0.9564321041107178,
        "bert_recall": 0.9060507416725159,
        "bert_f1": 0.9305600523948669,
        "meteor": 0.4934210526315789,
        "sbert_similarity": 0.8167983293533325
      }
    },
    {
      "sample_id": 0,
      "question": "What card game is Deborah talking about?",
      "prediction": "a card game about cats",
      "reference": "Exploding Kittens",
      "category": 3,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.849633514881134,
        "bert_recall": 0.8522714376449585,
        "bert_f1": 0.8509503602981567,
        "meteor": 0.0,
        "sbert_similarity": 0.473378449678421
      }
    },
    {
      "sample_id": 0,
      "question": "When did Jolene and her partner try scuba diving lessons?",
      "prediction": "last Friday, 15 September 2023",
      "reference": "Friday before 17 September, 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6,
        "rouge1_f": 0.6,
        "rouge2_f": 0.25,
        "rougeL_f": 0.6,
        "bleu1": 0.6666666666666666,
        "bleu2": 0.11547005383792518,
        "bleu3": 0.0712114757473708,
        "bleu4": 0.05773502691896258,
        "bert_precision": 0.9073281288146973,
        "bert_recall": 0.9054970145225525,
        "bert_f1": 0.9064116477966309,
        "meteor": 0.10000000000000002,
        "sbert_similarity": 0.9061554670333862
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Jolene and her partner find a cool diving spot?",
      "prediction": "a cool dive spot we can explore together",
      "reference": "Phuket",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8144571185112,
        "bert_recall": 0.7471166849136353,
        "bert_f1": 0.7793349623680115,
        "meteor": 0.0,
        "sbert_similarity": 0.20758885145187378
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Jolene and her partner spend most of September 2023?",
      "prediction": "together",
      "reference": "Phuket",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8450254201889038,
        "bert_recall": 0.7242565751075745,
        "bert_f1": 0.7799938917160034,
        "meteor": 0.0,
        "sbert_similarity": 0.1342727243900299
      }
    },
    {
      "sample_id": 0,
      "question": "Has Deborah tried surfing?",
      "prediction": "I haven't had the chance to try scuba diving yet.",
      "reference": "yes",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8124498128890991,
        "bert_recall": 0.8397506475448608,
        "bert_f1": 0.8258746862411499,
        "meteor": 0.0,
        "sbert_similarity": 0.0006867684423923492
      }
    },
    {
      "sample_id": 0,
      "question": "Has Jolene tried surfing?",
      "prediction": "Gotta find that spare time!",
      "reference": "no",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7769457101821899,
        "bert_recall": 0.8474780917167664,
        "bert_f1": 0.8106806874275208,
        "meteor": 0.0,
        "sbert_similarity": 0.057900458574295044
      }
    },
    {
      "sample_id": 0,
      "question": "When did the Deboran and Jolene agree to go surfing?",
      "prediction": "5:35 pm on 22 March, 2023",
      "reference": "in October 2023",
      "category": 2,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2222222222222222,
        "rouge1_f": 0.2,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2,
        "bleu1": 0.14285714285714285,
        "bleu2": 0.048795003647426664,
        "bleu3": 0.037468614372419724,
        "bleu4": 0.033031643180138064,
        "bert_precision": 0.8307988047599792,
        "bert_recall": 0.8746495842933655,
        "bert_f1": 0.8521603941917419,
        "meteor": 0.15151515151515152,
        "sbert_similarity": 0.6785389184951782
      }
    },
    {
      "sample_id": 0,
      "question": "Which locations does Deborah practice her yoga at?",
      "prediction": "a park with a forest trail and a beach",
      "reference": "at her mother's old home, park, yoga studio, beach",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.2105263157894737,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2105263157894737,
        "bleu1": 0.14248453076221212,
        "bleu2": 0.03379317364116882,
        "bleu3": 0.022621325652159758,
        "bleu4": 0.018284887072297418,
        "bert_precision": 0.8915145397186279,
        "bert_recall": 0.8635743856430054,
        "bert_f1": 0.8773220777511597,
        "meteor": 0.05555555555555555,
        "sbert_similarity": 0.3569936156272888
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of professional activities does Jolene participate in to gain more experience in her field?",
      "prediction": "I'm interning at a well-known engineering firm. It's been a great opportunity to test my skills and gain real-world experience.",
      "reference": "present work at virtual conference, attend workshops  and intern at firms",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.13793103448275862,
        "rouge1_f": 0.2285714285714286,
        "rouge2_f": 0.06060606060606061,
        "rougeL_f": 0.17142857142857143,
        "bleu1": 0.08333333333333333,
        "bleu2": 0.019034674690672018,
        "bleu3": 0.01234526788340704,
        "bleu4": 0.009410489957951634,
        "bert_precision": 0.8531290292739868,
        "bert_recall": 0.8479390144348145,
        "bert_f1": 0.8505260944366455,
        "meteor": 0.21475256769374415,
        "sbert_similarity": 0.5015702843666077
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of engineering projects has Jolene worked on?",
      "prediction": "Jolene has worked on a robotics project and an engineering project where she came up with some neat solutions.",
      "reference": "electrical engineering, robotics, sustainable water purifier, productive and affordable aerial surveillance system",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2,
        "rouge1_f": 0.1935483870967742,
        "rouge2_f": 0.0,
        "rougeL_f": 0.12903225806451615,
        "bleu1": 0.15,
        "bleu2": 0.02809757434745082,
        "bleu3": 0.017056169390452146,
        "bleu4": 0.012673718536830811,
        "bert_precision": 0.8390730619430542,
        "bert_recall": 0.8499603271484375,
        "bert_f1": 0.8444815874099731,
        "meteor": 0.03937007874015748,
        "sbert_similarity": 0.29330867528915405
      }
    },
    {
      "sample_id": 0,
      "question": "Which community activities have Deborah and Anna participated in?",
      "prediction": "Deborah and Anna have participated in a yoga retreat, a yoga class for neighbors, a running group, mindfulness workshops, and a community cleanup project.",
      "reference": "yoga, running",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.1904761904761905,
        "rouge1_f": 0.15384615384615385,
        "rouge2_f": 0.0,
        "rougeL_f": 0.15384615384615385,
        "bleu1": 0.10344827586206899,
        "bleu2": 0.019221293610962246,
        "bleu3": 0.011613054982669974,
        "bleu4": 0.008517399705356638,
        "bert_precision": 0.8151111006736755,
        "bert_recall": 0.8616379499435425,
        "bert_f1": 0.8377290368080139,
        "meteor": 0.11904761904761905,
        "sbert_similarity": 0.4434540867805481
      }
    },
    {
      "sample_id": 0,
      "question": "What gifts has Deborah received?",
      "prediction": "a bouquet when I was struggling",
      "reference": "an appreciate letter from her community, a flower bouqet from her friend, a motivational quote from a friend",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.1111111111111111,
        "rouge1_f": 0.08333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.08333333333333333,
        "bleu1": 0.01616199464406751,
        "bleu2": 0.0055986791750362004,
        "bleu3": 0.004370351799365829,
        "bleu4": 0.003958864010356003,
        "bert_precision": 0.8670333027839661,
        "bert_recall": 0.8350412249565125,
        "bert_f1": 0.8507366180419922,
        "meteor": 0.02976190476190476,
        "sbert_similarity": 0.37848782539367676
      }
    },
    {
      "sample_id": 0,
      "question": "Which countries has Deborah traveled to?",
      "prediction": "Bali and Rio de Janeiro",
      "reference": "Thailand, Brazil",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8201919794082642,
        "bert_recall": 0.8661485910415649,
        "bert_f1": 0.8425440788269043,
        "meteor": 0.0,
        "sbert_similarity": 0.6018776893615723
      }
    },
    {
      "sample_id": 0,
      "question": "What activities does Deborah pursue besides practicing and teaching yoga?",
      "prediction": "meditate, do yoga, and teach classes; go for a morning jog; spend time with loved ones",
      "reference": "biking, going to art shows, running, organizing workshops to practice mindfulness and self-care, surfing, gardening",
      "category": 1,
      "metrics": {
        "exact_match": 0,
        "f1": 0.06666666666666667,
        "rouge1_f": 0.125,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0625,
        "bleu1": 0.15,
        "bleu2": 0.02809757434745082,
        "bleu3": 0.017056169390452146,
        "bleu4": 0.012673718536830811,
        "bert_precision": 0.8632667660713196,
        "bert_recall": 0.861596405506134,
        "bert_f1": 0.8624307513237,
        "meteor": 0.06622516556291391,
        "sbert_similarity": 0.5342676639556885
      }
    },
    {
      "sample_id": 0,
      "question": "What are the names of Jolene's snakes?",
      "prediction": "Susie and Seraphim",
      "reference": "Susie, Seraphim",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8,
        "rouge1_f": 0.8,
        "rouge2_f": 0.0,
        "rougeL_f": 0.8,
        "bleu1": 0.6666666666666666,
        "bleu2": 0.18257418583505536,
        "bleu3": 0.1522474354853864,
        "bleu4": 0.13512001548070346,
        "bert_precision": 0.9420279860496521,
        "bert_recall": 0.9420279860496521,
        "bert_f1": 0.9420279860496521,
        "meteor": 0.2380952380952381,
        "sbert_similarity": 0.917330265045166
      }
    },
    {
      "sample_id": 0,
      "question": "What are Jolene's favorite books?",
      "prediction": "I'd love to hear your thoughts.",
      "reference": "Sapiens, Avalanche by Neal Stephenson",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8257796764373779,
        "bert_recall": 0.7985783219337463,
        "bert_f1": 0.8119512796401978,
        "meteor": 0.0,
        "sbert_similarity": 0.11321403086185455
      }
    },
    {
      "sample_id": 0,
      "question": "What music pieces does Deborah listen to during her yoga practice?",
      "prediction": "The context does not provide information about music pieces Deborah listens to during her yoga practice.",
      "reference": "Savana, Sleep",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.827498197555542,
        "bert_recall": 0.8097495436668396,
        "bert_f1": 0.8185276389122009,
        "meteor": 0.0,
        "sbert_similarity": 0.18002170324325562
      }
    },
    {
      "sample_id": 0,
      "question": "What games does Jolene recommend for Deborah?",
      "prediction": "Zelda BOTW for Switch and Animal Crossing: New Horizons",
      "reference": "Zelda BOTW for Switch , Animal Crossing: New Horizons, Overcooked 2",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8421052631578948,
        "rouge1_f": 0.8421052631578948,
        "rouge2_f": 0.7058823529411765,
        "rougeL_f": 0.8421052631578948,
        "bleu1": 0.666736398613546,
        "bleu2": 0.6198129921724927,
        "bleu3": 0.5639419664458528,
        "bleu4": 0.4874858042804568,
        "bert_precision": 0.9715757966041565,
        "bert_recall": 0.9429328441619873,
        "bert_f1": 0.9570400714874268,
        "meteor": 0.6405895691609977,
        "sbert_similarity": 0.9069766402244568
      }
    },
    {
      "sample_id": 0,
      "question": "What projects is Jolene planning for next year?",
      "prediction": "You've got a lot of amazing plans for the future. Which projects are you most interested in getting involved in?",
      "reference": "developing renewable energy finding ways to supply clean water to those with limited access",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8496201038360596,
        "bert_recall": 0.8398267030715942,
        "bert_f1": 0.8446950316429138,
        "meteor": 0.0684931506849315,
        "sbert_similarity": 0.24675747752189636
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Deborah get her cats?",
      "prediction": "Max is my mother's cat, I took him when my mother passed away.",
      "reference": "Luna is from the shelter and Max is her mother's cat",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.3636363636363636,
        "rouge1_f": 0.3846153846153846,
        "rouge2_f": 0.24999999999999994,
        "rougeL_f": 0.3846153846153846,
        "bleu1": 0.3125,
        "bleu2": 0.25,
        "bleu3": 0.16765563463645106,
        "bleu4": 0.07655122720591222,
        "bert_precision": 0.889480710029602,
        "bert_recall": 0.9098215103149414,
        "bert_f1": 0.8995360732078552,
        "meteor": 0.22817460317460317,
        "sbert_similarity": 0.6961167454719543
      }
    },
    {
      "sample_id": 0,
      "question": "How old are Deborah's cats?",
      "prediction": "Max is 8 years old, Luna is 5 years old.",
      "reference": "Max is 8 years old and Luna is 5 years old",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.9333333333333333,
        "rouge1_f": 0.9523809523809523,
        "rouge2_f": 0.8421052631578948,
        "rougeL_f": 0.9523809523809523,
        "bleu1": 0.8333333333333334,
        "bleu2": 0.778498944161523,
        "bleu3": 0.7161767386056302,
        "bleu4": 0.6340466277046861,
        "bert_precision": 0.9911024570465088,
        "bert_recall": 0.9902957677841187,
        "bert_f1": 0.9906989932060242,
        "meteor": 0.7282110091743119,
        "sbert_similarity": 0.9887763261795044
      }
    },
    {
      "sample_id": 0,
      "question": "What was Jolene doing with her partner in Rio de Janeiro?",
      "prediction": "we checked out some cool yoga classes",
      "reference": "they went on excursions, checked out some cool yoga classes, visited a lot of delicious cafes, visited an old temple",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.46153846153846156,
        "rouge1_f": 0.4444444444444444,
        "rouge2_f": 0.39999999999999997,
        "rougeL_f": 0.4444444444444444,
        "bleu1": 0.08717262197505157,
        "bleu2": 0.08595336441773133,
        "bleu3": 0.08455208907913989,
        "bleu4": 0.08228727908938598,
        "bert_precision": 0.9460654258728027,
        "bert_recall": 0.8881661891937256,
        "bert_f1": 0.9162019491195679,
        "meteor": 0.2663101604278074,
        "sbert_similarity": 0.48339390754699707
      }
    },
    {
      "sample_id": 0,
      "question": "Have Deborah and Jolene been to Rio de Janeiro?",
      "prediction": "Yes, both Deborah and Jolene have been to Rio de Janeiro.",
      "reference": "yes",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.16666666666666669,
        "rouge1_f": 0.16666666666666669,
        "rouge2_f": 0.0,
        "rougeL_f": 0.16666666666666669,
        "bleu1": 0.07692307692307693,
        "bleu2": 0.025318484177091663,
        "bleu3": 0.018733084686676876,
        "bleu4": 0.01553712569276035,
        "bert_precision": 0.820356011390686,
        "bert_recall": 0.8433769941329956,
        "bert_f1": 0.831707239151001,
        "meteor": 0.0,
        "sbert_similarity": 0.1326407790184021
      }
    },
    {
      "sample_id": 0,
      "question": "When did Jolene's parents give her first console?",
      "prediction": "When I was 10, my parents got me that",
      "reference": "when she was 10",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.46153846153846156,
        "rouge1_f": 0.46153846153846156,
        "rouge2_f": 0.18181818181818182,
        "rougeL_f": 0.46153846153846156,
        "bleu1": 0.3,
        "bleu2": 0.18257418583505533,
        "bleu3": 0.07665320007195604,
        "bleu4": 0.04939382737115371,
        "bert_precision": 0.8847492933273315,
        "bert_recall": 0.9439194202423096,
        "bert_f1": 0.9133771061897278,
        "meteor": 0.22222222222222224,
        "sbert_similarity": 0.510070264339447
      }
    },
    {
      "sample_id": 0,
      "question": "What do Deborah and Jolene plan to try when they meet in a new cafe?",
      "prediction": "fresh pastries",
      "reference": "coffee and fresh pastries",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.36787944117144233,
        "bleu2": 0.36787944117144233,
        "bleu3": 0.1720701423929801,
        "bleu4": 0.11633369384516798,
        "bert_precision": 0.9564321041107178,
        "bert_recall": 0.9060507416725159,
        "bert_f1": 0.9305600523948669,
        "meteor": 0.4934210526315789,
        "sbert_similarity": 0.8167983293533325
      }
    },
    {
      "sample_id": 0,
      "question": "What project did Jolene finish last week before 23 January, 2023?",
      "prediction": "a big project",
      "reference": "an electrical engineering project",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.28571428571428575,
        "rouge1_f": 0.28571428571428575,
        "rouge2_f": 0.0,
        "rougeL_f": 0.28571428571428575,
        "bleu1": 0.23884377019126307,
        "bleu2": 0.09250379442961536,
        "bleu3": 0.08678511835352629,
        "bleu4": 0.0814136751754278,
        "bert_precision": 0.9219410419464111,
        "bert_recall": 0.9056722521781921,
        "bert_f1": 0.9137341976165771,
        "meteor": 0.12820512820512822,
        "sbert_similarity": 0.39237186312675476
      }
    },
    {
      "sample_id": 0,
      "question": "When did Jolene buy her pet snake?",
      "prediction": "I got her last year",
      "reference": "A year ago",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.25,
        "rouge2_f": 0.0,
        "rougeL_f": 0.25,
        "bleu1": 0.2,
        "bleu2": 0.07071067811865477,
        "bleu3": 0.05665132701906204,
        "bleu4": 0.05372849659117709,
        "bert_precision": 0.8269362449645996,
        "bert_recall": 0.7910716533660889,
        "bert_f1": 0.8086064457893372,
        "meteor": 0.15625,
        "sbert_similarity": 0.330782413482666
      }
    },
    {
      "sample_id": 0,
      "question": "What project was Jolene working on as of 1 February, 2023?",
      "prediction": "That's awesome, Jolene! You're enjoying the process. It must be really satisfying to see it come together.",
      "reference": "Robotics project",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8104217052459717,
        "bert_recall": 0.8471960425376892,
        "bert_f1": 0.8284009695053101,
        "meteor": 0.14285714285714285,
        "sbert_similarity": 0.019197402521967888
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Deborah meet her new neighbor Anna?",
      "prediction": "I met my new neighbor Anna yesterday!",
      "reference": "yoga in the park",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8426130414009094,
        "bert_recall": 0.8478095531463623,
        "bert_f1": 0.8452033400535583,
        "meteor": 0.0,
        "sbert_similarity": 0.09707565605640411
      }
    },
    {
      "sample_id": 0,
      "question": "What activity did Jolene and her partner plan to do together instead of resuming yoga?",
      "prediction": "go on a meditation retreat together",
      "reference": "play the console",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8448576927185059,
        "bert_recall": 0.8807551860809326,
        "bert_f1": 0.8624330759048462,
        "meteor": 0.0,
        "sbert_similarity": 0.0589321106672287
      }
    },
    {
      "sample_id": 0,
      "question": "What milestone did Jolene achieve recently on 4 February, 2023?",
      "prediction": "I had a major milestone last week and it went really well - I'm so relieved and proud. It was a huge accomplishment for me as an engineer.",
      "reference": "Design and build a sustainable water purifier for a rural community",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.17142857142857143,
        "rouge1_f": 0.2051282051282051,
        "rouge2_f": 0.0,
        "rougeL_f": 0.15384615384615383,
        "bleu1": 0.12903225806451615,
        "bleu2": 0.02073903389460851,
        "bleu3": 0.011925842920713768,
        "bleu4": 0.008531104334876973,
        "bert_precision": 0.8405896425247192,
        "bert_recall": 0.8323124647140503,
        "bert_f1": 0.8364306092262268,
        "meteor": 0.1968503937007874,
        "sbert_similarity": 0.042864538729190826
      }
    },
    {
      "sample_id": 0,
      "question": "What is Jolene's favorite book which she mentioned on 4 February, 2023?",
      "prediction": "Jolene did not mention a favorite book on 4 February, 2023.",
      "reference": "\"Sapiens\"",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8161287307739258,
        "bert_recall": 0.8068196177482605,
        "bert_f1": 0.8114474415779114,
        "meteor": 0.0,
        "sbert_similarity": -0.04120265692472458
      }
    },
    {
      "sample_id": 0,
      "question": "What does Deborah bring with her whenever she comes to reflect on her mom?",
      "prediction": "memories",
      "reference": "amulet",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.9984305500984192,
        "bert_recall": 0.9984305500984192,
        "bert_f1": 0.9984305500984192,
        "meteor": 0.0,
        "sbert_similarity": 0.2732107639312744
      }
    },
    {
      "sample_id": 0,
      "question": "What new outlook did Jolene gain after her mini retreat on 9 February, 2023?",
      "prediction": "a new outlook on life",
      "reference": "A confidence boost",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.25,
        "rouge2_f": 0.0,
        "rougeL_f": 0.25,
        "bleu1": 0.2,
        "bleu2": 0.07071067811865477,
        "bleu3": 0.05665132701906204,
        "bleu4": 0.05372849659117709,
        "bert_precision": 0.8666757345199585,
        "bert_recall": 0.8798625469207764,
        "bert_f1": 0.87321937084198,
        "meteor": 0.15625,
        "sbert_similarity": 0.20177480578422546
      }
    },
    {
      "sample_id": 0,
      "question": "What cool stuff did Jolene accomplish at the retreat on 9 February, 2023?",
      "prediction": "Jolene did not mention any accomplishments at the retreat on 9 February, 2023, in the provided context.",
      "reference": "Came up with neat solutions for her engineering project",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8259274959564209,
        "bert_recall": 0.8378537893295288,
        "bert_f1": 0.8318479061126709,
        "meteor": 0.0,
        "sbert_similarity": 0.11549792438745499
      }
    },
    {
      "sample_id": 0,
      "question": "What idea did Jolene have to help underprivileged kids learn about STEM subjects on 9 February, 2023?",
      "prediction": "a volunteer program where engineers teach STEM to underprivileged kids",
      "reference": "A volunteer program where engineers teach STEM to underprivileged kids",
      "category": 4,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.999535083770752,
        "bert_recall": 0.999535083770752,
        "bert_f1": 0.999535083770752,
        "meteor": 0.9995,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "How does Jolene plan to involve local engineers in her idea of teaching STEM to underprivileged kids?",
      "prediction": "teaming up with local schools/centers to do workshops and invite engineers as guest speakers",
      "reference": "As guest speakers for workshops",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4210526315789473,
        "rouge1_f": 0.4,
        "rouge2_f": 0.22222222222222224,
        "rougeL_f": 0.3,
        "bleu1": 0.2857142857142857,
        "bleu2": 0.20965696734438366,
        "bleu3": 0.15706026521556773,
        "bleu4": 0.07596458453655348,
        "bert_precision": 0.855994462966919,
        "bert_recall": 0.9225908517837524,
        "bert_f1": 0.8880458474159241,
        "meteor": 0.6355932203389831,
        "sbert_similarity": 0.7749799489974976
      }
    },
    {
      "sample_id": 0,
      "question": "What gave Deborah peace in the garden she visited?",
      "prediction": "The roses and dahlias bring me peace.",
      "reference": "Roses and dahlias",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6,
        "rouge1_f": 0.6,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6,
        "bleu1": 0.375,
        "bleu2": 0.32732683535398854,
        "bleu3": 0.2649097550589377,
        "bleu4": 0.1374708101760565,
        "bert_precision": 0.9078960418701172,
        "bert_recall": 0.9369074106216431,
        "bert_f1": 0.9221736192703247,
        "meteor": 0.866013071895425,
        "sbert_similarity": 0.8049888014793396
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Deborah spend time in the garden?",
      "prediction": "to find some comfort",
      "reference": "to find comfort after losing a friend",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5454545454545454,
        "rouge1_f": 0.5454545454545454,
        "rouge2_f": 0.2222222222222222,
        "rougeL_f": 0.5454545454545454,
        "bleu1": 0.354274914555761,
        "bleu2": 0.23618327637050732,
        "bleu3": 0.1112396062304518,
        "bleu4": 0.08881915596542085,
        "bert_precision": 0.9351838827133179,
        "bert_recall": 0.9074504375457764,
        "bert_f1": 0.9211084842681885,
        "meteor": 0.3814262023217247,
        "sbert_similarity": 0.621046781539917
      }
    },
    {
      "sample_id": 0,
      "question": "How did Jolene and her partner initially meet?",
      "prediction": "how did you two meet?",
      "reference": "In an engineering class in college",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8277373909950256,
        "bert_recall": 0.835830569267273,
        "bert_f1": 0.831764280796051,
        "meteor": 0.0,
        "sbert_similarity": 0.047200217843055725
      }
    },
    {
      "sample_id": 0,
      "question": "What activity does Deborah incorporate into her daily routine after going for a morning jog in the park?",
      "prediction": "I will now incorporate this into my daily routine.",
      "reference": "spending time with loved ones",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8555140495300293,
        "bert_recall": 0.8372249603271484,
        "bert_f1": 0.8462706804275513,
        "meteor": 0.0925925925925926,
        "sbert_similarity": 0.19927237927913666
      }
    },
    {
      "sample_id": 0,
      "question": "According to Jolene, what does exercise help her to feel?",
      "prediction": "calm",
      "reference": "connected to her body",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8912410736083984,
        "bert_recall": 0.8163497447967529,
        "bert_f1": 0.8521530628204346,
        "meteor": 0.0,
        "sbert_similarity": 0.14030618965625763
      }
    },
    {
      "sample_id": 0,
      "question": "What did Deb share a photo of, which brought a smile to Jolene's face?",
      "prediction": "a photo of a bed with a snake head sticking out of it",
      "reference": "a yellow coffee cup with a handwritten message",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.23529411764705882,
        "rouge1_f": 0.2857142857142857,
        "rouge2_f": 0.10526315789473685,
        "rougeL_f": 0.2857142857142857,
        "bleu1": 0.23076923076923078,
        "bleu2": 0.1386750490563073,
        "bleu3": 0.057551852907951895,
        "bleu4": 0.036362270465000714,
        "bert_precision": 0.8808126449584961,
        "bert_recall": 0.8942049741744995,
        "bert_f1": 0.8874582648277283,
        "meteor": 0.3006535947712418,
        "sbert_similarity": 0.2597525715827942
      }
    },
    {
      "sample_id": 0,
      "question": "What is one of Jolene's favorite dishes?",
      "prediction": "I can still remember the smell of her special dish.",
      "reference": "lasagna",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8408619165420532,
        "bert_recall": 0.7679466009140015,
        "bert_f1": 0.802751898765564,
        "meteor": 0.0,
        "sbert_similarity": 0.22029855847358704
      }
    },
    {
      "sample_id": 0,
      "question": "What picture did Jolene share related to feeling overwhelmed?",
      "prediction": "[Image: a photo of a bed with a snake head sticking out of it] I want to show you one of my snakes! They always calm me down and make me happy. This is Susie.",
      "reference": "a photo of a desk with a notebook and a computer monitor",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2564102564102564,
        "rouge1_f": 0.2978723404255319,
        "rouge2_f": 0.17777777777777776,
        "rougeL_f": 0.2978723404255319,
        "bleu1": 0.17073170731707318,
        "bleu2": 0.13066434376564753,
        "bleu3": 0.09793823176388942,
        "bleu4": 0.06928257073358142,
        "bert_precision": 0.8471922874450684,
        "bert_recall": 0.9060664176940918,
        "bert_f1": 0.8756408095359802,
        "meteor": 0.24475524475524477,
        "sbert_similarity": 0.2199312448501587
      }
    },
    {
      "sample_id": 0,
      "question": "What did Jolene and Deb discuss as a helpful strategy for studying and time management?",
      "prediction": "break it into smaller pieces and set goals for yourself",
      "reference": "breaking tasks into smaller pieces and setting goals, using planners or schedulers",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.45454545454545453,
        "rouge1_f": 0.6363636363636365,
        "rouge2_f": 0.5,
        "rougeL_f": 0.6363636363636365,
        "bleu1": 0.37040911034085894,
        "bleu2": 0.3024377721377921,
        "bleu3": 0.2595624983326595,
        "bleu4": 0.20577107905082873,
        "bert_precision": 0.9312472343444824,
        "bert_recall": 0.9093369841575623,
        "bert_f1": 0.9201616644859314,
        "meteor": 0.4990583804143125,
        "sbert_similarity": 0.5724416971206665
      }
    },
    {
      "sample_id": 0,
      "question": "What did Jolene ask Deb to help with on 13 March, 2023?",
      "prediction": "Take your time, Jolene. We'll work it out. Take care of yourself, OK?",
      "reference": "time management",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.14285714285714285,
        "rouge1_f": 0.125,
        "rouge2_f": 0.0,
        "rougeL_f": 0.125,
        "bleu1": 0.05263157894736841,
        "bleu2": 0.017099639201419235,
        "bleu3": 0.012523428510015045,
        "bleu4": 0.010182425646195498,
        "bert_precision": 0.8166500926017761,
        "bert_recall": 0.8216428756713867,
        "bert_f1": 0.8191388845443726,
        "meteor": 0.0,
        "sbert_similarity": 0.2251366674900055
      }
    },
    {
      "sample_id": 0,
      "question": "What method does Deb suggest Jolene to try for organizing tasks based on importance and urgency?",
      "prediction": "the Eisenhower Matrix",
      "reference": "The Eisenhower Matrix",
      "category": 4,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 0.9991123676300049,
        "bert_recall": 0.9991123676300049,
        "bert_f1": 0.9991123676300049,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What did Jolene and Anna discuss while watching the sunset by the sea?",
      "prediction": "we realized that we inspire each other",
      "reference": "They realized they inspire each other",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.7272727272727272,
        "rouge1_f": 0.6153846153846153,
        "rouge2_f": 0.3636363636363636,
        "rougeL_f": 0.6153846153846153,
        "bleu1": 0.5714285714285714,
        "bleu2": 0.4364357804719847,
        "bleu3": 0.34016320005192946,
        "bleu4": 0.17567205239427922,
        "bert_precision": 0.9709598422050476,
        "bert_recall": 0.9836084842681885,
        "bert_f1": 0.977243185043335,
        "meteor": 0.6147540983606558,
        "sbert_similarity": 0.6519147157669067
      }
    },
    {
      "sample_id": 0,
      "question": "How does Jolene plan to pursue her dream of learning to surf?",
      "prediction": "I've been gathering information, watching videos, and I even got a beginners' guide to surfing. Just need to find the right time and place to get a lesson.",
      "reference": "gathering information, watching videos, getting a beginners' guide",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.43750000000000006,
        "rouge1_f": 0.4324324324324324,
        "rouge2_f": 0.34285714285714286,
        "rougeL_f": 0.3783783783783784,
        "bleu1": 0.29411764705882354,
        "bleu2": 0.26702293491727636,
        "bleu3": 0.24077559940810211,
        "bleu4": 0.20379765144415737,
        "bert_precision": 0.8809573650360107,
        "bert_recall": 0.9280593395233154,
        "bert_f1": 0.9038951396942139,
        "meteor": 0.77890625,
        "sbert_similarity": 0.6126793026924133
      }
    },
    {
      "sample_id": 0,
      "question": "What did Deborah buy to enhance her yoga practice besides the props?",
      "prediction": "I bought new props for the yoga class!",
      "reference": "candle",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8104513883590698,
        "bert_recall": 0.8557977080345154,
        "bert_f1": 0.8325074911117554,
        "meteor": 0.0,
        "sbert_similarity": 0.19796009361743927
      }
    },
    {
      "sample_id": 0,
      "question": "What type of music does Deborah find helpful during her yoga practice?",
      "prediction": "The context does not specify what type of music Deborah finds helpful during her yoga practice.",
      "reference": "instrumental tracks with mellow melodies and rhythms",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8367984890937805,
        "bert_recall": 0.8421822786331177,
        "bert_f1": 0.8394817113876343,
        "meteor": 0.0,
        "sbert_similarity": 0.3595305383205414
      }
    },
    {
      "sample_id": 0,
      "question": "Who are the musicians mentioned by Jolene that she enjoys listening to during her yoga practice?",
      "prediction": "the musicians are not mentioned in the context",
      "reference": "Nils Frahm and Olafur Arnalds",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8391456604003906,
        "bert_recall": 0.7464137673377991,
        "bert_f1": 0.7900680303573608,
        "meteor": 0.0,
        "sbert_similarity": 0.3185601532459259
      }
    },
    {
      "sample_id": 0,
      "question": "What album does Deborah recommend for meditation and deep relaxation?",
      "prediction": "'Sleep'",
      "reference": "'Sleep'",
      "category": 4,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 0.46773514128719823,
        "bleu4": 0.316227766016838,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.5,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "Which show did Deborah go to with a friend on 9 April, 2023?",
      "prediction": "an art show",
      "reference": "an art show",
      "category": 4,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What does Deborah find comforting about going to art shows?",
      "prediction": "It's hard but comforting.",
      "reference": "It makes her feel like she's still experiencing it with her mom",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.2222222222222222,
        "rouge2_f": 0.0,
        "rougeL_f": 0.2222222222222222,
        "bleu1": 0.10380107463819924,
        "bleu2": 0.025425966761614016,
        "bleu3": 0.017641405872776076,
        "bleu4": 0.015118370289367042,
        "bert_precision": 0.8759900331497192,
        "bert_recall": 0.8538047671318054,
        "bert_f1": 0.8647551536560059,
        "meteor": 0.0,
        "sbert_similarity": 0.32538214325904846
      }
    },
    {
      "sample_id": 0,
      "question": "How does Jolene describe the time spent with her snakes and partner?",
      "prediction": "they always calm me down and make me happy.",
      "reference": "Valuable and relaxing",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.18181818181818182,
        "rouge1_f": 0.16666666666666666,
        "rouge2_f": 0.0,
        "rougeL_f": 0.16666666666666666,
        "bleu1": 0.10000000000000002,
        "bleu2": 0.03333333333333335,
        "bleu3": 0.024950558772614845,
        "bleu4": 0.021105340631872645,
        "bert_precision": 0.8528556823730469,
        "bert_recall": 0.82539963722229,
        "bert_f1": 0.8389030694961548,
        "meteor": 0.13888888888888892,
        "sbert_similarity": 0.24504756927490234
      }
    },
    {
      "sample_id": 0,
      "question": "What does Jolene enjoy doing with her partner after a long day?",
      "prediction": "spending time with her pet",
      "reference": "Playing video games",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8373875617980957,
        "bert_recall": 0.8619966506958008,
        "bert_f1": 0.8495139479637146,
        "meteor": 0.0,
        "sbert_similarity": 0.21857336163520813
      }
    },
    {
      "sample_id": 0,
      "question": "What is Jolene currently doing in June 2023?",
      "prediction": "I'm interning at a well-known engineering firm. It's been a great opportunity to test my skills and gain real-world experience.",
      "reference": "interning at a well-known engineering firm",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4799999999999999,
        "rouge1_f": 0.45161290322580644,
        "rouge2_f": 0.41379310344827586,
        "rougeL_f": 0.45161290322580644,
        "bleu1": 0.25,
        "bleu2": 0.23312620206007845,
        "bleu3": 0.2179166584968628,
        "bleu4": 0.19383418023456653,
        "bert_precision": 0.8673574328422546,
        "bert_recall": 0.9291348457336426,
        "bert_f1": 0.897183895111084,
        "meteor": 0.6027027027027027,
        "sbert_similarity": 0.7787250876426697
      }
    },
    {
      "sample_id": 0,
      "question": "For how long has Jolene had Seraphim as a pet?",
      "prediction": "I got her last year.",
      "reference": "one year",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.28571428571428575,
        "rouge1_f": 0.28571428571428575,
        "rouge2_f": 0.0,
        "rougeL_f": 0.28571428571428575,
        "bleu1": 0.16666666666666669,
        "bleu2": 0.05773502691896258,
        "bleu3": 0.04506819749679463,
        "bleu4": 0.040824829046386304,
        "bert_precision": 0.8761680722236633,
        "bert_recall": 0.8796733617782593,
        "bert_f1": 0.8779171705245972,
        "meteor": 0.21739130434782608,
        "sbert_similarity": 0.30765479803085327
      }
    },
    {
      "sample_id": 0,
      "question": "How does Jolene feel when spending time with Seraphim?",
      "prediction": "She always cheers me up and brings a sense of peace.",
      "reference": "comforted",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8243610262870789,
        "bert_recall": 0.80952388048172,
        "bert_f1": 0.8168750405311584,
        "meteor": 0.0,
        "sbert_similarity": 0.14974400401115417
      }
    },
    {
      "sample_id": 0,
      "question": "Which new yoga pose did Deborah share a photo of?",
      "prediction": "Dancer Pose (Natarajasana)",
      "reference": "tree pose",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4,
        "rouge2_f": 0.0,
        "rougeL_f": 0.4,
        "bleu1": 0.2,
        "bleu2": 0.07071067811865477,
        "bleu3": 0.05665132701906204,
        "bleu4": 0.05372849659117709,
        "bert_precision": 0.814473032951355,
        "bert_recall": 0.9163485765457153,
        "bert_f1": 0.8624126315116882,
        "meteor": 0.2380952380952381,
        "sbert_similarity": 0.465834379196167
      }
    },
    {
      "sample_id": 0,
      "question": "What group activity did Deborah start with Anna?",
      "prediction": "a running group",
      "reference": "running group",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8,
        "rouge1_f": 0.8,
        "rouge2_f": 0.6666666666666666,
        "rougeL_f": 0.8,
        "bleu1": 0.6666666666666666,
        "bleu2": 0.5773502691896257,
        "bleu3": 0.3254992452916931,
        "bleu4": 0.24028114141347542,
        "bert_precision": 0.9172487258911133,
        "bert_recall": 0.9638155102729797,
        "bert_f1": 0.9399557113647461,
        "meteor": 0.8928571428571429,
        "sbert_similarity": 0.8704909086227417
      }
    },
    {
      "sample_id": 0,
      "question": "What made being part of the running group easy for Deborah to stay motivated?",
      "prediction": "Connecting with people who care about fitness!",
      "reference": "helping and pushing each other during runs",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8357916474342346,
        "bert_recall": 0.8355164527893066,
        "bert_f1": 0.8356540203094482,
        "meteor": 0.0,
        "sbert_similarity": 0.2641819715499878
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Jolene decide to get a snake as a pet?",
      "prediction": "I was fascinated by reptiles, and it felt like the perfect pet for me.",
      "reference": "fascinated by reptiles and it felt like the perfect pet",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8333333333333333,
        "rouge1_f": 0.8333333333333333,
        "rouge2_f": 0.8181818181818181,
        "rougeL_f": 0.8333333333333333,
        "bleu1": 0.625,
        "bleu2": 0.5773502691896257,
        "bleu3": 0.5261597794341888,
        "bleu4": 0.4578831372133982,
        "bert_precision": 0.9138137102127075,
        "bert_recall": 0.9326245784759521,
        "bert_f1": 0.9231233596801758,
        "meteor": 0.860636277302944,
        "sbert_similarity": 0.9463666081428528
      }
    },
    {
      "sample_id": 0,
      "question": "What is the favorite game Jolene plays with her partner?",
      "prediction": "We played the game \"Detroit\" on the console.",
      "reference": "It takes two",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8405765891075134,
        "bert_recall": 0.7973237037658691,
        "bert_f1": 0.8183789849281311,
        "meteor": 0.0,
        "sbert_similarity": 0.027735568583011627
      }
    },
    {
      "sample_id": 0,
      "question": "What activity does Deborah do with her cats?",
      "prediction": "I took him when my mother passed away.",
      "reference": "take them out for a run in the park every morning and evening",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8570841550827026,
        "bert_recall": 0.8305479884147644,
        "bert_f1": 0.843607485294342,
        "meteor": 0.08,
        "sbert_similarity": 0.1343349814414978
      }
    },
    {
      "sample_id": 0,
      "question": "How does Jolene describe the feeling of finding her snake snuggled under the bed after it got out?",
      "prediction": "I spent hours searching, so relieved when I finally found her snuggling under the bed. It really showed how much I love her.",
      "reference": "It really showed how much she loves her.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4285714285714285,
        "rouge1_f": 0.4516129032258065,
        "rouge2_f": 0.3448275862068965,
        "rougeL_f": 0.4516129032258065,
        "bleu1": 0.2692307692307693,
        "bleu2": 0.2320477404461286,
        "bleu3": 0.1919823711270459,
        "bleu4": 0.15553986407412196,
        "bert_precision": 0.8750391006469727,
        "bert_recall": 0.9377758502960205,
        "bert_f1": 0.9053218960762024,
        "meteor": 0.728249194414608,
        "sbert_similarity": 0.4428890347480774
      }
    },
    {
      "sample_id": 0,
      "question": "Why does Deborah take her cats out for a run in the park every day?",
      "prediction": "Exercise and nature are really important to me.",
      "reference": "Exercise and nature are important to her",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.7999999999999999,
        "rouge1_f": 0.7999999999999999,
        "rouge2_f": 0.6153846153846153,
        "rougeL_f": 0.7999999999999999,
        "bleu1": 0.6666666666666666,
        "bleu2": 0.5773502691896257,
        "bleu3": 0.46026455517844755,
        "bleu4": 0.3549481056010053,
        "bert_precision": 0.9770984649658203,
        "bert_recall": 0.9850162267684937,
        "bert_f1": 0.9810413718223572,
        "meteor": 0.8294209702660407,
        "sbert_similarity": 0.6250620484352112
      }
    },
    {
      "sample_id": 0,
      "question": "How did Jolene come to have her pet, Susie?",
      "prediction": "I adopted her two years ago when I was feeling lonely and wanted some company.",
      "reference": "She adopted her two years ago when feeling lonely.",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6956521739130435,
        "rouge1_f": 0.6666666666666667,
        "rouge2_f": 0.5454545454545454,
        "rougeL_f": 0.6666666666666667,
        "bleu1": 0.5625,
        "bleu2": 0.47434164902525694,
        "bleu3": 0.4042758289982756,
        "bleu4": 0.3489981252688509,
        "bert_precision": 0.9249916076660156,
        "bert_recall": 0.964111328125,
        "bert_f1": 0.9441463947296143,
        "meteor": 0.7206632653061225,
        "sbert_similarity": 0.7863562107086182
      }
    },
    {
      "sample_id": 0,
      "question": "What activities have been helping Jolene stay distracted during tough times?",
      "prediction": "spending time with her pet, doing yoga and meditation, and participating in workshops and events",
      "reference": "Video games and spending time with her pet, Susie",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5454545454545455,
        "rouge1_f": 0.5,
        "rouge2_f": 0.36363636363636365,
        "rougeL_f": 0.4166666666666667,
        "bleu1": 0.4117647058823529,
        "bleu2": 0.35871502698971963,
        "bleu3": 0.32862787454531706,
        "bleu4": 0.2928298013714697,
        "bert_precision": 0.8919447660446167,
        "bert_recall": 0.8970745205879211,
        "bert_f1": 0.8945022225379944,
        "meteor": 0.6134259259259259,
        "sbert_similarity": 0.6107792258262634
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of yoga routine does Deborah recommend to Jolene?",
      "prediction": "a gentle flow that's all about breathing and grounding",
      "reference": "A gentle flow routine focused on breathing and grounding",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.631578947368421,
        "rouge2_f": 0.47058823529411764,
        "rougeL_f": 0.631578947368421,
        "bleu1": 0.6,
        "bleu2": 0.5163977794943222,
        "bleu3": 0.4091569047284194,
        "bleu4": 0.17567205239427922,
        "bert_precision": 0.9498218894004822,
        "bert_recall": 0.9590703845024109,
        "bert_f1": 0.9544237852096558,
        "meteor": 0.654320987654321,
        "sbert_similarity": 0.8637232780456543
      }
    },
    {
      "sample_id": 0,
      "question": "What did Jolene design inspired by their love for space and engines?",
      "prediction": "notebooks with elements like galaxies and circuitry",
      "reference": "Notebooks",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.25,
        "rouge2_f": 0.0,
        "rougeL_f": 0.25,
        "bleu1": 0.14285714285714285,
        "bleu2": 0.048795003647426664,
        "bleu3": 0.037468614372419724,
        "bleu4": 0.033031643180138064,
        "bert_precision": 0.8205810785293579,
        "bert_recall": 0.837803840637207,
        "bert_f1": 0.8291030526161194,
        "meteor": 0.31250000000000006,
        "sbert_similarity": 0.7459202408790588
      }
    },
    {
      "sample_id": 0,
      "question": "What journal has Jolene been using to help track tasks and stay organized?",
      "prediction": "bullet journal",
      "reference": "bullet journal",
      "category": 4,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 0.46773514128719823,
        "bleu4": 0.316227766016838,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9375,
        "sbert_similarity": 1.000000238418579
      }
    },
    {
      "sample_id": 0,
      "question": "What game did Jolene recommend for being calming and cute?",
      "prediction": "Animal Crossing: New Horizons is really calming and cute.",
      "reference": "Animal Crossing: New Horizons",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6153846153846153,
        "rouge1_f": 0.6153846153846153,
        "rouge2_f": 0.5454545454545454,
        "rougeL_f": 0.6153846153846153,
        "bleu1": 0.45454545454545453,
        "bleu2": 0.4264014327112209,
        "bleu3": 0.3964882289652318,
        "bleu4": 0.3508439695638686,
        "bert_precision": 0.9115729928016663,
        "bert_recall": 0.9819133877754211,
        "bert_f1": 0.9454367160797119,
        "meteor": 0.8819444444444445,
        "sbert_similarity": 0.799439549446106
      }
    },
    {
      "sample_id": 0,
      "question": "What game did Jolene suggest as an awesome open-world game for the Nintendo Switch?",
      "prediction": "Zelda BOTW",
      "reference": "Zelda BOTW",
      "category": 4,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 0.46773514128719823,
        "bleu4": 0.316227766016838,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9375,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What did Deborah and her husband use to play to bond and make memories?",
      "prediction": "play games",
      "reference": "video games",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 0.5,
        "rouge2_f": 0.0,
        "rougeL_f": 0.5,
        "bleu1": 0.5,
        "bleu2": 0.223606797749979,
        "bleu3": 0.1740444189610778,
        "bleu4": 0.1495348781221221,
        "bert_precision": 0.9962374567985535,
        "bert_recall": 0.9962374567985535,
        "bert_f1": 0.9962374567985535,
        "meteor": 0.25,
        "sbert_similarity": 0.7346286773681641
      }
    },
    {
      "sample_id": 0,
      "question": "What is special about the bench at the park near Deborah's house?",
      "prediction": "There's also a special bench that holds special meaning to me.",
      "reference": "It holds special memories of conversations with her mom",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2105263157894737,
        "rouge1_f": 0.1904761904761905,
        "rouge2_f": 0.10526315789473685,
        "rougeL_f": 0.1904761904761905,
        "bleu1": 0.15384615384615385,
        "bleu2": 0.11322770341445958,
        "bleu3": 0.05034417113155098,
        "bleu4": 0.03285702044797773,
        "bert_precision": 0.873719334602356,
        "bert_recall": 0.8622890114784241,
        "bert_f1": 0.8679665327072144,
        "meteor": 0.20380434782608692,
        "sbert_similarity": 0.2514879107475281
      }
    },
    {
      "sample_id": 0,
      "question": "What did Deborah and her mom chat about at their special bench in the park?",
      "prediction": "dreams and life",
      "reference": "dreams and life",
      "category": 4,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 1.0000001192092896,
        "bert_recall": 1.0000001192092896,
        "bert_f1": 1.0000001192092896,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What feeling does Deborah get when she thinks about the time spent with her mom at their special spot?",
      "prediction": "It's full of good moments.",
      "reference": "peace and gratitude",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.864771842956543,
        "bert_recall": 0.8397578001022339,
        "bert_f1": 0.852081298828125,
        "meteor": 0.0,
        "sbert_similarity": 0.29909276962280273
      }
    },
    {
      "sample_id": 0,
      "question": "What habits does Jolene practice to feel balanced?",
      "prediction": "self-care, like yoga and meditation.",
      "reference": "yoga, meditation, walks, and mindfulness",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6,
        "rouge1_f": 0.5454545454545454,
        "rouge2_f": 0.0,
        "rougeL_f": 0.3636363636363636,
        "bleu1": 0.4953587998572467,
        "bleu2": 0.08459862056036736,
        "bleu3": 0.05132221137688236,
        "bleu4": 0.04049515890265692,
        "bert_precision": 0.8936758637428284,
        "bert_recall": 0.9092652201652527,
        "bert_f1": 0.9014031291007996,
        "meteor": 0.10000000000000002,
        "sbert_similarity": 0.6551253795623779
      }
    },
    {
      "sample_id": 0,
      "question": "Which yoga pose is Jolene a fan of for rest and calmness?",
      "prediction": "savasana - aka the corpse pose",
      "reference": "savasana (the corpse pose)",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.888888888888889,
        "rouge2_f": 0.5714285714285715,
        "rougeL_f": 0.888888888888889,
        "bleu1": 0.6666666666666666,
        "bleu2": 0.5163977794943222,
        "bleu3": 0.4091569047284194,
        "bleu4": 0.21711852081087685,
        "bert_precision": 0.9548021554946899,
        "bert_recall": 0.9654984474182129,
        "bert_f1": 0.9601204991340637,
        "meteor": 0.2380952380952381,
        "sbert_similarity": 0.961768627166748
      }
    },
    {
      "sample_id": 0,
      "question": "How long has Jolene been doing yoga?",
      "prediction": "Nice job, Jolene! How long have you been doing yoga and meditation?",
      "reference": "3 years",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.822493314743042,
        "bert_recall": 0.8391119241714478,
        "bert_f1": 0.830719530582428,
        "meteor": 0.0,
        "sbert_similarity": 0.341994971036911
      }
    },
    {
      "sample_id": 0,
      "question": "What did Jolene participate in recently that provided her with a rewarding experience?",
      "prediction": "I'm interning at a well-known engineering firm. It's been a great opportunity to test my skills and gain real-world experience.",
      "reference": "presenting at a virtual conference",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.16666666666666666,
        "rouge1_f": 0.13793103448275862,
        "rouge2_f": 0.07407407407407408,
        "rougeL_f": 0.13793103448275862,
        "bleu1": 0.08333333333333333,
        "bleu2": 0.06019292654288461,
        "bleu3": 0.026393714719473722,
        "bleu4": 0.016734480530603443,
        "bert_precision": 0.8288596868515015,
        "bert_recall": 0.8476476669311523,
        "bert_f1": 0.8381484150886536,
        "meteor": 0.15384615384615388,
        "sbert_similarity": 0.13132382929325104
      }
    },
    {
      "sample_id": 0,
      "question": "How did Jolene feel after receiving positive feedback at the virtual conference?",
      "prediction": "It was a great experience and confirmed that I'm on the right track.",
      "reference": "thrilled and rewarded",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.125,
        "rouge1_f": 0.11764705882352941,
        "rouge2_f": 0.0,
        "rougeL_f": 0.11764705882352941,
        "bleu1": 0.06666666666666667,
        "bleu2": 0.02182178902359924,
        "bleu3": 0.016071866876084712,
        "bleu4": 0.013217947626377298,
        "bert_precision": 0.8423473834991455,
        "bert_recall": 0.832566499710083,
        "bert_f1": 0.8374283909797668,
        "meteor": 0.125,
        "sbert_similarity": 0.3192569315433502
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of event did Jolene present at recently?",
      "prediction": "Sounds like a great way to relax.",
      "reference": "virtual conference",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8479814529418945,
        "bert_recall": 0.846379280090332,
        "bert_f1": 0.847179651260376,
        "meteor": 0.0,
        "sbert_similarity": 0.09334447979927063
      }
    },
    {
      "sample_id": 0,
      "question": "What did Jolene's mom stress the value of, which she wants to keep in mind for her engineering projects?",
      "prediction": "helping others",
      "reference": "Helping others",
      "category": 4,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 0.46773514128719823,
        "bleu4": 0.316227766016838,
        "bert_precision": 0.9383810758590698,
        "bert_recall": 0.9119039177894592,
        "bert_f1": 0.9249529838562012,
        "meteor": 0.9375,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What type of projects is Jolene interested in getting involved in the future?",
      "prediction": "projects that make a real difference to communities, sustainable initiatives and developing innovative solutions for environmental issues, social causes",
      "reference": "Sustainable initiatives and developing innovative solutions for environmental issues",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6428571428571429,
        "rouge1_f": 0.6428571428571429,
        "rouge2_f": 0.6153846153846153,
        "rougeL_f": 0.6428571428571429,
        "bleu1": 0.42857142857142855,
        "bleu2": 0.41403933560541256,
        "bleu3": 0.40192139296044693,
        "bleu4": 0.38091370416670794,
        "bert_precision": 0.9017528295516968,
        "bert_recall": 0.9609056711196899,
        "bert_f1": 0.9303900003433228,
        "meteor": 0.7992187500000001,
        "sbert_similarity": 0.7742274403572083
      }
    },
    {
      "sample_id": 0,
      "question": "How did Deborah get Luna, one of her cats?",
      "prediction": "I took Luna from the shelter.",
      "reference": "From the shelter",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6666666666666666,
        "rouge1_f": 0.6666666666666666,
        "rouge2_f": 0.5714285714285715,
        "rougeL_f": 0.6666666666666666,
        "bleu1": 0.42857142857142855,
        "bleu2": 0.3779644730092272,
        "bleu3": 0.30935528891357367,
        "bleu4": 0.16348126556655487,
        "bert_precision": 0.8845548629760742,
        "bert_recall": 0.8960587382316589,
        "bert_f1": 0.8902695775032043,
        "meteor": 0.5681818181818182,
        "sbert_similarity": 0.5362256765365601
      }
    },
    {
      "sample_id": 0,
      "question": "How old is Max?",
      "prediction": "Max is 8 years old.",
      "reference": "8 years old",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.7499999999999999,
        "rouge1_f": 0.7499999999999999,
        "rouge2_f": 0.6666666666666666,
        "rougeL_f": 0.7499999999999999,
        "bleu1": 0.5,
        "bleu2": 0.447213595499958,
        "bleu3": 0.3721003696282278,
        "bleu4": 0.20205155046766235,
        "bert_precision": 0.9219101667404175,
        "bert_recall": 0.9223495721817017,
        "bert_f1": 0.9221298098564148,
        "meteor": 0.5859375,
        "sbert_similarity": 0.5282630324363708
      }
    },
    {
      "sample_id": 0,
      "question": "What type of classes did Jolene and her partner check out during their trip to Rio de Janeiro on 30 August, 2023?",
      "prediction": "yoga classes",
      "reference": "Yoga classes",
      "category": 4,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 0.46773514128719823,
        "bleu4": 0.316227766016838,
        "bert_precision": 0.9983010292053223,
        "bert_recall": 0.9983010292053223,
        "bert_f1": 0.9983010292053223,
        "meteor": 0.9375,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What type of place does Jolene visit to meditate?",
      "prediction": "a nearby place to meditate by a tranquil spot",
      "reference": "A tranquil spot by a pond",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.6153846153846154,
        "rouge1_f": 0.6666666666666667,
        "rouge2_f": 0.4615384615384615,
        "rougeL_f": 0.4,
        "bleu1": 0.5555555555555556,
        "bleu2": 0.45643546458763845,
        "bleu3": 0.3135508904498039,
        "bleu4": 0.14923729480049117,
        "bert_precision": 0.9116306304931641,
        "bert_recall": 0.9446440935134888,
        "bert_f1": 0.9278437495231628,
        "meteor": 0.7079365079365081,
        "sbert_similarity": 0.640250563621521
      }
    },
    {
      "sample_id": 0,
      "question": "What was the new plant Jolene got used as a reminder for on 30 August, 2023?",
      "prediction": "I met my new neighbor Anna yesterday!",
      "reference": "To nurture herself and embrace fresh starts",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8358749151229858,
        "bert_recall": 0.8427884578704834,
        "bert_f1": 0.8393174409866333,
        "meteor": 0.07142857142857142,
        "sbert_similarity": 0.240098237991333
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Jolene get the new plant on 30 August, 2023?",
      "prediction": "Jolene got the new plant for calming and connecting with nature.",
      "reference": "As a reminder to nurture herself and embrace fresh starts",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.09523809523809525,
        "rouge1_f": 0.09523809523809525,
        "rouge2_f": 0.0,
        "rougeL_f": 0.09523809523809525,
        "bleu1": 0.08333333333333333,
        "bleu2": 0.027524094128159027,
        "bleu3": 0.020427282860665447,
        "bleu4": 0.017033186037639283,
        "bert_precision": 0.8521894812583923,
        "bert_recall": 0.8617342710494995,
        "bert_f1": 0.8569353222846985,
        "meteor": 0.14851485148514848,
        "sbert_similarity": 0.3406236171722412
      }
    },
    {
      "sample_id": 0,
      "question": "What has Jolene been focusing on lately besides studying?",
      "prediction": "I've been working on a big project lately - it's been tough but also really cool to watch it take shape.",
      "reference": "relationship with her partner",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8203080296516418,
        "bert_recall": 0.8480746746063232,
        "bert_f1": 0.8339603543281555,
        "meteor": 0.0,
        "sbert_similarity": 0.03809822350740433
      }
    },
    {
      "sample_id": 0,
      "question": "How did Deborah's mom support her yoga practice when she first started?",
      "prediction": "My mum was my biggest fan and source of motivation. She'd often come to my classes with me.",
      "reference": "attended classes with her",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.2,
        "rouge1_f": 0.17391304347826086,
        "rouge2_f": 0.09523809523809525,
        "rougeL_f": 0.17391304347826086,
        "bleu1": 0.09523809523809525,
        "bleu2": 0.06900655593423542,
        "bleu3": 0.030316491853278917,
        "bleu4": 0.019316954186233335,
        "bert_precision": 0.858138918876648,
        "bert_recall": 0.891363799571991,
        "bert_f1": 0.8744359016418457,
        "meteor": 0.34722222222222227,
        "sbert_similarity": 0.5213899612426758
      }
    },
    {
      "sample_id": 0,
      "question": "What was the video game console that Jolene's parents got her at age 10?",
      "prediction": "a Nintendo game console",
      "reference": "nintendo game console",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8571428571428571,
        "rouge1_f": 0.8571428571428571,
        "rouge2_f": 0.8,
        "rougeL_f": 0.8571428571428571,
        "bleu1": 0.75,
        "bleu2": 0.7071067811865475,
        "bleu3": 0.63287829698514,
        "bleu4": 0.3976353643835253,
        "bert_precision": 0.9301676750183105,
        "bert_recall": 0.9301676750183105,
        "bert_f1": 0.9301676750183105,
        "meteor": 0.9498207885304659,
        "sbert_similarity": 0.9486323595046997
      }
    },
    {
      "sample_id": 0,
      "question": "What was one of Jolene's favorite games to play with her mom on the nintendo wii game system?",
      "prediction": "I taught myself, but my dad was always supportive and my mom would play games with me.",
      "reference": "Monster Hunter: World",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8214487433433533,
        "bert_recall": 0.7724816799163818,
        "bert_f1": 0.7962130308151245,
        "meteor": 0.0,
        "sbert_similarity": 0.13034170866012573
      }
    },
    {
      "sample_id": 0,
      "question": "What course did Jolene sign up for on 6 September 2023?",
      "prediction": "Jolene! Congrats on wrapping up your with it!",
      "reference": "meditation",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.766991913318634,
        "bert_recall": 0.8157781362533569,
        "bert_f1": 0.7906330823898315,
        "meteor": 0.0,
        "sbert_similarity": 0.03199251741170883
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Jolene have to reschedule their meeting with Deborah on September 8, 2023?",
      "prediction": "emotional rollercoaster",
      "reference": "Jolene already had plans",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.806840181350708,
        "bert_recall": 0.809769868850708,
        "bert_f1": 0.8083024024963379,
        "meteor": 0.0,
        "sbert_similarity": 0.09947636723518372
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Jolene and her partner travel for a few weeks in September 2023?",
      "prediction": "We'll definitely go there together sometime!",
      "reference": "Phuket",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.7926140427589417,
        "bert_recall": 0.720252513885498,
        "bert_f1": 0.7547027468681335,
        "meteor": 0.0,
        "sbert_similarity": 0.12373213469982147
      }
    },
    {
      "sample_id": 0,
      "question": "What was the main focus of the session that stood out to Jolene during the retreat?",
      "prediction": "self-assessment",
      "reference": "releasing expectations and judgments and savoring the present",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8550929427146912,
        "bert_recall": 0.8495982885360718,
        "bert_f1": 0.8523367643356323,
        "meteor": 0.0,
        "sbert_similarity": 0.3229124844074249
      }
    },
    {
      "sample_id": 0,
      "question": "How did Jolene feel about her progress in practicing mindfulness and gratitude?",
      "prediction": "Appreciating those small things is important. It helps me remember that even when times are tough, there's always something positive to hang onto.",
      "reference": "experiencing a new level of joy and happiness",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8439246416091919,
        "bert_recall": 0.8470776677131653,
        "bert_f1": 0.8454982042312622,
        "meteor": 0.05263157894736842,
        "sbert_similarity": 0.4332168996334076
      }
    },
    {
      "sample_id": 0,
      "question": "What positive change did Jolene experience during the retreat?",
      "prediction": "a new outlook",
      "reference": "finding inner peace",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8725487589836121,
        "bert_recall": 0.860657274723053,
        "bert_f1": 0.8665621876716614,
        "meteor": 0.0,
        "sbert_similarity": 0.1555865854024887
      }
    },
    {
      "sample_id": 0,
      "question": "What did Jolene recently play that she described to Deb?",
      "prediction": "What was it like?",
      "reference": "a card game about cats",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8190412521362305,
        "bert_recall": 0.833839476108551,
        "bert_f1": 0.8263741731643677,
        "meteor": 0.0,
        "sbert_similarity": 0.10462149232625961
      }
    },
    {
      "sample_id": 0,
      "question": "What did Deborah do with their mom's old friends?",
      "prediction": "reconnected with my mom's old friends",
      "reference": "reminisced and looked through photos",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8600356578826904,
        "bert_recall": 0.8338547945022583,
        "bert_f1": 0.8467428684234619,
        "meteor": 0.0,
        "sbert_similarity": 0.2649402618408203
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Deborah get married?",
      "prediction": "This is my husband in front of this house.",
      "reference": "on the beach",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8536581993103027,
        "bert_recall": 0.8778085112571716,
        "bert_f1": 0.8655649423599243,
        "meteor": 0.0,
        "sbert_similarity": 0.26408150792121887
      }
    },
    {
      "sample_id": 0,
      "question": "What does yoga on the beach provide for Deborah?",
      "prediction": "the perfect way to take care of myself",
      "reference": "a peaceful atmosphere",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8431713581085205,
        "bert_recall": 0.8833985328674316,
        "bert_f1": 0.862816333770752,
        "meteor": 0.0,
        "sbert_similarity": 0.17570969462394714
      }
    },
    {
      "sample_id": 0,
      "question": "How does Jolene describe their home room?",
      "prediction": "In my room, I usually go to relax and feel at ease. After a busy day, it's my little haven for peace and rest - the perfect spot to relax and recharge.",
      "reference": "little haven for peace and rest",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.3636363636363636,
        "rouge1_f": 0.3157894736842105,
        "rouge2_f": 0.27777777777777773,
        "rougeL_f": 0.3157894736842105,
        "bleu1": 0.16216216216216217,
        "bleu2": 0.15007505629691606,
        "bleu3": 0.13979800131408224,
        "bleu4": 0.1227616815524213,
        "bert_precision": 0.8699648976325989,
        "bert_recall": 0.9177851676940918,
        "bert_f1": 0.8932355046272278,
        "meteor": 0.6540697674418605,
        "sbert_similarity": 0.26409685611724854
      }
    },
    {
      "sample_id": 0,
      "question": "What new activity did Deborah and her neighbor organize for the community on 16 September, 2023?",
      "prediction": "me and my neighbor ran a free gardening class for the community",
      "reference": "Free gardening class",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4,
        "rouge1_f": 0.4,
        "rouge2_f": 0.3076923076923077,
        "rougeL_f": 0.4,
        "bleu1": 0.25,
        "bleu2": 0.21320071635561041,
        "bleu3": 0.16865550266337087,
        "bleu4": 0.08430118946484098,
        "bert_precision": 0.8758156299591064,
        "bert_recall": 0.9355934858322144,
        "bert_f1": 0.9047182202339172,
        "meteor": 0.7549857549857552,
        "sbert_similarity": 0.8171904683113098
      }
    },
    {
      "sample_id": 0,
      "question": "What was Deborah's mom passionate about?",
      "prediction": "Travel was also her great passion!",
      "reference": "Cooking",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8049652576446533,
        "bert_recall": 0.8532726764678955,
        "bert_f1": 0.8284152746200562,
        "meteor": 0.0,
        "sbert_similarity": 0.05565379932522774
      }
    },
    {
      "sample_id": 0,
      "question": "What food did Deborah's mom make for her on birthdays?",
      "prediction": "pineapple birthday cakes",
      "reference": "Pineapple cakes",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.8,
        "rouge1_f": 0.8,
        "rouge2_f": 0.0,
        "rougeL_f": 0.8,
        "bleu1": 0.6666666666666666,
        "bleu2": 0.18257418583505536,
        "bleu3": 0.1522474354853864,
        "bleu4": 0.13512001548070346,
        "bert_precision": 0.9060444235801697,
        "bert_recall": 0.8502072691917419,
        "bert_f1": 0.8772382140159607,
        "meteor": 0.4761904761904762,
        "sbert_similarity": 0.8782073259353638
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of cookies did Jolene used to bake with someone close to her?",
      "prediction": "chocolate chip cookies",
      "reference": "Chocolate chip cookies",
      "category": 4,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 0.9697465300559998,
        "bert_recall": 0.9697465300559998,
        "bert_f1": 0.9697465300559998,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What outdoor activity did Jolene suggest doing together with Deborah?",
      "prediction": "going for walks to take it all in",
      "reference": "Surfing",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.809247612953186,
        "bert_recall": 0.7970792055130005,
        "bert_f1": 0.8031172752380371,
        "meteor": 0.0,
        "sbert_similarity": 0.1696004420518875
      }
    },
    {
      "sample_id": 0,
      "question": "What activity did Deborah enjoy at the music festival with their pals on September 20, 2023?",
      "prediction": "dance and bop around",
      "reference": "Dancing and bopping around",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.5,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 0.5,
        "bleu2": 0.12909944487358058,
        "bleu3": 0.09635409769034631,
        "bleu4": 0.09554427922043669,
        "bert_precision": 0.9532220363616943,
        "bert_recall": 0.9532220363616943,
        "bert_f1": 0.9532220363616943,
        "meteor": 0.9921875,
        "sbert_similarity": 0.9467301368713379
      }
    },
    {
      "sample_id": 0,
      "question": "What did Deborah find freeing at the music festival?",
      "prediction": "It was so freeing to dance and bop around.",
      "reference": "Dancing and bopping around",
      "category": 4,
      "metrics": {
        "exact_match": 0,
        "f1": 0.30769230769230765,
        "rouge1_f": 0.6153846153846153,
        "rouge2_f": 0.5454545454545454,
        "rougeL_f": 0.6153846153846153,
        "bleu1": 0.2,
        "bleu2": 0.04714045207910317,
        "bleu3": 0.03136318607896979,
        "bleu4": 0.025098621243978974,
        "bert_precision": 0.8723219037055969,
        "bert_recall": 0.8951267004013062,
        "bert_f1": 0.8835771083831787,
        "meteor": 0.654320987654321,
        "sbert_similarity": 0.6539264917373657
      }
    },
    {
      "sample_id": 0,
      "question": "What are the names of Deborah's snakes?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Susie, Seraphim",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8715996742248535,
        "bert_recall": 0.825202226638794,
        "bert_f1": 0.8477665781974792,
        "meteor": 0.0,
        "sbert_similarity": 0.11498250812292099
      }
    },
    {
      "sample_id": 0,
      "question": "What are Deborah's favorite books?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Sapiens, Avalanche by Neal Stephenson",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8562721014022827,
        "bert_recall": 0.7947893738746643,
        "bert_f1": 0.824385941028595,
        "meteor": 0.0,
        "sbert_similarity": 0.05159516632556915
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Deborah get her dogs?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Luna is from the shelter and Max is her mother's cat",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.13333333333333333,
        "rouge1_f": 0.11764705882352941,
        "rouge2_f": 0.0,
        "rougeL_f": 0.11764705882352941,
        "bleu1": 0.0493193927883213,
        "bleu2": 0.017437038542312454,
        "bleu3": 0.013970045246163798,
        "bleu4": 0.013249284136531224,
        "bert_precision": 0.8761718273162842,
        "bert_recall": 0.8351521492004395,
        "bert_f1": 0.8551703691482544,
        "meteor": 0.04807692307692308,
        "sbert_similarity": 0.09645657986402512
      }
    },
    {
      "sample_id": 0,
      "question": "How old are Jolene's cats?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Max is 8 years old and Luna is 5 years old",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8629279732704163,
        "bert_recall": 0.8255099058151245,
        "bert_f1": 0.8438042998313904,
        "meteor": 0.0,
        "sbert_similarity": 0.07399392127990723
      }
    },
    {
      "sample_id": 0,
      "question": "When did Deborah's parents give her first console?",
      "prediction": "Not mentioned in the conversation",
      "reference": "when she was 10",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.873089075088501,
        "bert_recall": 0.8451880812644958,
        "bert_f1": 0.8589119911193848,
        "meteor": 0.0,
        "sbert_similarity": 0.10233412683010101
      }
    },
    {
      "sample_id": 0,
      "question": "When did Jolene release her pet snake?",
      "prediction": "A year ago",
      "reference": "A year ago",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 0.9999998807907104
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Jolene meet her new friend Anna?",
      "prediction": "Not mentioned in the conversation",
      "reference": "yoga in the park",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.4444444444444445,
        "rouge1_f": 0.4444444444444445,
        "rouge2_f": 0.28571428571428575,
        "rougeL_f": 0.4444444444444445,
        "bleu1": 0.4,
        "bleu2": 0.316227766016838,
        "bleu3": 0.1522474354853864,
        "bleu4": 0.11362193664674995,
        "bert_precision": 0.8891993761062622,
        "bert_recall": 0.8839166164398193,
        "bert_f1": 0.8865500688552856,
        "meteor": 0.45731707317073167,
        "sbert_similarity": 0.07275736331939697
      }
    },
    {
      "sample_id": 0,
      "question": "What is Deborah's favorite book which she mentioned on 4 February, 2023?",
      "prediction": "Not mentioned in the conversation",
      "reference": "\"Sapiens\"",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8610952496528625,
        "bert_recall": 0.8128283619880676,
        "bert_f1": 0.8362659215927124,
        "meteor": 0.0,
        "sbert_similarity": 0.11855398863554001
      }
    },
    {
      "sample_id": 0,
      "question": "What cool stuff did Deborah accomplish at the retreat on 9 February, 2023?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Came up with neat solutions for her engineering project",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8854869604110718,
        "bert_recall": 0.8422255516052246,
        "bert_f1": 0.8633146286010742,
        "meteor": 0.0,
        "sbert_similarity": 0.0781913697719574
      }
    },
    {
      "sample_id": 0,
      "question": "How does Deborah plan to involve local engineers in her idea of teaching STEM to underprivileged kids?",
      "prediction": "As guest speakers for workshops",
      "reference": "As guest speakers for workshops",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.996,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What gave Deborah anxiety in the garden she visited?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Roses and dahlias",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.869046151638031,
        "bert_recall": 0.8141825795173645,
        "bert_f1": 0.8407202363014221,
        "meteor": 0.0,
        "sbert_similarity": 0.08001655340194702
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Jolene spend time in the garden?",
      "prediction": "Not mentioned in the conversation",
      "reference": "to find comfort after losing a friend",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8837411403656006,
        "bert_recall": 0.8712509870529175,
        "bert_f1": 0.8774515986442566,
        "meteor": 0.0,
        "sbert_similarity": 0.0468454584479332
      }
    },
    {
      "sample_id": 0,
      "question": "How did Jolene and her rival initially meet?",
      "prediction": "Not mentioned in the conversation",
      "reference": "In an engineering class in college",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.20000000000000004,
        "rouge1_f": 0.1818181818181818,
        "rouge2_f": 0.0,
        "rougeL_f": 0.1818181818181818,
        "bleu1": 0.1637461506155964,
        "bleu2": 0.05789300674674099,
        "bleu3": 0.046382183633183686,
        "bleu4": 0.0439891724758422,
        "bert_precision": 0.8838033676147461,
        "bert_recall": 0.8545609712600708,
        "bert_f1": 0.8689362406730652,
        "meteor": 0.0847457627118644,
        "sbert_similarity": 0.09315697848796844
      }
    },
    {
      "sample_id": 0,
      "question": "What activity does Jolene incorporate into her daily routine after going for a morning jog in the park?",
      "prediction": "Not mentioned in the conversation",
      "reference": "spending time with loved ones",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8719295859336853,
        "bert_recall": 0.8355236053466797,
        "bert_f1": 0.8533384799957275,
        "meteor": 0.0,
        "sbert_similarity": 0.1054973155260086
      }
    },
    {
      "sample_id": 0,
      "question": "What method does Jolene suggest Deborah to try for organizing tasks based on importance and urgency?",
      "prediction": "Not mentioned in the conversation",
      "reference": "The Eisenhower Matrix",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.25,
        "rouge2_f": 0.0,
        "rougeL_f": 0.25,
        "bleu1": 0.2,
        "bleu2": 0.07071067811865477,
        "bleu3": 0.05665132701906204,
        "bleu4": 0.05372849659117709,
        "bert_precision": 0.8701463341712952,
        "bert_recall": 0.8589990139007568,
        "bert_f1": 0.8645367622375488,
        "meteor": 0.15625,
        "sbert_similarity": 0.07345458120107651
      }
    },
    {
      "sample_id": 0,
      "question": "How does Jolene plan to pursue her dream of climbing mountains?",
      "prediction": "Not mentioned in the conversation",
      "reference": "gathering information, watching videos, getting a beginners' guide",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8809507489204407,
        "bert_recall": 0.8529725074768066,
        "bert_f1": 0.8667359352111816,
        "meteor": 0.0,
        "sbert_similarity": 0.011919572949409485
      }
    },
    {
      "sample_id": 0,
      "question": "Who are the authors mentioned by Jolene that she enjoys reading during her yoga practice?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Nils Frahm and Olafur Arnalds",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8529372215270996,
        "bert_recall": 0.744828999042511,
        "bert_f1": 0.7952256798744202,
        "meteor": 0.0,
        "sbert_similarity": 0.12543624639511108
      }
    },
    {
      "sample_id": 0,
      "question": "Which show did Jolene go to with a friend on 9 April, 2023?",
      "prediction": "an art show",
      "reference": "an art show",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What does Deborah find comforting about going to horror movie screenings?",
      "prediction": "Not mentioned in the conversation",
      "reference": "It makes her feel like she's still experiencing it with her mom",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8677970170974731,
        "bert_recall": 0.8389610648155212,
        "bert_f1": 0.8531354665756226,
        "meteor": 0.0,
        "sbert_similarity": 0.037503086030483246
      }
    },
    {
      "sample_id": 0,
      "question": "How does Deborah describe the time spent with her snakes and partner?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Valuable and relaxing",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.867763340473175,
        "bert_recall": 0.8323348760604858,
        "bert_f1": 0.8496799468994141,
        "meteor": 0.0,
        "sbert_similarity": 0.12444566190242767
      }
    },
    {
      "sample_id": 0,
      "question": "For how long has Jolene had Lucifer as a pet?",
      "prediction": "Not mentioned in the conversation",
      "reference": "one year",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8675765991210938,
        "bert_recall": 0.882532000541687,
        "bert_f1": 0.8749904036521912,
        "meteor": 0.0,
        "sbert_similarity": 0.09858499467372894
      }
    },
    {
      "sample_id": 0,
      "question": "How does Deborah feel when spending time with Seraphim?",
      "prediction": "Not mentioned in the conversation",
      "reference": "comforted",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8675909042358398,
        "bert_recall": 0.8473381996154785,
        "bert_f1": 0.857344925403595,
        "meteor": 0.0,
        "sbert_similarity": 0.19600291550159454
      }
    },
    {
      "sample_id": 0,
      "question": "What made being part of the running group easy for Jolene to stay motivated?",
      "prediction": "helping and pushing each other during runs",
      "reference": "helping and pushing each other during runs",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9985422740524781,
        "sbert_similarity": 0.9999999403953552
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Jolene decide to get a tarantula as a pet?",
      "prediction": "Not mentioned in the conversation",
      "reference": "fascinated by reptiles and it felt like the perfect pet",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.13333333333333333,
        "rouge1_f": 0.13333333333333333,
        "rouge2_f": 0.0,
        "rougeL_f": 0.13333333333333333,
        "bleu1": 0.07357588823428847,
        "bleu2": 0.02601300475114445,
        "bleu3": 0.020840858525393174,
        "bleu4": 0.01976560930094397,
        "bert_precision": 0.8749295473098755,
        "bert_recall": 0.8415461778640747,
        "bert_f1": 0.8579132556915283,
        "meteor": 0.052631578947368425,
        "sbert_similarity": -0.010504177771508694
      }
    },
    {
      "sample_id": 0,
      "question": "How did Deborah come to have her pet, Susie?",
      "prediction": "Not mentioned in the conversation",
      "reference": "She adopted her two years ago when feeling lonely.",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8746306896209717,
        "bert_recall": 0.8423804044723511,
        "bert_f1": 0.8582026958465576,
        "meteor": 0.0,
        "sbert_similarity": 0.07686831057071686
      }
    },
    {
      "sample_id": 0,
      "question": "What did Deborah design inspired by their love for space and engines?",
      "prediction": "Notebooks",
      "reference": "Notebooks",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 0.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 0.316227766016838,
        "bleu3": 0.2187761623949553,
        "bleu4": 0.1778279410038923,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.5,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What journal has Deborah been using to help track tasks and stay organized?",
      "prediction": "Not mentioned in the conversation",
      "reference": "bullet journal",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8788697719573975,
        "bert_recall": 0.8686171770095825,
        "bert_f1": 0.8737134337425232,
        "meteor": 0.0,
        "sbert_similarity": 0.13520275056362152
      }
    },
    {
      "sample_id": 0,
      "question": "What game did Jolene recommend to Deborah for being thrilling and intense?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Animal Crossing: New Horizons",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8553851246833801,
        "bert_recall": 0.7750961780548096,
        "bert_f1": 0.8132638931274414,
        "meteor": 0.0,
        "sbert_similarity": 0.07317369431257248
      }
    },
    {
      "sample_id": 0,
      "question": "What game did Deborah suggest as an awesome open-world game for the Nintendo Switch?",
      "prediction": "Zelda BOTW",
      "reference": "Zelda BOTW",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 0.46773514128719823,
        "bleu4": 0.316227766016838,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9375,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What is special about the bench at the park near Jolene's house?",
      "prediction": "It holds special memories of conversations with her mom.",
      "reference": "It holds special memories of conversations with her mom",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 0.9,
        "bleu2": 0.8944271909999159,
        "bleu3": 0.888960273227615,
        "bleu4": 0.8801117367933934,
        "bert_precision": 0.9875357151031494,
        "bert_recall": 0.9861544966697693,
        "bert_f1": 0.9868445992469788,
        "meteor": 0.8880208333333333,
        "sbert_similarity": 0.9942597150802612
      }
    },
    {
      "sample_id": 0,
      "question": "What did Jolene and her mom chat about at their special bench in the park?",
      "prediction": "Not mentioned in the conversation",
      "reference": "dreams and life",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8782315254211426,
        "bert_recall": 0.8504981994628906,
        "bert_f1": 0.8641424179077148,
        "meteor": 0.0,
        "sbert_similarity": 0.1441478431224823
      }
    },
    {
      "sample_id": 0,
      "question": "How did Deborah feel after receiving positive feedback at the virtual conference?",
      "prediction": "thrilled and rewarded",
      "reference": "thrilled and rewarded",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of event did Deborah present at recently?",
      "prediction": "yoga event",
      "reference": "virtual conference",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.937172532081604,
        "bert_recall": 0.937172532081604,
        "bert_f1": 0.937172532081604,
        "meteor": 0.0,
        "sbert_similarity": 0.2956556975841522
      }
    },
    {
      "sample_id": 0,
      "question": "What did Deborah's mom stress the value of, which she wants to keep in mind for her engineering projects?",
      "prediction": "Helping others",
      "reference": "Helping others",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 0.46773514128719823,
        "bleu4": 0.316227766016838,
        "bert_precision": 0.9999998807907104,
        "bert_recall": 0.9999998807907104,
        "bert_f1": 0.9999998807907104,
        "meteor": 0.9375,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What type of projects is Deborah interested in getting involved in the future?",
      "prediction": "Sustainable initiatives and developing innovative solutions for environmental issues",
      "reference": "Sustainable initiatives and developing innovative solutions for environmental issues",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 0.9999999403953552,
        "bert_recall": 0.9999999403953552,
        "bert_f1": 0.9999999403953552,
        "meteor": 0.9993141289437586,
        "sbert_similarity": 1.0000001192092896
      }
    },
    {
      "sample_id": 0,
      "question": "How did Jolene get Luna, one of her cats?",
      "prediction": "Not mentioned in the conversation",
      "reference": "From the shelter",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.25,
        "rouge2_f": 0.0,
        "rougeL_f": 0.25,
        "bleu1": 0.2,
        "bleu2": 0.07071067811865477,
        "bleu3": 0.05665132701906204,
        "bleu4": 0.05372849659117709,
        "bert_precision": 0.8835307359695435,
        "bert_recall": 0.8661384582519531,
        "bert_f1": 0.8747481107711792,
        "meteor": 0.15625,
        "sbert_similarity": 0.11768080294132233
      }
    },
    {
      "sample_id": 0,
      "question": "What type of classes did Deborah and her partner check out during their trip to Rio de Janeiro on 30 August, 2023?",
      "prediction": "Yoga classes",
      "reference": "Yoga classes",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 0.46773514128719823,
        "bleu4": 0.316227766016838,
        "bert_precision": 0.9999998807907104,
        "bert_recall": 0.9999998807907104,
        "bert_f1": 0.9999998807907104,
        "meteor": 0.9375,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "Why did Deborah get the new plant on 30 August, 2023?",
      "prediction": "Not mentioned in the conversation",
      "reference": "As a reminder to nurture herself and embrace fresh starts",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8745598793029785,
        "bert_recall": 0.8379760384559631,
        "bert_f1": 0.8558772206306458,
        "meteor": 0.0,
        "sbert_similarity": 0.010935167782008648
      }
    },
    {
      "sample_id": 0,
      "question": "How did Jolene's mom support her yoga practice when she first started?",
      "prediction": "attended classes with her",
      "reference": "attended classes with her",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 1.0,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9921875,
        "sbert_similarity": 0.9999999403953552
      }
    },
    {
      "sample_id": 0,
      "question": "What was the video game console that Deborah's parents got her at age 10?",
      "prediction": "nintendo game console",
      "reference": "nintendo game console",
      "category": 5,
      "metrics": {
        "exact_match": 1,
        "f1": 1.0,
        "rouge1_f": 1.0,
        "rouge2_f": 1.0,
        "rougeL_f": 1.0,
        "bleu1": 1.0,
        "bleu2": 1.0,
        "bleu3": 1.0,
        "bleu4": 0.5623413251903491,
        "bert_precision": 1.0,
        "bert_recall": 1.0,
        "bert_f1": 1.0,
        "meteor": 0.9814814814814815,
        "sbert_similarity": 1.0
      }
    },
    {
      "sample_id": 0,
      "question": "What was one of Deborah's favorite games to play with her mom on the PlayStation game system?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Monster Hunter: World",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8571063876152039,
        "bert_recall": 0.7771293520927429,
        "bert_f1": 0.8151609301567078,
        "meteor": 0.0,
        "sbert_similarity": 0.08434903621673584
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Deborah and her partner travel for a few weeks in September 2023?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Phuket",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8488593101501465,
        "bert_recall": 0.7342110872268677,
        "bert_f1": 0.7873836755752563,
        "meteor": 0.0,
        "sbert_similarity": 0.15100602805614471
      }
    },
    {
      "sample_id": 0,
      "question": "What did Jolene do with their mom's old friends?",
      "prediction": "rem reminisced and looked through photos",
      "reference": "reminisced and looked through photos",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.9090909090909091,
        "rouge1_f": 0.9090909090909091,
        "rouge2_f": 0.888888888888889,
        "rougeL_f": 0.9090909090909091,
        "bleu1": 0.8333333333333334,
        "bleu2": 0.816496580927726,
        "bleu3": 0.7955364837549187,
        "bleu4": 0.7598356856515925,
        "bert_precision": 0.9111550450325012,
        "bert_recall": 0.90864497423172,
        "bert_f1": 0.9098982810974121,
        "meteor": 0.9764705882352942,
        "sbert_similarity": 0.9055341482162476
      }
    },
    {
      "sample_id": 0,
      "question": "Where did Jolene get married?",
      "prediction": "Not mentioned in the conversation",
      "reference": "on the beach",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.25,
        "rouge1_f": 0.25,
        "rouge2_f": 0.0,
        "rougeL_f": 0.25,
        "bleu1": 0.2,
        "bleu2": 0.07071067811865477,
        "bleu3": 0.05665132701906204,
        "bleu4": 0.05372849659117709,
        "bert_precision": 0.8855166435241699,
        "bert_recall": 0.8994693756103516,
        "bert_f1": 0.8924384713172913,
        "meteor": 0.15625,
        "sbert_similarity": 0.21214993298053741
      }
    },
    {
      "sample_id": 0,
      "question": "What new activity did Jolene and her neighbor organize for the community on 16 September, 2023?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Free gardening class",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8798320293426514,
        "bert_recall": 0.8547803163528442,
        "bert_f1": 0.8671252727508545,
        "meteor": 0.0,
        "sbert_similarity": 0.044674478471279144
      }
    },
    {
      "sample_id": 0,
      "question": "What food did Jolene's mom make for her on holidays?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Pineapple cakes",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.857772946357727,
        "bert_recall": 0.7771978378295898,
        "bert_f1": 0.8154999613761902,
        "meteor": 0.0,
        "sbert_similarity": 0.10151557624340057
      }
    },
    {
      "sample_id": 0,
      "question": "What kind of cookies did Deborah used to bake with someone close to her?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Chocolate chip cookies",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8656420707702637,
        "bert_recall": 0.76582932472229,
        "bert_f1": 0.8126824498176575,
        "meteor": 0.0,
        "sbert_similarity": 0.06812132894992828
      }
    },
    {
      "sample_id": 0,
      "question": "What activity did Jolene enjoy at the music festival with their pals on September 20, 2023?",
      "prediction": "Not mentioned in the conversation",
      "reference": "Dancing and bopping around",
      "category": 5,
      "metrics": {
        "exact_match": 0,
        "f1": 0.0,
        "rouge1_f": 0.0,
        "rouge2_f": 0.0,
        "rougeL_f": 0.0,
        "bleu1": 0,
        "bleu2": 0,
        "bleu3": 0,
        "bleu4": 0,
        "bert_precision": 0.8738872408866882,
        "bert_recall": 0.8152652978897095,
        "bert_f1": 0.8435590863227844,
        "meteor": 0.0,
        "sbert_similarity": 0.15424872934818268
      }
    }
  ]
}